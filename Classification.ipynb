{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from sklearn import preprocessing\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Heartbeat Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N = ['N', 'L', 'R', 'e', 'j']\n",
    "SVEB = ['A', 'a', 'J', 'S']\n",
    "VEB = ['V', 'E']\n",
    "F = ['F']\n",
    "Q = ['l', 'f', 'Q']\n",
    "Non_beat_anns = ['[', ']', '!', 'x', '(', ')', 'p', 't', 'u', '`', '~', '^', '|', '+', 's', 'T', '*', 'D', '=', '\"', '@']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Training Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DS1 = ['101', '106', '108', '109', '112', '114', '115', '116', '118', '119', '122', '124', \n",
    "       '201', '203', '205', '207', '208', '209', '215', '220', '223', '230']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Training_Hbs_lead0 = {}\n",
    "Training_Hbs_lead1 = {}\n",
    "\n",
    "for ds in DS1:\n",
    "    Training_Hbs_lead0[ds] = pd.read_csv('Extracted Features/DS1/' + ds + '_lead0.csv')\n",
    "    Training_Hbs_lead1[ds] = pd.read_csv('Extracted Features/DS1/' + ds + '_lead1.csv')\n",
    "    \n",
    "    new_beat_0 = []\n",
    "    new_beat_1 = []\n",
    "    \n",
    "    cA7_lead0 = []\n",
    "    cD7_lead0 = []\n",
    "    cD6_lead0 = []\n",
    "    cD5_lead0 = []\n",
    "    cD4_lead0 = []\n",
    "    cD3_lead0 = []\n",
    "    cD2_lead0 = []\n",
    "    cD1_lead0 = []\n",
    "    \n",
    "    cA7_lead1 = []\n",
    "    cD7_lead1 = []\n",
    "    cD6_lead1 = []\n",
    "    cD5_lead1 = []\n",
    "    cD4_lead1 = []\n",
    "    cD3_lead1 = []\n",
    "    cD2_lead1 = []\n",
    "    cD1_lead1 = []\n",
    "    \n",
    "    for i in range(len(Training_Hbs_lead0[ds]['beat'])):\n",
    "        new_beat_0.append(pd.Series(json.loads(Training_Hbs_lead0[ds]['beatValues'][i]), index=json.loads(Training_Hbs_lead0[ds]['beatIndex'][i])))\n",
    "        new_beat_1.append(pd.Series(json.loads(Training_Hbs_lead1[ds]['beatValues'][i]), index=json.loads(Training_Hbs_lead1[ds]['beatIndex'][i])))\n",
    "        \n",
    "        cA7_lead0.append(json.loads(Training_Hbs_lead0[ds]['cA7'][i]))\n",
    "        cD7_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD7'][i]))\n",
    "        cD6_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD6'][i]))\n",
    "        cD5_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD5'][i]))\n",
    "        cD4_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD4'][i]))\n",
    "        cD3_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD3'][i]))\n",
    "        cD2_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD2'][i]))\n",
    "        cD1_lead0.append(json.loads(Training_Hbs_lead0[ds]['cD1'][i]))\n",
    "        \n",
    "        cA7_lead1.append(json.loads(Training_Hbs_lead1[ds]['cA7'][i]))\n",
    "        cD7_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD7'][i]))\n",
    "        cD6_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD6'][i]))\n",
    "        cD5_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD5'][i]))\n",
    "        cD4_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD4'][i]))\n",
    "        cD3_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD3'][i]))\n",
    "        cD2_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD2'][i]))\n",
    "        cD1_lead1.append(json.loads(Training_Hbs_lead1[ds]['cD1'][i]))\n",
    "        \n",
    "    Training_Hbs_lead0[ds]['beat'] = new_beat_0\n",
    "    Training_Hbs_lead0[ds]['cA7'] = cA7_lead0\n",
    "    Training_Hbs_lead0[ds]['cD7'] = cD7_lead0                      \n",
    "    Training_Hbs_lead0[ds]['cD6'] = cD6_lead0\n",
    "    Training_Hbs_lead0[ds]['cD5'] = cD5_lead0                      \n",
    "    Training_Hbs_lead0[ds]['cD4'] = cD4_lead0 \n",
    "    Training_Hbs_lead0[ds]['cD3'] = cD3_lead0                      \n",
    "    Training_Hbs_lead0[ds]['cD2'] = cD2_lead0 \n",
    "    Training_Hbs_lead0[ds]['cD1'] = cD1_lead0                      \n",
    "                          \n",
    "    Training_Hbs_lead1[ds]['beat'] = new_beat_1\n",
    "    Training_Hbs_lead1[ds]['cA7'] = cA7_lead1\n",
    "    Training_Hbs_lead1[ds]['cD7'] = cD7_lead1                      \n",
    "    Training_Hbs_lead1[ds]['cD6'] = cD6_lead1\n",
    "    Training_Hbs_lead1[ds]['cD5'] = cD5_lead1                      \n",
    "    Training_Hbs_lead1[ds]['cD4'] = cD4_lead1 \n",
    "    Training_Hbs_lead1[ds]['cD3'] = cD3_lead1                      \n",
    "    Training_Hbs_lead1[ds]['cD2'] = cD2_lead1 \n",
    "    Training_Hbs_lead1[ds]['cD1'] = cD1_lead1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann</th>\n",
       "      <th>annIdx</th>\n",
       "      <th>beat</th>\n",
       "      <th>cA7</th>\n",
       "      <th>cD1</th>\n",
       "      <th>cD2</th>\n",
       "      <th>cD3</th>\n",
       "      <th>cD4</th>\n",
       "      <th>cD5</th>\n",
       "      <th>cD6</th>\n",
       "      <th>cD7</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>postRR</th>\n",
       "      <th>preRR</th>\n",
       "      <th>skewness</th>\n",
       "      <th>beatValues</th>\n",
       "      <th>beatIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>441</td>\n",
       "      <td>351    0.120418\n",
       "352    0.131024\n",
       "353    0.14175...</td>\n",
       "      <td>[-0.6855614132675378, 0.6510380366797159]</td>\n",
       "      <td>[-0.007499561745074906, -0.0081047163052224, -...</td>\n",
       "      <td>[-0.021762909161338634, -0.02551553356263281, ...</td>\n",
       "      <td>[-0.06775185534555714, -0.06327188790700006, 0...</td>\n",
       "      <td>[-0.1909314964659382, 0.36584125262880723, -0....</td>\n",
       "      <td>[0.3009534213591719, 0.014668449869526007, 1.1...</td>\n",
       "      <td>[0.7790524149689939, -0.8858083129886856, -0.3...</td>\n",
       "      <td>[1.3384287988998684, 0.2783035336978315]</td>\n",
       "      <td>3.738128</td>\n",
       "      <td>347.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.764917</td>\n",
       "      <td>[0.12041775474730385, 0.13102373667904321, 0.1...</td>\n",
       "      <td>[351, 352, 353, 354, 355, 356, 357, 358, 359, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ann  annIdx                                               beat  \\\n",
       "0   N     441  351    0.120418\n",
       "352    0.131024\n",
       "353    0.14175...   \n",
       "\n",
       "                                         cA7  \\\n",
       "0  [-0.6855614132675378, 0.6510380366797159]   \n",
       "\n",
       "                                                 cD1  \\\n",
       "0  [-0.007499561745074906, -0.0081047163052224, -...   \n",
       "\n",
       "                                                 cD2  \\\n",
       "0  [-0.021762909161338634, -0.02551553356263281, ...   \n",
       "\n",
       "                                                 cD3  \\\n",
       "0  [-0.06775185534555714, -0.06327188790700006, 0...   \n",
       "\n",
       "                                                 cD4  \\\n",
       "0  [-0.1909314964659382, 0.36584125262880723, -0....   \n",
       "\n",
       "                                                 cD5  \\\n",
       "0  [0.3009534213591719, 0.014668449869526007, 1.1...   \n",
       "\n",
       "                                                 cD6  \\\n",
       "0  [0.7790524149689939, -0.8858083129886856, -0.3...   \n",
       "\n",
       "                                        cD7  kurtosis  postRR  preRR  \\\n",
       "0  [1.3384287988998684, 0.2783035336978315]  3.738128   347.0    NaN   \n",
       "\n",
       "   skewness                                         beatValues  \\\n",
       "0 -1.764917  [0.12041775474730385, 0.13102373667904321, 0.1...   \n",
       "\n",
       "                                           beatIndex  \n",
       "0  [351, 352, 353, 354, 355, 356, 357, 358, 359, ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Hbs_lead0['108'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Testing Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "DS2 = ['100', '103', '105', '111', '113', '117', '121', '123', '200', '202', '210', '212', \n",
    "       '213', '214', '219', '221', '222', '228', '231', '232', '233', '234']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Testing_Hbs_lead0 = {}\n",
    "Testing_Hbs_lead1 = {}\n",
    "\n",
    "for ds in DS2:\n",
    "    Testing_Hbs_lead0[ds] = pd.read_csv('Extracted Features/DS2/' + ds + '_lead0.csv')\n",
    "    Testing_Hbs_lead1[ds] = pd.read_csv('Extracted Features/DS2/' + ds + '_lead1.csv')\n",
    "    \n",
    "    new_beat_0 = []\n",
    "    new_beat_1 = []\n",
    "    \n",
    "    cA7_lead0 = []\n",
    "    cD7_lead0 = []\n",
    "    cD6_lead0 = []\n",
    "    cD5_lead0 = []\n",
    "    cD4_lead0 = []\n",
    "    cD3_lead0 = []\n",
    "    cD2_lead0 = []\n",
    "    cD1_lead0 = []\n",
    "    \n",
    "    cA7_lead1 = []\n",
    "    cD7_lead1 = []\n",
    "    cD6_lead1 = []\n",
    "    cD5_lead1 = []\n",
    "    cD4_lead1 = []\n",
    "    cD3_lead1 = []\n",
    "    cD2_lead1 = []\n",
    "    cD1_lead1 = []\n",
    "    \n",
    "    for i in range(len(Testing_Hbs_lead0[ds]['beat'])):\n",
    "        new_beat_0.append(pd.Series(json.loads(Testing_Hbs_lead0[ds]['beatValues'][i]), index=json.loads(Testing_Hbs_lead0[ds]['beatIndex'][i])))\n",
    "        new_beat_1.append(pd.Series(json.loads(Testing_Hbs_lead1[ds]['beatValues'][i]), index=json.loads(Testing_Hbs_lead1[ds]['beatIndex'][i])))\n",
    "        \n",
    "        cA7_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cA7'][i]))\n",
    "        cD7_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD7'][i]))\n",
    "        cD6_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD6'][i]))\n",
    "        cD5_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD5'][i]))\n",
    "        cD4_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD4'][i]))\n",
    "        cD3_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD3'][i]))\n",
    "        cD2_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD2'][i]))\n",
    "        cD1_lead0.append(json.loads(Testing_Hbs_lead0[ds]['cD1'][i]))\n",
    "        \n",
    "        cA7_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cA7'][i]))\n",
    "        cD7_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD7'][i]))\n",
    "        cD6_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD6'][i]))\n",
    "        cD5_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD5'][i]))\n",
    "        cD4_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD4'][i]))\n",
    "        cD3_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD3'][i]))\n",
    "        cD2_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD2'][i]))\n",
    "        cD1_lead1.append(json.loads(Testing_Hbs_lead1[ds]['cD1'][i]))\n",
    "        \n",
    "    Testing_Hbs_lead0[ds]['beat'] = new_beat_0\n",
    "    Testing_Hbs_lead0[ds]['cA7'] = cA7_lead0\n",
    "    Testing_Hbs_lead0[ds]['cD7'] = cD7_lead0                      \n",
    "    Testing_Hbs_lead0[ds]['cD6'] = cD6_lead0\n",
    "    Testing_Hbs_lead0[ds]['cD5'] = cD5_lead0                      \n",
    "    Testing_Hbs_lead0[ds]['cD4'] = cD4_lead0 \n",
    "    Testing_Hbs_lead0[ds]['cD3'] = cD3_lead0                      \n",
    "    Testing_Hbs_lead0[ds]['cD2'] = cD2_lead0 \n",
    "    Testing_Hbs_lead0[ds]['cD1'] = cD1_lead0                      \n",
    "                          \n",
    "    Testing_Hbs_lead1[ds]['beat'] = new_beat_1\n",
    "    Testing_Hbs_lead1[ds]['cA7'] = cA7_lead1\n",
    "    Testing_Hbs_lead1[ds]['cD7'] = cD7_lead1                      \n",
    "    Testing_Hbs_lead1[ds]['cD6'] = cD6_lead1\n",
    "    Testing_Hbs_lead1[ds]['cD5'] = cD5_lead1                      \n",
    "    Testing_Hbs_lead1[ds]['cD4'] = cD4_lead1 \n",
    "    Testing_Hbs_lead1[ds]['cD3'] = cD3_lead1                      \n",
    "    Testing_Hbs_lead1[ds]['cD2'] = cD2_lead1 \n",
    "    Testing_Hbs_lead1[ds]['cD1'] = cD1_lead1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann</th>\n",
       "      <th>annIdx</th>\n",
       "      <th>beat</th>\n",
       "      <th>cA7</th>\n",
       "      <th>cD1</th>\n",
       "      <th>cD2</th>\n",
       "      <th>cD3</th>\n",
       "      <th>cD4</th>\n",
       "      <th>cD5</th>\n",
       "      <th>cD6</th>\n",
       "      <th>cD7</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>postRR</th>\n",
       "      <th>preRR</th>\n",
       "      <th>skewness</th>\n",
       "      <th>beatValues</th>\n",
       "      <th>beatIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>196</td>\n",
       "      <td>106   -0.004937\n",
       "107   -0.004219\n",
       "108   -0.00333...</td>\n",
       "      <td>[1.5844777501600635, -0.36985029277674747]</td>\n",
       "      <td>[-0.0005074752601473076, -0.000682562347570346...</td>\n",
       "      <td>[-0.001728801591072192, -0.0002090682989102632...</td>\n",
       "      <td>[-0.0031979442446018165, -0.013979095860740283...</td>\n",
       "      <td>[-0.011043111774410757, -0.16880017877670617, ...</td>\n",
       "      <td>[-0.3068244520617898, 0.5176590206737243, -2.9...</td>\n",
       "      <td>[0.08947136053677307, 1.8822124772535171, -0.8...</td>\n",
       "      <td>[-1.0953481028411476, -0.7149465074712467]</td>\n",
       "      <td>7.034972</td>\n",
       "      <td>262.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.601941</td>\n",
       "      <td>[-0.0049367932597447822, -0.004219114864275645...</td>\n",
       "      <td>[106, 107, 108, 109, 110, 111, 112, 113, 114, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ann  annIdx                                               beat  \\\n",
       "0   N     196  106   -0.004937\n",
       "107   -0.004219\n",
       "108   -0.00333...   \n",
       "\n",
       "                                          cA7  \\\n",
       "0  [1.5844777501600635, -0.36985029277674747]   \n",
       "\n",
       "                                                 cD1  \\\n",
       "0  [-0.0005074752601473076, -0.000682562347570346...   \n",
       "\n",
       "                                                 cD2  \\\n",
       "0  [-0.001728801591072192, -0.0002090682989102632...   \n",
       "\n",
       "                                                 cD3  \\\n",
       "0  [-0.0031979442446018165, -0.013979095860740283...   \n",
       "\n",
       "                                                 cD4  \\\n",
       "0  [-0.011043111774410757, -0.16880017877670617, ...   \n",
       "\n",
       "                                                 cD5  \\\n",
       "0  [-0.3068244520617898, 0.5176590206737243, -2.9...   \n",
       "\n",
       "                                                 cD6  \\\n",
       "0  [0.08947136053677307, 1.8822124772535171, -0.8...   \n",
       "\n",
       "                                          cD7  kurtosis  postRR  preRR  \\\n",
       "0  [-1.0953481028411476, -0.7149465074712467]  7.034972   262.0    NaN   \n",
       "\n",
       "   skewness                                         beatValues  \\\n",
       "0  2.601941  [-0.0049367932597447822, -0.004219114864275645...   \n",
       "\n",
       "                                           beatIndex  \n",
       "0  [106, 107, 108, 109, 110, 111, 112, 113, 114, ...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_Hbs_lead0['105'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load SUP Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SUP = ['800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '820', '821', \n",
    "#       '822', '823', '824', '825', '826', '827', '828', '829', '840', '841', '842', '843', '844', '845', '846', \n",
    "#       '847', '848', '849', '850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1173,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SUP = ['851','852','853','854','855','856','857','858','859','860','861','862','863','864','865','866','867',\n",
    "       '868','869','870','871','872','873','874','875','876','877','878','879','880','881','882','883','884',\n",
    "       '885','886','887','888','889','890','891','892','893','894']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n"
     ]
    }
   ],
   "source": [
    "SUP_Hbs_lead0 = {}\n",
    "\n",
    "for ds in SUP:\n",
    "    print(ds)\n",
    "    SUP_Hbs_lead0[ds] = pd.read_csv('D:/Data/Extracted Features/SUP/' + ds + '_lead0.csv')\n",
    "    \n",
    "    new_beat_0 = []\n",
    "    \n",
    "    cA7_lead0 = []\n",
    "    cD7_lead0 = []\n",
    "    cD6_lead0 = []\n",
    "    cD5_lead0 = []\n",
    "    cD4_lead0 = []\n",
    "    cD3_lead0 = []\n",
    "    cD2_lead0 = []\n",
    "    cD1_lead0 = []\n",
    "    \n",
    "    for i in range(len(SUP_Hbs_lead0[ds]['beat'])):\n",
    "        new_beat_0.append(pd.Series(json.loads(SUP_Hbs_lead0[ds]['beatValues'][i]), index=json.loads(SUP_Hbs_lead0[ds]['beatIndex'][i])))\n",
    "        \n",
    "        cA7_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cA7'][i]))\n",
    "        cD7_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD7'][i]))\n",
    "        cD6_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD6'][i]))\n",
    "        cD5_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD5'][i]))\n",
    "        cD4_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD4'][i]))\n",
    "        cD3_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD3'][i]))\n",
    "        cD2_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD2'][i]))\n",
    "        cD1_lead0.append(json.loads(SUP_Hbs_lead0[ds]['cD1'][i]))\n",
    "        \n",
    "    SUP_Hbs_lead0[ds]['beat'] = new_beat_0\n",
    "    SUP_Hbs_lead0[ds]['cA7'] = cA7_lead0\n",
    "    SUP_Hbs_lead0[ds]['cD7'] = cD7_lead0                      \n",
    "    SUP_Hbs_lead0[ds]['cD6'] = cD6_lead0\n",
    "    SUP_Hbs_lead0[ds]['cD5'] = cD5_lead0                      \n",
    "    SUP_Hbs_lead0[ds]['cD4'] = cD4_lead0 \n",
    "    SUP_Hbs_lead0[ds]['cD3'] = cD3_lead0                      \n",
    "    SUP_Hbs_lead0[ds]['cD2'] = cD2_lead0 \n",
    "    SUP_Hbs_lead0[ds]['cD1'] = cD1_lead0                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann</th>\n",
       "      <th>annIdx</th>\n",
       "      <th>beat</th>\n",
       "      <th>cA7</th>\n",
       "      <th>cD1</th>\n",
       "      <th>cD2</th>\n",
       "      <th>cD3</th>\n",
       "      <th>cD4</th>\n",
       "      <th>cD5</th>\n",
       "      <th>cD6</th>\n",
       "      <th>cD7</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>postRR</th>\n",
       "      <th>preRR</th>\n",
       "      <th>skewness</th>\n",
       "      <th>beatValues</th>\n",
       "      <th>beatIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>236</td>\n",
       "      <td>146    0.004401\n",
       "147    0.004539\n",
       "148    0.00606...</td>\n",
       "      <td>[2.0728159249247087, 0.06249117793281288]</td>\n",
       "      <td>[-9.707552380883644e-05, -0.001295537934714896...</td>\n",
       "      <td>[-0.0025063216758385264, 0.0037813090096038907...</td>\n",
       "      <td>[-0.0005321909783577231, 0.023911382933700782,...</td>\n",
       "      <td>[0.03830452387900508, 0.012260985926018264, -0...</td>\n",
       "      <td>[0.1604972652796808, -1.0450939691010928, 0.14...</td>\n",
       "      <td>[-0.8675467657409904, -1.6442954175267506, -2....</td>\n",
       "      <td>[-1.2083775492531927, -0.029406338635164782]</td>\n",
       "      <td>7.114818</td>\n",
       "      <td>187.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.166995</td>\n",
       "      <td>[0.0044012795578855027, 0.0045385650802304313,...</td>\n",
       "      <td>[146, 147, 148, 149, 150, 151, 152, 153, 154, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ann  annIdx                                               beat  \\\n",
       "0   N     236  146    0.004401\n",
       "147    0.004539\n",
       "148    0.00606...   \n",
       "\n",
       "                                         cA7  \\\n",
       "0  [2.0728159249247087, 0.06249117793281288]   \n",
       "\n",
       "                                                 cD1  \\\n",
       "0  [-9.707552380883644e-05, -0.001295537934714896...   \n",
       "\n",
       "                                                 cD2  \\\n",
       "0  [-0.0025063216758385264, 0.0037813090096038907...   \n",
       "\n",
       "                                                 cD3  \\\n",
       "0  [-0.0005321909783577231, 0.023911382933700782,...   \n",
       "\n",
       "                                                 cD4  \\\n",
       "0  [0.03830452387900508, 0.012260985926018264, -0...   \n",
       "\n",
       "                                                 cD5  \\\n",
       "0  [0.1604972652796808, -1.0450939691010928, 0.14...   \n",
       "\n",
       "                                                 cD6  \\\n",
       "0  [-0.8675467657409904, -1.6442954175267506, -2....   \n",
       "\n",
       "                                            cD7  kurtosis  postRR  preRR  \\\n",
       "0  [-1.2083775492531927, -0.029406338635164782]  7.114818   187.0    NaN   \n",
       "\n",
       "   skewness                                         beatValues  \\\n",
       "0  2.166995  [0.0044012795578855027, 0.0045385650802304313,...   \n",
       "\n",
       "                                           beatIndex  \n",
       "0  [146, 147, 148, 149, 150, 151, 152, 153, 154, ...  "
      ]
     },
     "execution_count": 983,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SUP_Hbs_lead0['851'].head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load INCART Data from Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1685,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I60', 'I61', 'I62', 'I63', 'I64', 'I65', 'I66', 'I67', 'I68', 'I69', 'I70', 'I71', 'I72', 'I73', 'I74', 'I75']\n"
     ]
    }
   ],
   "source": [
    "INCART = []\n",
    "for i in range(60, 76):\n",
    "    if i < 10:\n",
    "        INCART.append('I0' + str(i))\n",
    "    else:\n",
    "        INCART.append('I' + str(i))\n",
    "print(INCART)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1686,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I60\n",
      "I61\n",
      "I62\n",
      "I63\n",
      "I64\n",
      "I65\n",
      "I66\n",
      "I67\n",
      "I68\n",
      "I69\n",
      "I70\n",
      "I71\n",
      "I72\n",
      "I73\n",
      "I74\n",
      "I75\n"
     ]
    }
   ],
   "source": [
    "INCART_Hbs_lead0 = {}\n",
    "INCART_Hbs_lead1 = {}\n",
    "\n",
    "for ds in INCART:\n",
    "    print(ds)\n",
    "    INCART_Hbs_lead0[ds] = pd.read_csv('D:/Data/Extracted Features/INCART/' + ds + '_lead0.csv')\n",
    "    INCART_Hbs_lead1[ds] = pd.read_csv('D:/Data/Extracted Features/INCART/' + ds + '_lead1.csv')\n",
    "    \n",
    "    new_beat_0 = []\n",
    "    new_beat_1 = []\n",
    "    \n",
    "    cA7_lead0 = []\n",
    "    cD7_lead0 = []\n",
    "    cD6_lead0 = []\n",
    "    cD5_lead0 = []\n",
    "    cD4_lead0 = []\n",
    "    cD3_lead0 = []\n",
    "    cD2_lead0 = []\n",
    "    cD1_lead0 = []\n",
    "    \n",
    "    cA7_lead1 = []\n",
    "    cD7_lead1 = []\n",
    "    cD6_lead1 = []\n",
    "    cD5_lead1 = []\n",
    "    cD4_lead1 = []\n",
    "    cD3_lead1 = []\n",
    "    cD2_lead1 = []\n",
    "    cD1_lead1 = []\n",
    "    \n",
    "    for i in range(len(INCART_Hbs_lead0[ds]['beat'])):\n",
    "        new_beat_0.append(pd.Series(json.loads(INCART_Hbs_lead0[ds]['beatValues'][i]), index=json.loads(INCART_Hbs_lead0[ds]['beatIndex'][i])))\n",
    "        new_beat_1.append(pd.Series(json.loads(INCART_Hbs_lead1[ds]['beatValues'][i]), index=json.loads(INCART_Hbs_lead1[ds]['beatIndex'][i])))\n",
    "        \n",
    "        cA7_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cA7'][i]))\n",
    "        cD7_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD7'][i]))\n",
    "        cD6_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD6'][i]))\n",
    "        cD5_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD5'][i]))\n",
    "        cD4_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD4'][i]))\n",
    "        cD3_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD3'][i]))\n",
    "        cD2_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD2'][i]))\n",
    "        cD1_lead0.append(json.loads(INCART_Hbs_lead0[ds]['cD1'][i]))\n",
    "        \n",
    "        cA7_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cA7'][i]))\n",
    "        cD7_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD7'][i]))\n",
    "        cD6_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD6'][i]))\n",
    "        cD5_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD5'][i]))\n",
    "        cD4_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD4'][i]))\n",
    "        cD3_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD3'][i]))\n",
    "        cD2_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD2'][i]))\n",
    "        cD1_lead1.append(json.loads(INCART_Hbs_lead1[ds]['cD1'][i]))\n",
    "        \n",
    "    INCART_Hbs_lead0[ds]['beat'] = new_beat_0\n",
    "    INCART_Hbs_lead0[ds]['cA7'] = cA7_lead0\n",
    "    INCART_Hbs_lead0[ds]['cD7'] = cD7_lead0                      \n",
    "    INCART_Hbs_lead0[ds]['cD6'] = cD6_lead0\n",
    "    INCART_Hbs_lead0[ds]['cD5'] = cD5_lead0                      \n",
    "    INCART_Hbs_lead0[ds]['cD4'] = cD4_lead0 \n",
    "    INCART_Hbs_lead0[ds]['cD3'] = cD3_lead0                      \n",
    "    INCART_Hbs_lead0[ds]['cD2'] = cD2_lead0 \n",
    "    INCART_Hbs_lead0[ds]['cD1'] = cD1_lead0                      \n",
    "                          \n",
    "    INCART_Hbs_lead1[ds]['beat'] = new_beat_1\n",
    "    INCART_Hbs_lead1[ds]['cA7'] = cA7_lead1\n",
    "    INCART_Hbs_lead1[ds]['cD7'] = cD7_lead1                      \n",
    "    INCART_Hbs_lead1[ds]['cD6'] = cD6_lead1\n",
    "    INCART_Hbs_lead1[ds]['cD5'] = cD5_lead1                      \n",
    "    INCART_Hbs_lead1[ds]['cD4'] = cD4_lead1 \n",
    "    INCART_Hbs_lead1[ds]['cD3'] = cD3_lead1                      \n",
    "    INCART_Hbs_lead1[ds]['cD2'] = cD2_lead1 \n",
    "    INCART_Hbs_lead1[ds]['cD1'] = cD1_lead1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ann</th>\n",
       "      <th>annIdx</th>\n",
       "      <th>beat</th>\n",
       "      <th>cA7</th>\n",
       "      <th>cD1</th>\n",
       "      <th>cD2</th>\n",
       "      <th>cD3</th>\n",
       "      <th>cD4</th>\n",
       "      <th>cD5</th>\n",
       "      <th>cD6</th>\n",
       "      <th>cD7</th>\n",
       "      <th>kurtosis</th>\n",
       "      <th>postRR</th>\n",
       "      <th>preRR</th>\n",
       "      <th>skewness</th>\n",
       "      <th>beatValues</th>\n",
       "      <th>beatIndex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>N</td>\n",
       "      <td>157</td>\n",
       "      <td>67    -0.072184\n",
       "68    -0.079161\n",
       "69    -0.08707...</td>\n",
       "      <td>[0.5242842638471439, 0.39201903248058456]</td>\n",
       "      <td>[0.004933053907834231, 0.0027809410044728616, ...</td>\n",
       "      <td>[0.013367952995756507, -0.010476911852706466, ...</td>\n",
       "      <td>[0.002564730814633112, -0.02657074178364137, -...</td>\n",
       "      <td>[-0.07657610368421508, -0.028273341154906588, ...</td>\n",
       "      <td>[-0.10534499737213335, -0.21334357645573487, -...</td>\n",
       "      <td>[-0.45552402609522685, 0.011789243545128392, -...</td>\n",
       "      <td>[-0.3948120914902048, 0.3728664160403449]</td>\n",
       "      <td>5.983733</td>\n",
       "      <td>227.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.110229</td>\n",
       "      <td>[-0.072184296659828381, -0.07916068840020514, ...</td>\n",
       "      <td>[67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ann  annIdx                                               beat  \\\n",
       "0   N     157  67    -0.072184\n",
       "68    -0.079161\n",
       "69    -0.08707...   \n",
       "\n",
       "                                         cA7  \\\n",
       "0  [0.5242842638471439, 0.39201903248058456]   \n",
       "\n",
       "                                                 cD1  \\\n",
       "0  [0.004933053907834231, 0.0027809410044728616, ...   \n",
       "\n",
       "                                                 cD2  \\\n",
       "0  [0.013367952995756507, -0.010476911852706466, ...   \n",
       "\n",
       "                                                 cD3  \\\n",
       "0  [0.002564730814633112, -0.02657074178364137, -...   \n",
       "\n",
       "                                                 cD4  \\\n",
       "0  [-0.07657610368421508, -0.028273341154906588, ...   \n",
       "\n",
       "                                                 cD5  \\\n",
       "0  [-0.10534499737213335, -0.21334357645573487, -...   \n",
       "\n",
       "                                                 cD6  \\\n",
       "0  [-0.45552402609522685, 0.011789243545128392, -...   \n",
       "\n",
       "                                         cD7  kurtosis  postRR  preRR  \\\n",
       "0  [-0.3948120914902048, 0.3728664160403449]  5.983733   227.0    NaN   \n",
       "\n",
       "   skewness                                         beatValues  \\\n",
       "0  2.110229  [-0.072184296659828381, -0.07916068840020514, ...   \n",
       "\n",
       "                                           beatIndex  \n",
       "0  [67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 7...  "
      ]
     },
     "execution_count": 906,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INCART_Hbs_lead0['I01'].head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 把所有feature放在一起做简单的测试"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Feature Tree with Consideration of Beats Connections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 1 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction, selection and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ann', 'annIdx', 'beat', 'cA7', 'cD1', 'cD2', 'cD3', 'cD4', 'cD5', 'cD6', 'cD7', \n",
    "           'kurtosis', 'postRR', 'preRR', 'skewness', 'beatValues', 'beatIndex']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "Training_Data_Label_1 = []\n",
    "Training_Data_1 = []\n",
    "\n",
    "for ds in DS1:\n",
    "    for i in range(len(Training_Hbs_lead0[ds]['beat'])):\n",
    "        if np.isnan(Training_Hbs_lead0[ds]['postRR'][i]) or np.isnan(Training_Hbs_lead0[ds]['preRR'][i]):\n",
    "            continue\n",
    "            \n",
    "        if Training_Hbs_lead0[ds]['ann'][i] in Non_beat_anns:\n",
    "            continue\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            Training_Data_Label_1.append('N')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            Training_Data_Label_1.append('S')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            Training_Data_Label_1.append('V')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            Training_Data_Label_1.append('F')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            Training_Data_Label_1.append('Q')\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(Training_Hbs_lead0[ds][column][i]) == list:\n",
    "                features.extend(Training_Hbs_lead0[ds][column][i])\n",
    "            else:\n",
    "                features.append(Training_Hbs_lead0[ds][column][i])\n",
    "        Training_Data_1.append(features)\n",
    "\n",
    "Training_Data_1 = preprocessing.scale(Training_Data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试DataSet的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training_Data_1 Amount: 50959\n",
      "Training_Data_Label_1 Amount: 50959\n"
     ]
    }
   ],
   "source": [
    "print('Training_Data_1 Amount: ' + str(len(Training_Data_1)))\n",
    "print('Training_Data_Label_1 Amount: ' + str(len(Training_Data_Label_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 2 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 500,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ann', 'annIdx', 'beat', 'cA7', 'cD1', 'cD2', 'cD3', 'cD4', 'cD5', 'cD6', 'cD7', \n",
    "           'kurtosis', 'postRR', 'preRR', 'skewness', 'beatValues', 'beatIndex']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "Training_Data_Label_DS_2 = {}\n",
    "Training_Data_DS_2 = {}\n",
    "Training_Data_Label_2 = []\n",
    "Training_Data_2 = []\n",
    "\n",
    "for ds in DS1: \n",
    "    Training_Data_Label_DS_2[ds] = []\n",
    "    Training_Data_DS_2[ds] = []\n",
    "    dsLength = len(Training_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if Training_Hbs_lead0[ds]['ann'][i] in Non_beat_anns:\n",
    "            continue\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            Training_Data_Label_2.append('N')\n",
    "            Training_Data_Label_DS_2[ds].append('N')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            Training_Data_Label_2.append('S')\n",
    "            Training_Data_Label_DS_2[ds].append('S')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            Training_Data_Label_2.append('V')\n",
    "            Training_Data_Label_DS_2[ds].append('V')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            Training_Data_Label_2.append('F')\n",
    "            Training_Data_Label_DS_2[ds].append('F')\n",
    "        elif Training_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            Training_Data_Label_2.append('Q')\n",
    "            Training_Data_Label_DS_2[ds].append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 逐个计算feature\n",
    "        features = []\n",
    "        if ds == '114':\n",
    "            for column in selected_colums:\n",
    "                if type(Training_Hbs_lead1[ds][column][i]) == list:\n",
    "                    features.extend(Training_Hbs_lead1[ds][column][i])\n",
    "                else:\n",
    "                    features.append(Training_Hbs_lead1[ds][column][i])\n",
    "        else:\n",
    "            for column in selected_colums:\n",
    "                if type(Training_Hbs_lead0[ds][column][i]) == list:\n",
    "                    features.extend(Training_Hbs_lead0[ds][column][i])\n",
    "                else:\n",
    "                    features.append(Training_Hbs_lead0[ds][column][i])\n",
    "        Training_Data_2.append(features)\n",
    "        Training_Data_DS_2[ds].append(features)\n",
    "Training_Data_2 = preprocessing.scale(Training_Data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Distribution over Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "plt.figure(figsize=(15, 12), dpi=200)\n",
    "p1 = plt.subplot(221)\n",
    "p1.set_title('Recording 106')\n",
    "p1.set_ylabel('kurtosis')\n",
    "p1.set_xlabel('skewness')\n",
    "p2 = plt.subplot(222)\n",
    "p2.set_title('Recording 109')\n",
    "p2.set_ylabel('kurtosis')\n",
    "p2.set_xlabel('kurskewnesstosis')\n",
    "p3 = plt.subplot(223)\n",
    "p3.set_title('Recording 114')\n",
    "p3.set_ylabel('kurtosis')\n",
    "p3.set_xlabel('skewness')\n",
    "p4 = plt.subplot(224)\n",
    "p4.set_title('Recording 119')\n",
    "p4.set_ylabel('kurtosis')\n",
    "p4.set_xlabel('skewness')\n",
    "\n",
    "for ds in ['106','109', '114', '119']:\n",
    "    for i, features in enumerate(Training_Data_DS_2[ds]):\n",
    "        if features[1] > 1000 or features[0] > 1000:\n",
    "            continue\n",
    "        if Training_Data_Label_DS_2[ds][i] in N:\n",
    "            color = mark[0]\n",
    "        elif Training_Data_Label_DS_2[ds][i] in VEB:\n",
    "            color = mark[3]\n",
    "        else:\n",
    "            continue\n",
    "        if ds == '106':\n",
    "            p1.plot(features[2], features[3], color)\n",
    "        elif ds == '109':\n",
    "            p2.plot(features[2], features[3], color)\n",
    "        elif ds == '114':\n",
    "            p3.plot(features[2], features[3], color)\n",
    "        elif ds == '119':\n",
    "            p4.plot(features[2], features[3], color)\n",
    "        else: \n",
    "            continue\n",
    "plt.savefig('skewness&kurtosis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从以上观察可得preRR是分辨N和S的最主要手段，其次，skewness和kurtosis有时也能分辨出，如201"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101 N Median   : {352.0,25.1790821543}\n",
      "101 N Mean     : {348.66720517,25.1790821543}\n",
      "101 S Median   : {237.0,58.105268455}\n",
      "101 S Mean     : {254.666666667,58.105268455}\n",
      "101 ALL Median : {352.0,25.5478841401}\n",
      "101 ALL Mean   : {348.537056928,25.5478841401}\n",
      "\n",
      "106 N Median   : {359.0,57.087551719}\n",
      "106 N Mean     : {367.383388704,57.087551719}\n",
      "106 S Median   : {nan,nan}\n",
      "106 S Mean     : {nan,nan}\n",
      "106 ALL Median : {337.0,93.9276053698}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 ALL Mean   : {320.488395062,93.9276053698}\n",
      "\n",
      "108 N Median   : {371.0,40.4529350334}\n",
      "108 N Mean     : {370.727691422,40.4529350334}\n",
      "108 S Median   : {217.5,10.7790305687}\n",
      "108 S Mean     : {218.25,10.7790305687}\n",
      "108 ALL Median : {370.0,44.6740023936}\n",
      "108 ALL Mean   : {368.766477273,44.6740023936}\n",
      "\n",
      "109 N Median   : {257.0,12.6459931258}\n",
      "109 N Mean     : {257.341502611,12.6459931258}\n",
      "109 S Median   : {nan,nan}\n",
      "109 S Mean     : {nan,nan}\n",
      "109 ALL Median : {257.0,13.6176960228}\n",
      "109 ALL Mean   : {256.72874654,13.6176960228}\n",
      "\n",
      "112 N Median   : {256.0,7.70050813262}\n",
      "112 N Mean     : {256.045777427,7.70050813262}\n",
      "112 S Median   : {208.5,17.5}\n",
      "112 S Mean     : {208.5,17.5}\n",
      "112 ALL Median : {256.0,7.82777012034}\n",
      "112 ALL Mean   : {256.008280757,7.82777012034}\n",
      "\n",
      "114 N Median   : {341.0,44.5940676053}\n",
      "114 N Mean     : {348.798129813,44.5940676053}\n",
      "114 S Median   : {258.5,64.3317681157}\n",
      "114 S Mean     : {257.916666667,64.3317681157}\n",
      "114 ALL Median : {340.0,48.2318646304}\n",
      "114 ALL Mean   : {345.877996803,48.2318646304}\n",
      "\n",
      "115 N Median   : {328.0,31.3671381033}\n",
      "115 N Mean     : {332.921025641,31.3671381033}\n",
      "115 S Median   : {nan,nan}\n",
      "115 S Mean     : {nan,nan}\n",
      "115 ALL Median : {328.0,31.3671381033}\n",
      "115 ALL Mean   : {332.921025641,31.3671381033}\n",
      "\n",
      "116 N Median   : {270.0,20.6367363657}\n",
      "116 N Mean     : {273.67246629,20.6367363657}\n",
      "116 S Median   : {180.0,0.0}\n",
      "116 S Mean     : {180.0,0.0}\n",
      "116 ALL Median : {269.0,27.9783352486}\n",
      "116 ALL Mean   : {269.472810295,27.9783352486}\n",
      "\n",
      "118 N Median   : {291.0,29.2748911278}\n",
      "118 N Mean     : {288.921405455,29.2748911278}\n",
      "118 S Median   : {221.5,18.8878152779}\n",
      "118 S Mean     : {217.354166667,18.8878152779}\n",
      "118 ALL Median : {290.0,33.0257225574}\n",
      "118 ALL Mean   : {285.301098901,33.0257225574}\n",
      "\n",
      "119 N Median   : {331.0,67.6253142868}\n",
      "119 N Mean     : {365.258273848,67.6253142868}\n",
      "119 S Median   : {nan,nan}\n",
      "119 S Mean     : {nan,nan}\n",
      "119 ALL Median : {325.0,92.9280589993}\n",
      "119 ALL Mean   : {327.032241814,92.9280589993}\n",
      "\n",
      "122 N Median   : {262.0,14.444165497}\n",
      "122 N Mean     : {262.551556814,14.444165497}\n",
      "122 S Median   : {nan,nan}\n",
      "122 S Mean     : {nan,nan}\n",
      "122 ALL Median : {262.0,14.444165497}\n",
      "122 ALL Mean   : {262.551556814,14.444165497}\n",
      "\n",
      "124 N Median   : {406.0,28.6701476298}\n",
      "124 N Mean     : {404.437703849,28.6701476298}\n",
      "124 S Median   : {354.0,25.7211897971}\n",
      "124 S Mean     : {354.967741935,25.7211897971}\n",
      "124 ALL Median : {404.0,32.5872414177}\n",
      "124 ALL Mean   : {401.548886139,32.5872414177}\n",
      "\n",
      "201 N Median   : {307.0,128.49591005}\n",
      "201 N Mean     : {339.745554874,128.49591005}\n",
      "201 S Median   : {184.5,26.9841431573}\n",
      "201 S Mean     : {180.2265625,26.9841431573}\n",
      "201 ALL Median : {310.0,124.677237342}\n",
      "201 ALL Mean   : {329.88718734,124.677237342}\n",
      "\n",
      "203 N Median   : {234.0,68.5015303499}\n",
      "203 N Mean     : {232.283735655,68.5015303499}\n",
      "203 S Median   : {142.0,11.0}\n",
      "203 S Mean     : {142.0,11.0}\n",
      "203 ALL Median : {220.0,72.0532131634}\n",
      "203 ALL Mean   : {218.048690396,72.0532131634}\n",
      "\n",
      "205 N Median   : {243.0,16.6282736774}\n",
      "205 N Mean     : {247.150700935,16.6282736774}\n",
      "205 S Median   : {182.0,4.71404520791}\n",
      "205 S Mean     : {185.333333333,4.71404520791}\n",
      "205 ALL Median : {242.0,23.7317809399}\n",
      "205 ALL Mean   : {244.665284583,23.7317809399}\n",
      "\n",
      "207 N Median   : {339.0,50.2777490062}\n",
      "207 N Mean     : {333.983734548,50.2777490062}\n",
      "207 S Median   : {180.0,11.372980947}\n",
      "207 S Mean     : {179.933962264,11.372980947}\n",
      "207 ALL Median : {335.0,67.0920181313}\n",
      "207 ALL Mean   : {321.191247974,67.0920181313}\n",
      "\n",
      "208 N Median   : {234.0,46.3658547091}\n",
      "208 N Mean     : {244.782828283,46.3658547091}\n",
      "208 S Median   : {214.5,4.5}\n",
      "208 S Mean     : {214.5,4.5}\n",
      "208 ALL Median : {208.0,45.7268180942}\n",
      "208 ALL Mean   : {219.686779661,45.7268180942}\n",
      "\n",
      "209 N Median   : {227.0,15.0011633955}\n",
      "209 N Mean     : {225.831168831,15.0011633955}\n",
      "209 S Median   : {141.0,21.3387155705}\n",
      "209 S Mean     : {150.798955614,21.3387155705}\n",
      "209 ALL Median : {225.0,29.6806034784}\n",
      "209 ALL Mean   : {216.255163225,29.6806034784}\n",
      "\n",
      "215 N Median   : {193.0,16.2324575038}\n",
      "215 N Mean     : {195.5410401,16.2324575038}\n",
      "215 S Median   : {156.0,8.17856276426}\n",
      "215 S Mean     : {152.333333333,8.17856276426}\n",
      "215 ALL Median : {192.0,19.1947067126}\n",
      "215 ALL Mean   : {193.266964286,19.1947067126}\n",
      "\n",
      "220 N Median   : {322.0,17.6750942721}\n",
      "220 N Mean     : {323.495897436,17.6750942721}\n",
      "220 S Median   : {192.0,37.3714440481}\n",
      "220 S Mean     : {193.053191489,37.3714440481}\n",
      "220 ALL Median : {321.0,33.2984707134}\n",
      "220 ALL Mean   : {317.497064579,33.2984707134}\n",
      "\n",
      "223 N Median   : {255.0,25.420166113}\n",
      "223 N Mean     : {262.944199706,25.420166113}\n",
      "223 S Median   : {200.0,18.883391466}\n",
      "223 S Mean     : {203.273972603,18.883391466}\n",
      "223 ALL Median : {251.0,37.2406779565}\n",
      "223 ALL Mean   : {249.479446792,37.2406779565}\n",
      "\n",
      "230 N Median   : {286.0,30.9108284777}\n",
      "230 N Mean     : {288.194937833,30.9108284777}\n",
      "230 S Median   : {nan,nan}\n",
      "230 S Mean     : {nan,nan}\n",
      "230 ALL Median : {286.0,30.9500965384}\n",
      "230 ALL Mean   : {288.159343098,30.9500965384}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ds in DS1:\n",
    "    NNN = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    SSS = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    ALL = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    for idx, label in enumerate(Training_Data_Label_DS_2[ds]):\n",
    "        if Training_Data_DS_2[ds][idx][1] > 1000:\n",
    "            continue\n",
    "        ALL['preRR'].append(Training_Data_DS_2[ds][idx][1])\n",
    "        ALL['skewness'].append(Training_Data_DS_2[ds][idx][2])\n",
    "        ALL['kurtosis'].append(Training_Data_DS_2[ds][idx][3])\n",
    "        if label == 'N':\n",
    "            NNN['preRR'].append(Training_Data_DS_2[ds][idx][1])\n",
    "            NNN['skewness'].append(Training_Data_DS_2[ds][idx][2])\n",
    "            NNN['kurtosis'].append(Training_Data_DS_2[ds][idx][3])\n",
    "        if label == 'S':\n",
    "            SSS['preRR'].append(Training_Data_DS_2[ds][idx][1])\n",
    "            SSS['skewness'].append(Training_Data_DS_2[ds][idx][2])\n",
    "            SSS['kurtosis'].append(Training_Data_DS_2[ds][idx][3])\n",
    "    #print(ds + ': {' + str(np.mean(NNN['preRR'])) + ',' + str(np.mean(SSS['preRR'])) + '}') \n",
    "    ssmean = np.mean(SSS['preRR'])\n",
    "    nnmean = np.mean(NNN['preRR'])\n",
    "    #print(ds + ': ' + str((ssmean - nnmean) / nnmean))\n",
    "    print(ds + ' N Median   ' + ': {' + str(np.median(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' N Mean     ' + ': {' + str(np.mean(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' S Median   ' + ': {' + str(np.median(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' S Mean     ' + ': {' + str(np.mean(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' ALL Median ' + ': {' + str(np.median(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print(ds + ' ALL Mean   ' + ': {' + str(np.mean(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Testing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 1 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction, selection and Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ann', 'annIdx', 'beat', 'cA7', 'cD1', 'cD2', 'cD3', 'cD4', 'cD5', 'cD6', 'cD7', \n",
    "           'kurtosis', 'postRR', 'preRR', 'skewness', 'beatValues', 'beatIndex']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "Testing_Data_Label_1 = []\n",
    "Testing_Data_1 = []\n",
    "\n",
    "for ds in DS2:\n",
    "    for i in range(len(Testing_Hbs_lead0[ds]['beat'])):\n",
    "        if np.isnan(Testing_Hbs_lead0[ds]['postRR'][i]) or np.isnan(Testing_Hbs_lead0[ds]['preRR'][i]):\n",
    "            continue\n",
    "            \n",
    "        if Testing_Hbs_lead0[ds]['ann'][i] in Non_beat_anns:\n",
    "            continue\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            Testing_Data_Label_1.append('N')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            Testing_Data_Label_1.append('S')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            Testing_Data_Label_1.append('V')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            Testing_Data_Label_1.append('F')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            Testing_Data_Label_1.append('Q')\n",
    "        else:\n",
    "            continue\n",
    "            \n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(Testing_Hbs_lead0[ds][column][i]) == list:\n",
    "                features.extend(Testing_Hbs_lead0[ds][column][i])\n",
    "            else:\n",
    "                features.append(Testing_Hbs_lead0[ds][column][i])\n",
    "        Testing_Data_1.append(features)\n",
    "\n",
    "Testing_Data_1 = preprocessing.scale(Testing_Data_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "测试DataSet的情况"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing_Data_1 Amount: 49648\n",
      "Testing_Data_Label_1 Amount: 49648\n"
     ]
    }
   ],
   "source": [
    "print('Testing_Data_1 Amount: ' + str(len(Testing_Data_1)))\n",
    "print('Testing_Data_Label_1 Amount: ' + str(len(Testing_Data_Label_1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 2 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Tree Construction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ann', 'annIdx', 'beat', 'cA7', 'cD1', 'cD2', 'cD3', 'cD4', 'cD5', 'cD6', 'cD7', \n",
    "           'kurtosis', 'postRR', 'preRR', 'skewness', 'beatValues', 'beatIndex']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "Testing_Data_Label_DS_2 = {}\n",
    "Testing_Data_DS_2 = {}\n",
    "Testing_Data_Label_2 = []\n",
    "Testing_Data_2 = []\n",
    "\n",
    "for ds in DS2: \n",
    "    Testing_Data_Label_DS_2[ds] = []\n",
    "    Testing_Data_DS_2[ds] = []\n",
    "    dsLength = len(Testing_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if Testing_Hbs_lead0[ds]['ann'][i] in Non_beat_anns:\n",
    "            continue\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            Testing_Data_Label_2.append('N')\n",
    "            Testing_Data_Label_DS_2[ds].append('N')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            Testing_Data_Label_2.append('S')\n",
    "            Testing_Data_Label_DS_2[ds].append('S')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            Testing_Data_Label_2.append('V')\n",
    "            Testing_Data_Label_DS_2[ds].append('V')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            Testing_Data_Label_2.append('F')\n",
    "            Testing_Data_Label_DS_2[ds].append('F')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            Testing_Data_Label_2.append('Q')\n",
    "            Testing_Data_Label_DS_2[ds].append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 逐个计算feature\n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(Testing_Hbs_lead0[ds][column][i]) == list:\n",
    "                features.extend(Testing_Hbs_lead0[ds][column][i])\n",
    "            else:\n",
    "                features.append(Testing_Hbs_lead0[ds][column][i])\n",
    "        Testing_Data_2.append(features)\n",
    "        Testing_Data_DS_2[ds].append(features)\n",
    "Testing_Data_2 = preprocessing.scale(Testing_Data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check Distribution over Selected Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 509,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABQgAAAGPCAYAAAAQmj0dAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAAMTQAADE0B0s6tTgAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzs3XuQXNV57/3fmpsuDAgbyYfASCPN\njEi4xGVknNgMxzYWxxIp15sTcOHXxkkg+EKkCGPKOPUCtnMc4SQ2GGNABmIZYYfjkESu1BuOjTgh\n8BqNTGwsOAmIGM1IGjECgwTmIpA0mpn1/rFmZ3p61lq7e/dl+vL9VKma7t1799qX3qgfPet5jLVW\nAAAAAAAAAJpTy2wPAAAAAAAAAMDsIUAIAAAAAAAANDEChAAAAAAAAEATI0AIAAAAAAAANDEChAAA\nAAAAAEATI0AIAAAAAAAANDEChAAAAAAAAEATI0AIAAAAAAAANDEChAAAAAAAAEATI0AIAAAAAAAA\nNLG2Qt9ojHlA0omSJiS9LmmdtfYJY8wcSTdKWiVpVNLj1tqPT66zXNLdkhZKekXSJdbaHWmfNWfO\nHLto0aJi9wUAAAAAAACApH379o1aa+cU8t6CA4SSLrLWviJJxpj/Luk7klZI+ku5oOEp1lprjPm1\nnHXukHSntXaTMebDkjZKek/aBy1atEgjIyNFDA0AAAAAAABAwhizv9D3FhwgTIKDkxZImjDGHCPp\nUkld1lo7+b7nJwfxNrkA4gcn19ks6VZjzFJr7Z5CPxcAAAAAAABA5RRVg9AY811jzLOS1kv6Q0m9\nkl6SdJ0x5jFjzCPGmJWTb18s6Tlr7ZgkTQYQ90paUrbRAwAAAAAAAChJUQFCa+0fWGsXS7pO0tck\ntUvqkbTDWnuWpD+R9LfGmKSAoM3bhPFt1xhzlTFmJPlz8ODBonYCAAAAAAAAQDZmcmZw8Ssac0jS\nUknPSeqw1o5Pvv5TSZ+XtEPSTkknWGvHjDFG0vOS3p02xbirq8tSgxAAAAAAAADIxhizz1rbVch7\nC8ogNMYcZ4w5Kef578lNLX5R0oNyHYxljOmWtEzSL6y1L0p6XNLHJ1e7UNIe6g8CAAAAAAAAtaPQ\nJiULJG02xsyT61i8X9KHJrsWXy7pO8aYv5I0LulTSaMSSZ+WtMkYc42k1+TqFgIAAAAAAACoEZmn\nGFcSU4wBAAAAAACA7Mo+xRgAAAAAAABAYyJACAAAAAAAADQxAoQAAAAAAABAEyu0SQkAAAAAAED5\nWSsNDEiDg1Jfn9TfLxkz26MCmgoBQgAAAAAAMDuGh6VVq6Tdu6WODml0VFq2TNqyRerunu3RAU2D\nKcYAAAAAAKD6rHXBwaEhFxg8eNA9Dg1Jq1e75QCqggAhAAAAAACovoEBac8eaWxs+utjY9KuXW45\ngKogQAgAAAAAAKpvcFBqb/cv6+hwywFUBQFCAAAAAABQfX19bkqxz+ioWw6gKggQAgAAAACA6uvv\ndw1J2vL6p7a1ST09bjmAqiBACAAAAAAAqs8Y1624t9dNKe7sdI99fe51Y2Z7hEDTaEt/CwAAAAAA\nQAV0d0tPP+0akgwOuuBgfz/BQaDKjK3BtuFdXV12ZGRktocBAAAAAAAA1CVjzD5rbVch72WKMQAA\nAAAAANDECBACAAAAAAAATYwAIQAAAAAAANDECBACAAAAAAAATYwAIQAAAAAAANDECBACAAAAAAAA\nTYwAIQAAAAAAANDECBACAAAAAAAATYwAIQAAAAAAANDECBACAAAAAAAATYwAIQAAAAAAANDECBAC\nAAAAAAAATYwAIQAAAAAAANDECBACAAAAAAAATYwAIQAAAAAAANDECBACAAAAAAAATYwAIQAAAAAA\nANDECBACAAAAAAAATYwAIQAAAAAAANDECBACAAAAAAAATazgAKEx5gFjzL8ZY54wxjxijHlH3vIv\nGWOsMeaMnNeWG2O2GWOeMcb81BhzWjkHDwAAAAAAAKA0xWQQXmStfbu19h2SbpT0nWSBMWaFpHdL\n2pu3zh2S7rTWniLpq5I2ljheAAAAAAAAAGVUcIDQWvtKztMFkiYkyRgzR9JtktZIsskbjDFvk7RC\n0t9MvrRZ0jJjzNKSRgwAAAAAAACgbNqKebMx5ruSzp18unry8cuS/sZau9sYk/v2xZKes9aOSZK1\n1hpj9kpaImlP3navknRV8nzBggXFDAsAAAAAAABARkU1KbHW/oG1drGk6yR9zRjzHknvkrQhtEre\nc+N9k7Vft9Z2JX86OzuLGRYAAAAAAABQGGulrVulTZvco80PXzWfojIIE9bau40xt0sakPQbkpLs\nwS5JW4wxn5D0c0ldxpg2a+2YcW9YrJl1CgEAAAAAAIDKGx6WVq2Sdu+WOjqk0VFp2TJpyxapu3u2\nRzdrCsogNMYcZ4w5Kef570l6SdJXrLUnWWuXWmuXShqRtMpa+yNr7YuSHpf08cnVLpS0x1q7p5w7\nAAAAAAAAAKSy1gUHh4ZcYPDgQfc4NCStXt3UmYSFZhAukLTZGDNPrjnJfkkfsjb1yH1a0iZjzDWS\nXpP0h5lHCgAAAAAAAGQ1MCDt2SONjU1/fWxM2rXLLT/nnFkZ2mwrKEBorX1W0m8V8L6lec9/Iek9\nmUYGAAAAAAAAlMvgoNTeLh05MnNZR4db3qQBwqKalAAAAAAAAAB1qa/PTSn2GR11y5sUAUIAAAAA\nAAA0vv5+15CkLW9CbVub1NPjljcpAoQAAAAAAABofMa4bsW9vW5KcWene+zrc68bM9sjnDWFNikB\nAAAAAAAA6lt3t/T0064hyeCgCw729zd1cFCSTHoj4urr6uqyIyMjsz0MAAAAAAAAoC4ZY/ZZa7sK\neS9TjAEAAAAAAIAmRoAQAAAAAAAAaGLUIAQAAACAcrCWmlYAgLpEgBAAAAAASjU8LK1aJe3e7Tpi\njo5Ky5a5rpjd3bM9OgAAophiDAAAAAClsNYFB4eGXGDw4EH3ODQkrV7tlgMAUMMIEAIAAABAKQYG\npD17pLGx6a+PjUm7drnlAADUMAKEAAAAAFCKwUGpvd2/rKPDLQcAoIYRIAQAAACAUvT1uSnFPqOj\nbjkAADWMACEAAAAAlKK/3zUkacvrAdnWJvX0uOUAANQwAoQAAAAAUApjXLfi3l43pbiz0z329bnX\njZntEQIAENWW/hYAAAAAQFR3t/T0064hyeCgCw729xMcBADUBWOtne0xzNDV1WVHRkZmexgAAAAA\nAABAXTLG7LPWdhXyXqYYAwAAAAAAAE2MACEAAAAAAADQxAgQAgAAAAAAAE2MACEAAAAAAADQxAgQ\nAgAAAAAAAE2MACEAAAAAAADQxAgQAgAAAAAAAE2MACEAAAAAAADQxAgQAgAAAAAAAE2MACEAAAAA\nAADQxAgQAgAAAAAAAE2MACEAAAAAAADQxAgQAgAAAAAAAE2MACEAAAAAAADQxAgQAgAAAAAAAE2M\nACEAAAAAAADQxAoOEBpjHjDG/Jsx5gljzCPGmHcYY+YaY/7RGPPM5Ov3G2OW5qzztsnXdhpjnjTG\nnFOJnQAAAAAAAACQTTEZhBdZa99urX2HpBslfWfy9Tsl/frk6/dNPk/8paRHrbXLJV0q6R5jTFsZ\nxg0AAAAAAACgDAoOEFprX8l5ukDShLX2sLX2h9ZaO/n6o5J6ct53kaTbJtf/maQXJJFFCAAAAAAA\nANSIorL5jDHflXTu5NPVnrdcIemfJt97gqQWa+3+nOV7JC3xbPcqSVclzxcsWFDMsAAAAAAAAABk\nVFSTEmvtH1hrF0u6TtLXcpcZY66RtFzStbmr5G3CBLb7dWttV/Kns7OzmGEBAAAAAAAAyChTF2Nr\n7d2Szp3MEpQx5nOSLpB0vrX2zcn3vDS5bFHOqt2S9pY0YgAAAAAAAABlU1CA0BhznDHmpJznvyfp\nJUkvT04P/qik/5ZXp1CS/l7S2sl13iXpRElbyzFwAAAAAAAAAKUrtAbhAkmbjTHzJE1I2i/pQ5JO\nlutovEvSQ8YYSTpirf3tyfX+VNL3jDE7JY1K+n1r7VgZxw8AAAAAAACgBAUFCK21z0r6rcBib13B\nyfVekPTBDOMCAAAAAAAAUAWZahACAAAAAAAAaAwECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAA\nAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIE\nCAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAA\nAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAm\nRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEAAAAAAIAmRoAQAAAAAAAAaGIECAEA\nAAAAAIAm1jbbAwAAAECEtdLAgDQ4KPX1Sf39kjGzPSoAAAA0EAKEAAAAtWp4WFq1Stq9W+rokEZH\npWXLpC1bpO7u2R4dAAAAGgRTjAEAAGqRtS44ODTkAoMHD7rHoSFp9Wq3HAAAACgDAoQAAAC1aGBA\n2rNHGhub/vrYmLRrl1sOAAAAlAEBQgAAgFo0OCi1t/uXdXS45QAAAEAZECAEAACoRX19bkqxz+io\nWw4AAACUAQFCAACAWtTf7xqStOX1lGtrk3p63HIAAACgDAoOEBpjHjDG/Jsx5gljzCPGmHdMvr7c\nGLPNGPOMMeanxpjTctYJLgMAAECEMa5bcW+vm1Lc2eke+/rc68bM9ggBAADQINrS3/KfLrLWviJJ\nxpj/Luk7klZIukPSndbaTcaYD0vaKOk9k+vElgEAACCmu1t6+mnXkGRw0AUH+/sJDqK5WMt3AACA\nCjPW2uJXMuYPJa2T9DuSnpG00Fo7Zowxkp6X9G5Jb4aWWWv3xLbf1dVlR0ZGih4XAAAAgAYyPCyt\nWiXt3u0yaEdH3dT7LVtcAB0AAAQZY/ZZa7sKeW8xGYQyxnxX0rmTT1dLWizpOWvtmCRZa60xZq+k\nJZLeiCzbk7fdqyRdlTxfsGBBMcMCAAAA0GisdcHBoSFpbGyqac/QkLR6tbRjB5mEAACUSVFNSqy1\nf2CtXSzpOklfS17Oe1vu/6Vjy3K3+3VrbVfyp7Ozs5hhAQAAAGg0AwPSnj0uOJhrbEzatcstBwAA\nZZGpi7G19m65TMIRSV3GmDZJmpxGvFjSXknPRpYBAAAAzcVaaetWadMm95ih1E9TGRyU2tv9yzo6\n3HIAAFAWBU0xNsYcJ6nTWvvc5PPfk/SSpBclPS7p45I2SbpQ0p6kxqAxJrgMAAAAaBrU0iteX9/U\ntOJ8o6NuOQAAKIuCmpQYYxZL2ixpnqQJSfslfc5a+4Qx5tflAoAnSHpN0h9aa5+aXC+4LIYmJQAA\nAGgY1kqnnjpVSy/R1uaCXNTS8+O4AQBQkmKalGTqYlxpBAgBAADQMLZulc47TzpyZOayjg7pwQel\nc86p/rjqgS/zsqfHZV4uWTLbowMAoKZVrIsxAAAAgCIltfRCAcLBQQKEId3d0tNPu4Ykg4Muc7C/\nn8xBAADKjAAhAAAAUEnU0iuNMS6AShAVAICKIUAIAABQDGvJZkJx+vtdQxJfLb2eHrccAFAf+HsA\nGhQBQgAAgELRiRZZGOOukVAtPX5YAkB94O8BaGA0KQEAACgEHVVRKrJOAKB+8fcA1KFimpS0VHow\nAAAADWFgQNqzZ/qPAsk937XLLQdiklp6l1ziHvkhCQD1g78HoMERIAQAAChE0onWJ+lECwAAGhN/\nD0CDI0AIAABQCDrRAgDQvPh7ABocAUIAAIBCJJ1o2/J6vNGJFgCAxsffA9DgCBACAAAUIulE29vr\nphJ1drrHvj460QIA0Oj4ewAaHF2MAQAAikEnWgAAmhd/D0AdKaaLMQFCAAAAAAAAoMEUEyBkijEA\nAAAAAADQxAgQAgAAAAAAAE2MACEAAAAAAADQxAgQAgAAAAAAAE2MACEAAAAAAADQxNpmewAAAKDG\nWCsNDEiDg1Jfn9TfLxkz26MCAAAAUCEECAEAwJThYWnVKmn3bqmjQxodlZYtk7Zskbq7Z3t0AAAA\nACqAACEAAHCsdcHBoSFpbMwFByX3fPVqaccOMgkrhaxNcA0AAIBZRIAQAAA4AwPSnj0uOJhrbEza\ntcstP+ecWRlaQyNrE1wDAABgltGkBAAAOIODUnu7f1lHh1uO8srN2hwdlQ4edI9J1qa1sz3C8rFW\n2rpV2rTJPTbSvpWima4BAABQswgQAgAAp69valpxvtFRtxzlVUjWZiMYHpZOPVVauVJat849nnqq\ne73ZNcs1AAAAahoBQgAA4PT3u2mNbXkVSNrapJ4etxzl1QxZm2TIxTXDNQAAAGoeAUIAAOAY42qe\n9fa6wERnp3vs63Ov0zCh/Joha5MMubhmuAYAAEDNo0kJAACY0t0tPf003VSrJcnaTDpHJ6qRtVmt\nrrlJhtyRIzOXJRlyzdz8ZjavAQAAgEkECAEAwHTGuIBNMwdtqiXJ2szvYNvTU9mszWp2zSVDLm62\nrgEAAIAcxtZg3Zeuri47MjIy28MAAKA2VCvTC7Mndo7Lff6tdQ1CfBlrfX3Sjh3lvb6q/Xn1iu85\nAAAoM2PMPmttV0HvJUAIAEANq2amF2pPJc7/1q3SeeeFp/w++GD5s0d9+5FkyC1ZUt7PAgAAgKTi\nAoRMMQYAoFbldn8dG5uappl0fyXzqrFV6vzPRk1AalsCAADUNAKEAADUqkK6v1InsHFV6vzPVk1A\nalui2pi2DQBAwVpmewAAACAgyfTySTK90Lgqdf6Trrltef9OTNdcNJLhYVf7cuVKad0693jqqe51\nAAAwQ0EBQmPMXGPMPxpjnjHGPGGMud8Ys3Ry2VnGmJ8YYx43xjxtjPl8znrzjTHfN8YMTq57QWV2\nAwCABkT318Zirav/t2mTe0yrA12p8590ze3tdYHGzk732NdXn11ziz2us7XNSm4X0+VOzx8dlQ4e\ndI/J9HyOOwAAMxTUpMQYM1fSByT9yFprjTF/Iun/stZ+0BjzuKQvWWv/X2PMWyX9h6T3W2t3GGO+\nKKnHWnuJMWaZpJ9IOtVa+6vY59GkBAAA0f21kWRpNmKtO8+7ds1c1tsr7dxZejfjep9+WYkmLpVq\nDETDoeqZjUY8AADUoGKalBSUQWitPWyt/aGdiiY+Kqkn5y3HTz4eI2lU0suTzz8i6bbJbeyW9GNJ\nv1vIZwIA0PQaLdOrWdVqNlNSE/CSS9xjvV1PlTiulTpXtXoNNCrKMwAAULSsNQivkPRPk/99qaQ/\nN8bslfSMpP/HWvvLyWVLJOUW+tgz+RoAAChE0v31wQelW25xjzt2SEv432ndKKTZSGi9ffv8y559\nNrxes8h6XKu9zUpuF36UZwAAoGhFBwiNMddIWi7p2smXrpZ0tbV2iaTTJV1vjPn1nFVy/0nU+0/T\nxpirjDEjyZ+DBw8WOywAABpXvWd6Nbus2UyVzoKq93p4lTg+lTrmZLRVF414AAAoWlEBQmPM5yRd\nIOl8a+2bxpiFkn7PWvt3kmSt3SXpXyWdPbnKXklLczbRPfnaNNbar1tru5I/nZ2dxe8JAABALcqa\nzVTJLKhG6PBaieNTqWNORlt1UZ4BAICiFdSkRHJZfpIulnRe0mTEGNMqab9ckPD/mwwYPi7pAmvt\nz4wxfyZpaU6TkkflmpS87P8UhyYlAACgYRTSbEaa2TBEcusNDkrj41PrtbZKy5dnb1LTKM1vKrEf\nlTo2jXLM600jNOIBAKAExTQpKbSLcZekZyXtkvT65MtHrLW/bYw5T9JfSWqT1C7pDmvtzZPrHSPp\nO5LeKWlC0jXW2n9I+zwChAAAoKH4Otj29LhspqSBha+77ciIdO650tGjU9vq6JAeekg6++zw58U0\nUofX2HHNWqezEtus5HYBAAACyh4grDYChAAAoOH4spmkeGbZxIRrYlHOrLNNm9y0Yl/N585O1wzn\nkkuK3+5sqUSWWKUyz8hoAwAAVUSAEAAAoB7EsvmSpha52YOJUjL9tm51NQd9NfHqLYMQAAAAQcUE\nCIvuYgwAABpcPXW3jY21HvYj1t22pcX98Sml8y0dXgEAAJCnLf0tAACgafjqpCX18Lq7Z3t008XG\nKtXHfsS6205MhIOapXS+TTq8hurhMeUVAACg6TDFGAAAOPXUaTVtrIXU7quFenDl2I9SPnu29x+N\nh+sKAICaQQ1CAABQvHrqbltq7b7Fi2snw7DYDsd0vkWtqqcMZAAAmkAxAUKmGAMAUE71nD2T1MML\nBQgHB0sLEJbz2MTGGqrbJ7n92LlT+sQnprL2kim+Q0PS6tXVz5Ts7nafefvt0vbt0ooV0uWXT+3H\n009X/5qq5+sYsyMJZtfK9woAABSFACEAAOVS79kzfX3+gJvkXs9a804q/7EppXbfoUPSnj3Tp+1K\n7vmuXS4wVs1Myfxj873vSd/85tSxMcaNp1pjqvfrGLNjYKC2vlcAAKAodDEGAKAccrNnRkelgwfd\nY5I9U2slPXwdfs8+O/x+Y+LL0z6r3Mcm1om3t9dNww116Z03L9w5uJTuwFLxXZULOTaldGMudt1K\nj6eWNMp+1IpYR+5Sv1cAAKDiyCAEAKAc6il7JpQhtn59OEgyPi5t25ZtHypxbIyRNm6Uzj13+ust\nLe71k08O1+7buzecfVhKd+AsXZXXr48fm82bpeuuy5bNlyUTMO1clTKeWkKWZPnFsnpL+V4BAICq\noEkJAADlsGmTtG6dy7jK19kp3XKLdMkl1R7VTLGuuQsXSr/8ZXjdjRulP/qj4j+z1GPjq4cnuf0Y\nHHTBy0Rrq7R8uat3Jvnr6FWiW3Nsm7297r9Dx/zgQf+xOeYY6dhjpQMHih9n1n1MO1edndL+/eFj\nPhs15oqtl1hP3brrCccVAICaU0yTEqYYAwBQDvWSPRPLEHvxxfi6Tz6Z7TNLqW04POyCDitXusDV\nypXu+ebNbj9yA1WSe55kJSa1+y65xD0mwQljXKZYb6/LHuvsdI99fe71LEGM2HEdGnJj8i07cCB+\nbF56KZ55mWU8sXVj1/GRI268vmM+NBQfT6WEro/h4fA6WY8N4irxvQIAAFVDgBAAgHyx2mQTE9KG\nDa4L7oYN7rk0VROvtXX6tlpb3dTWJOutmnz7EasTFuv+K0mvvpptHIXUNiy2Pt+6daXVO0s6B990\nk/SRj7jHp56SlizJto+x49raGj62c+ZIJ5zgv24WLnTLfdL2MWs9uFhtx4ULZwbVEmNjrjt0NSXX\nx+Dg9OtjcDBe25JaeZXT3e26bj/4oMsMfvBB9z3L+r0CAABVQ4AQAIBcsYykgQFp7lxp7Vo33Xbt\nWvc8yVbbuHFmIKi11b1e7eyZ0H50doYzxNLKjrzzndnGsm1bfCrsD34QzxIsNvOukIzN4WHptNOk\nz35Wuvde93jaafHMs5hY5t34+FQgOd/Ro9IXv+i/br70pexZqVkzWmNZYGvWhD/PWtcdupoGBlwN\nwWIzGusl27dehTJ3AQBATaMGIQAAibQ6crt2uYBOvo4O6c03pdNPr436W1nr4fX1uewpX5ZYR4cL\nAKVlGfrE6trF6uwtWiS99pr0xhvFrVep+nwxWY952vmYmJg5Pbka++ir67dpk3TZZf5AchIgv/TS\n8DbL7a67so2HWnkAAKBJUIMQANA8YtOBY8t8YrXJBgf9wUHJZR1dfXXt1DWL7cfu3a5zbqhO2MMP\nz5xe2t7uXk+Cg8Ue17S6dqE6e7EswaNH3RTGnh433jlzpgJuafXOSq1B59v/WObdAw+El11/fXws\n11+fraZbIfXgYufRlwW2fPnMayPR1uaWV9OhQ+FrL5bRSK08AACAGQJ/ywMAoA4MD7saZLt3ux/4\no6OuftqWLW55aFl3t397g4Mza8EV6rHHXCDNF9BK6pqdc062bRcrqbEWGsvBg65OWKjDb2+vez15\n3tMjnXSSWz92zEPHtb9f6upyAa98b3mLC+T4gq9z5rjgjS9LsKdHOussN8bc5iNSesAydp7b2uLn\nKm3/Q8dV8i+7++7s5ypNbDxZz2NPTzgTstp1NufNm7pG8xnjloeknSsAAIAmQ4AQAFAdvimLuT/G\n05b7tpc0sBgbm8pQGxpyDQpyp2bmLwtNIeztdVOFffLrnOU76yzpX//Vv6zadc2y1ljLPaa5+5sc\nt6eeih/zLFMzOzqkV14Jj/WWW6TrrpseyOrpke6/f/pY8scaG0vsPB86NDXtN1/aNZd85jnn+AOM\nvmWFnKvYNrModD9849+yZWZgsadndjLvkoxGX3C5kIzGch9XAACAOkaAEABQeWnZSlmymWLTRIeG\npv47f1kyhTQUFAhlJEku68wXKOzokL72NemHP/RnV1W7i3HSiTY0lq4uV4Mt/3ivXx+f7nr77W6d\n0DEPHdeBASlUW/jFF6UTT5Sef94/1gsvdH/yg8eFTBPOEviJZR9W4jPTzlUp103oe5V2nmP7UUuZ\nd7WW0QgAAFDHqEEIAKis3Gyl0VE3ZXJ0dHqmX2x5KGCTTKP1aWkJN9NIpvv66q8NDYWnJc6fL/3p\nn878zI4OV5+vtbVydc2KrfkXq7F2//3uuPqO97p14WPa0SH9/OfhOoxjY9LOnf5lO3fG17viivhx\n89XDi53/5ByHDA258+kzf/5UgDlfKZ8ZUql6eLHvXdp5TtuPWulSmxy7LHUoAQAAMA0ZhACAykrL\nurr99mzZTLGpmRMT4SDa6KgLwoQy6HwdfJPxnH++9Od/7sa8fbu0YoV0+eVTwchKZFdlya6MjSV2\nPg4cCI91dFRasCBbU4i0ZhLz5xd/3Pr6wg1MjhyJT+nu64uf59C6Wadup6nEdVPKea7mdPhyyFKH\nEgAAANMQIAQAVFZaw4zt27M194hNzeztnV6DMHdZT4907bVTdfaSgM/goKt1lzbd0xhpzZrw/sbq\nmsXqLPqWSaXV/PONJXY+5syRjj023BTkjDOyNYWYOzc8xmR5sfXgzj47vMyY+PKs03oLWa/YWpq5\nYy5nPbxSznO9TM3Nr6WYKKVLZ7YRAAAgAElEQVQmJgAAQJNiijEAoLLSsq5WrMiWlZU2NfOBB/zL\nkvpr+bUEx8ddQHH9+spMEx4edlmLK1e6KZ4rV7rnw8PhZZs3p2dXFit2Po4elb74xZn72dIibdwo\nnXKKCyL5xJpCHD4cH1Pacp9t28LLJibiy7NO601bb+/e8DmutliGZdL8pRLXeTUVUhMSAAAABSGD\nEACqJWtmUb1Ly7q6/HLpm9/M1qQhbWqmb9mmTfF6eK+/Ht9mlvMY6xq7atXUf+cvu+IKdxyKza7M\n/dz8sSbnY3BwepC0tdW9fvPNM4OnY2PSZZe5LsY9Pf51Y00h5s1Lzzws9rju3BmeJjw+7pbHjk3a\ntRMaT2g9yQUDy9nhuRRpGZYXXOBv/lJP96S07OS07wcAAAD+EwFCAKiGrHXkGkGSdZW//z097vWW\nlvjytIBFbGqmb1laPbxDh8LbzHoe0zouGxOuFRerpRirFRcb68aN0rnnzgzyXXml9JnPuAy8XBMT\nbpzbtoXX3bgxfK6WL3eBTl9gtq3NTXf11YSMHddCzmOarOfZt97WrZXpqpxVIRmWyT7UaxCtUjUh\nAQAAmhABQgAoVrGZTrHssWapk9Xd7fYza3OPcmZfZs1mk7Kfx1imU2treKxz5rjpn8XWiku75nxN\nXCYmpP/xP+LZlc88I331q+EMw9AxSMtmu/baqXqRhR7XQs5jFoV8X6WZ10cls9myXP+lZljWg6y1\nJAEAADADAUIAKEaWDLJC6mTV+w/1NPnH7Xvfc9OKc49bubP2QrJmsyW1C7Ocx1imU36wLdeRI9Jd\nd7nmKcVkVw4MuPf7xjo4GM5Y3L8/npX35JNuX30ZhoOD4WOwbVt4rEntx1B2ZWibaecxVA8xTdr3\ndfPmmecjuT4qkc2W9fovR4ZlrUvLTm70f3gBAAAoI5qUAEChcjOLRkelgwfdY5JZFPoxnmQW+SSZ\nRda6KYqbNrnH0LZqnW8/sh63ZHtZ1w3p73cBhPxmG0n342uvdeck9/MGB13TibTzGPvMZcvCnxlr\ninHBBa7239q10plnuscnn5SWLAl/3s6d4UzA8fHw57W1xcfyyivpGYY+g4PuGIU+MxQkHRtz++KT\nnMf8DMy0eoi5fNdr2vd13Tr/9Zh0wPad49wOx8V8zwu5/kPbLKRzdCNIso8ffNA1XnnwQZflGft+\nAAAAYAYyCAGgUFkzAdPqZHV2Fl9/rRaFMp1KybyrRPZlLOto/XrpYx/zdzjev39qSnS+tAyxtM/8\n6Ef9601MSHfc4eoCJoG5Rx6Rbr1VeuihcBAsLXssFJAbH3f76Fve1ia98UZ4HyUXuPSJddQdG8uW\n6VZq9ljseg2N9fBht8x3Pe7eLd1zTzjbc+/e8mcfh7IZt2wJn4tE2vJ6EqtDCgAAgIKQQQgAhSok\nE9Anlj3W0+My1krJkKuF7MNYplMpmXelZl9OTEgbNkif+IR7TKbGhrKOXnstnnl3wgnxDLHkWPjG\nk9RhvOkm6SMfcY9PPeU+M1QrbmzMHb/8MR09Kn3gAzOn+iaS+nw+xkgLF4azGUNBUGOk+fP9yxKv\nvOJ/PVaD0Nr4WGO1BNOyx0LnP7lefZmi114bH2vsejx40H+OFy+uTPbxunX+fVi9OnwuEq++Gl8O\nAACApkIGIQAUKmvHzLTssYsvzp4hVyvdkWOZTgcOhANAaZl3pWRfjoy4brtJcG3jRtelN8m8K7bD\nsSStWeOyxEIZa7HzIfnrMF58cfwzQ9l+o6Ou6cuaNTOXpdXnu/VWf6ZbWjbjm2+GxylJxx/vfz1W\ng9AYF5T0BUkLqSUYyh4bGAiff2vdvvsyRZOu0qHPSrseTztt5jnOmkUby7w8fNj9Ce3D+ef710u8\n853x5QAAAGgqZBACQKHSMgFjNc9CmU6vv549u64S9fmyimU6zZmTPfMudsyXLXNBLt/+r1o1PTiU\nyM28831eWl22k08OZ6zFzseqVeGMtW99q9CjPNP27f4subT6fBdeWHw24/h4egbhGWf4X4/VIJw7\n12U0xmoJFpslOzERP/+/+EU8UzTUWToZa7HX4xVXzFwnEfuep2VexjJPTzstvK4kffrT8eUxlcha\nroVMaAAAgCZGBiEAFKrUmme+TKesWYlSbXVHjmU6jY66YFqsE28s8y5L9uXgYDzz7vrrZ2YCLlvm\nthdz+HA8Yy10PoaG/LX/xselF190ASnfeFtawtOIJWnBAhe08mXJxa7V/Hp4hWQzWiu95S3hsba2\nSqec4l83dp0fPRq/PrLU7rv99nAAcHRUeuCBeAAqFHgbHZW+8AV3jHO1tLg6kZ/9bDiLNvR5se95\nLPMyrbnPjh3x6+onP8l2f6hE1nKtZEIDAAA0MQKEAFCMJBNwYMAFofr6pqarZpFkyA0NTQ8sFJKV\nmGTt+QJzSVZStQKEsUynpBPvhRf6j1tu5t3Y2FQgKcmE3LHDf8zvvju8/2nn44Yb3HTZ/M/bsGFq\nTL5txurhxc5HS0s4QJY0BvFJCxDefPPMAFCSJXfokDt2t9/uMg1XrJAuv9ztx6mn+o/3hg3hz5Kk\n008PNzFpbQ1fB2nX+YUX+q8PyY01CfgmY03q7O3Y4T/X27fH9+O55+LLFy6UXnrJP9abb555TsbH\npS9/OXz+58xx04/3759+7Fpb49/zJPPSd+2EPktyx+RXvwoHyScmXMfpYu8PhXxXi70XVmKbAAAA\nKFpBU4yNMXONMf9ojHnGGPOEMeZ+Y8zSyWXGGPNnk8ueNMY8nLPe2ybfu3NyGe3lANS/JIPskkvc\nYyk/XpOsxN5eFwjo7HSPfX3pWYmlZB+W27Zt4WXWTmVC+Y5bIZmQvnVj+582PfGNN/yf99JL4WPe\n2hqvh5fWqTcmFAScmAhPdw0F6qSpLMnTTnNZbffe6x5PO811vg0d7/374+N86ql4RlvoOijkOved\n44GBeK3AgQH/561YEd+Pk06KL1+71j/W9etdtptvPAcOuAxTnyNHXOZhfiC4tdVlfYaOaewaj10b\nbW3p9SKzdDEu5LtaC9sEAABA0YqpQXinpF+31r5D0n2TzyXpCkm/KekMa+0ZknKrm/+lpEettcsl\nXSrpHmMMWYsA6lu5a2WldWINKaQmYrXqeu3cGa+HtnNneN1KdIfu7Y2Pd86c8OeFgjUtLS5DLnRM\n0+rFZTExEc8Ci7nhBn/Nw1hX6VDAKfHKK+FagnPmxGtmZrnOd+4MTxWOXVeXXx6/platijci6ery\n12hMqxkaOs/GSN/4xszlExPSZZe514utwdnb6/6Elh1zjH8siVdfLf7+kPW7Wu1tAgAAoGgFBeus\ntYcl/TDnpUclJQV4rpb0fmvt6OR7n89530WSlk2+/jNjzAuSzpH0cGnDBoBZUqlaWaG6dmnrFFNn\nrpJ1vWLdf611y0Mq1R36Ix8J11+LdYaNZcj94Acza+Ulx/TZZ8P7OBsNF954w5/ptn9/eEpzKBiZ\nOP748LE7ciQ9a7XY6zzrddXS4uow5jcq6eiQHn7Y7Wesy/Oxx4a7Eceu1dC1MzERz5LbvDl8XcW+\n48n0XN+y++6T7rrLPx5JWro03AE8dH+oRNZyLWVCAwAANDFjM/xoMcZ8V9JLkr4kab+k6yRdOLn4\nJmvtvcaYEyQ9a62dn7Pe30m6z1r73bztXSXpquT5ggULTn7llVeKHhcAVJS102u3Jdra3I/Y2aqV\nZW24dlu1xnrXXVOZUPmMcdMoL700PP7cOnOJZEpv2lh9+5+MJyRUZ7C11dUZPHhw5rLOTvfnwAH/\nMb36atdJuB66r554or8e3qJF0gsvhM/jnXdKn/xkeLtjY/EsRN+5ip3bUq4rye3f1VdLjz0mnXWW\n9LWvufGlfZcnJlzgLn9ZkpnqW2/hQnfd+K6dJGPVF1w95hgXkAxdVzt2uPHm15JMgryhYzoxMb2B\nTa72dhdILPb+UIl7YK3eVwEAABqAMWaftbarkPcWM8U42fg1kpZLulZSu6QOSfOste+Wyxj8ujHm\njMm35/+N3vs3PGvt1621Xcmfzs7OYocFAJVXq7WyQrXbqjnW5ctnTnVMtLXFa/clgZ5i67Plrp+/\n/2n11WLbjGXI5TeukKaO6ZNPVjc42Noar08Y87GP+Y/3l74UP487dsS3e8cd4WXDwy4QtHKlm+a8\ncqV7PjwcXqeU62p42DVVue026fHH3ePpp7vXYzURkzqDvvO8e7db7lvv1lvj9QJD2Zlp19Xmzf5a\nkslxC9X2TLIo86fvdnS4bMgs94dSaqaGVGKbAAAAKFpRAUJjzOckXSDpfGvtm9balyQdlPQ3kmSt\n3StpQNJZk8tkjFmUs4luSXvLMXAAqLp6qpVV7bH297uMpPyAVWur++Ef68ZsrT9LLLc+W7FefTW+\nPBR0mDtXOuEEf123hQvD9fc6Olx9vkqIBUhizU1i7rnHf7xvvtlNMw2dx7R9/PnP/a/ndqrNrYmY\ndKoNnePkugrV2QtdV4V8XqgmYlqdwYMH/etdcEG8XmBoPxYujNfEXLeu+OOWe/wOH3bB0csuc4+H\nDrnrPOv9IWvN1JhKbBMAAABFKThAODkN+KOS/pu1NvcXwvclrZ58z1sk/Zakf5tc9veS1k4ue5ek\nEyVtLX3YADALZrNWVqyZgG9ZqWMttnlBkgXU1zc9C2j58vQsoEKyHYsdzzvfGV8ecvSoC1D09roM\nrORPX597PdQwY3TU1eeLCWX1lZIhlTVjMX86qzR1vK+/fqr5xZw5U1M9t2xJ38cFC/znKmtGa252\nWXu7G097e3p2WaGfV2x37OS741svLRPugQeKzzxMyy4sJBO4pUVas0b69rfdY3I9l3J/yNrJPfY9\nLmd3eAAAABStoCYlxpguSTdK2iXpIeP+0nbEWvvbkq6RdJcxZs3k2//CWrt98r//VNL3jDE7JY1K\n+n1rbaDNJQDUuKSjqK9WVtI1uBJijVEk/7L7788+1qyNWJIsoGJqzEnuvbHOwY8+6mr7FTOeyy+X\nrrwyXH/t5JNdACnf4sXu8Re/mP76f/yHC2bEjukZZ4RrGxojvfWtLjCX74QT/K/njtcXzGltTW8q\nEhJat63NHZck4CVNPVrr9jHm137N3/jiE59w++Gbvp1krMUalyRdfpP/npiIB0eTDNosn9ff77oY\n79o1c9nixfHvTtp3wLdMCl9XCxdKr73mv44LOW4hs3Evq1SDJwAAAJRFpiYlldbV1WVHRkZmexgA\nmlmo8L/vR27SNXTJkuKbMBQyjizNFPr6pB/9yI11166pgFBvr8tkCk3dq2TDgNCx+fGPpfe9L7ze\nkiXSc88V30yhu9vfWXjxYhc88gWAenvdvocMDUm/8ztTQU1rp7Ikh4el9743vO6v/Zr0/PMzXz/p\nJLd/IW1tMzPIYq+XwhgXHHv+ef/xvuOO+LlavNjtS37zk5NPln75S3+gs6PDTSnt7w832ym2gc3W\nra7GYezzQoG1JAM3dH3s3Fn+7LbQfWX9elcvMst+ZP3M5F5WTrXaiKTc92sAAIAaU0yTkoIyCAGg\nqaRluoQyhCqRITMw4Lbnm2KYBKlC0w8feyycCZbl84aG3PIsAYnYsfn3f4+vu2/fzGy3tPEMDLiA\nlM9zz4WDALt3x8dyzTXuc3PHMzjoD0Tme/FF/+uhcSYWLHDTTPMdf3w88zALa2cG+KSp413Iucqv\nfzg+7l7/L//FHwhdvNgFJX2Zh+vXu9fyxzM+Hj//pWTIDQyEz+fwcPbvQEzoviJlz2bM+pmVCJAV\nMuW73Mc0DRmNAAAA0xTdxRgA6kqxtesKaW7gq5WVtQlDmp07w3XvxsfDde3a26eaGxw96qZaHj06\nfTy+YxP7vLExt7xYacdm+/b4+qFptMl4fPvxzDPx4xbaZlpzj3vv9Qc5PvAB95kxWT/TFxyUXHCw\nEsGc2PHevl2aP9+/vL09vC/j4+Gad9a668B3fVxxRXi92PnPWrtQil87Y2NuebE1QWtVter+1VqD\np0rdrwEAAOoYGYQAGleWDJGsmS6VypA5dCj8Y9Xa8BTTI0fc/obGs3mzdN11M4/NxRfHP+/QoeL3\nIe3YnH9+8dtMxjMy4s88SzvW5Q4AjI66zsDVVs1AhrUumzEWPIt5+WX/68PDLtDtuz5CWZfJeELn\nP6nPWWztQkl68sn48m3bpK9+tbiaoGlZaaF71fr1LvvS59lnZyfzLovZbPDkU4sZjQAAALOMDEIA\njSlrhkjWTJdKZcjMmxfO6jHGNTFoy/u3nqS5wZw5/vVyswvzj82GDfHPmzfPBVk2bHCNJzZsSM+A\nSzs2Z5wRXt7SEh/Pbbf59+Mf/iE+pkrYu7f6n1lNxkinn559/Vh2YSgTNv/azrdhQ/g7/sEPTk0x\nPnJkapp0WobYq6/GP/Pv/97/matWZbvnJPeqwcHp6w0Ouu9p2n2lHjIWkynfvntVJRs8hdRaRiMA\nAEANIEAIoDEVkiHi09fn73wquddDmS6VypBZvjwcJGlrk770pZkBtJYW6YtfDO/H4cNu2qrv2Lz0\nUjxYc/iwNHeutHattHGje5w7N3w8pfRjesop0kMPzfzB3tHhAoCh8RgT3o/XXguPp1KOOy77urXU\nGCF2/kPnUSptH0LZh6FsxcSLL4brc+7aFa9dGPLOd8Y/8403wjU68xsGJcti95yk7qdvrPv3h4/5\n6KjU2ekyKFeudMHElSvd8+Hh+D5UW+6U744ON+6OjsKmfFdCrWU0AgAA1AAChAAaU9YMkbPPDm/T\nmPDyJEOmtXX6662thWXIhLKA+vvd+r7t9vZK3/iGvynEN74R/7xQduGcOdKiRTN/sBvj9u8zn5kZ\ntDl61NXgS6Zv5u9HIce0v98FH2+7TbrsMvd46JD0yU/Ga/eFAkuzkUX1m7+Zfd3OTv85nju3tDEV\nyxh3/vODhC0t7nqbOzd8zNMySWMWLfJnlx17bHy9WFZiaJy5tTR91+vll4fvHbFz0toaDq7G7jlp\ndUZPOCGceXfttfVTRy9pivLgg9Itt7jHHTvK3zG5EJXMaKyHjE4AAAAPAoQAGlPWDJFt28LZLNa6\n5T7GuIy6/ABBa6t7PZYhMzwczgJKMm/6+qZn3ixf7uqTDQ/7M4927YoHbGJZSb46hNZKZ54ZDmSM\njkrXX+/fjx/8IDyOiYmpY9rSIq1ZI3372+6xpUW6447wuqUIBXJK8ZOfZF/3ve/1n8fzzittTCGh\n67G1VfqTP5l57UxMuPN7+HA84JE1E2zNGn922Yc/nG17sTEmtTRD37tnnw1ntN56azyYF/rOxe45\nsTqjUvjYJN//YjMWZ1O1mqIUMo5KZDTG7uUAAAA1jgAhgMaUNUNkcND9UPSZMyecBWSty3zL/6E/\nMeF/PXe9tLplocyb11+P1+6LZVeFspKWLZNuvNG/3r33+l9P3HCDfz/WrQtnc42Px7O5Hnss/plZ\nlZLtFpJWuy7mhz/0v/6jH2XfZkwoANLSIv3Zn/mXffSjLnsuFjzJki1ljNTV5a7pm26SPvIR9/jU\nU/Hs01LMmRP/3p19tvTmm9JFF7kp8Bdd5KYWf/rT4ftKb6+7txR7z0mrM9rVVfz3nzp66cqd0Uhn\nZAAAUOcIEAJoTFkzRLJmHiZ1xEK1yWL1xwqplejLvInV9hsby5aV9F//a3idNKHabPv3p3dGDmXe\nxLrY1pqTT44vjwXlQsdnfNw1g/EpdRqkz9Gj4Sndo6Ouw2/+VOhEWlZmrLbhscdKp50mffazLhD9\n2c+658cdF67B2dISr08Z89RT8e/d7bdL8+dLf/d30jPPuMf58122a+i+8sAD2e45aXVGly8Pf/+p\no1eacmY0Zq17CwAAUCMIEAIor1qqv5QlQyRr5mGsjlhuzbN8hdZK9HUOTsuuSstKeuop12TkzDPd\n45NPSr/4RXybMaHAUej1RCyba+vW7OOptk99Kr48rSNvyPi4u7Zys9mOHnWBo6xiAduYX/0qfl3F\nxNa79lp/F9/rrguv19YWD7rGxvHqq+HvXVubC1KHam0uXuzPdlyyJNs9p9S6p7XSGbjZ0RkZAADU\nuYy/VgDAY3jYBXp273Y/iEZH3Q/YLVvcD+fZkGSInHNO4e/fsmXmfvT0xLOAYnXEkiw5n0K6Jg8M\nSOeeOxWw2LhRuvJK6eab45/Z0uLPBmttdbXk5s2b2uYjj7j6ahdc4N9eIWL1CWMeeCCcefP669nH\nU02tra5uXUzo+KRNd37xRemMM6auxz173PNCr+lyevPN8LK04GJoeZJl66vBODgYXy8WlGxt9V//\nbW2uU/Hf/I1/vSNH4lmU118v3XPP1Pn43vekb35z6j5X7D2nkLqnvm1lvVehMsjoBAAAdY4AIYDy\nyK2/NDY29UMpqb+0Y0f9/GBNsoAGBlyAoq/PZeMk47d25rKkjpgvmGGMWz4x4aYubt8urVjhuqWm\nZQ+9+91uaqMvm2nt2niAMBZ4CnUjjjUUSZM1W3RkxGXe+AKlsVqKtaS1Vdq3rzLb3rp1avp27veq\nlJqHWR1zTPYuxqHlsfVCgbq09SYmpLe9TXrppenjTWoFXn65C+ol96vc5fPnS6+9Ft72DTe4QGm5\n7nNJ3VNfcCmpexoKNnZ3u8/Mv69UogkP4pKMTt81RUYnAACoA/wNEkB5NFr9pVBtqlCtvGOPjdcR\nO3zYNXhYu9ZlAK5d657fcUc4sDYxIX3+8+HMs7SAXChQMTER3ubRo27apM/KlfHPy+rQoXAWZSxA\nNBtCgRdr49l1pTh4MFzbMeu07ixaW6Xjj6+PZgvWSh/72MzvQEvLVLdxX3fxlhbp/PPj2w6dj6z3\nuVIyz4aH/bUb6ZpbfZXqjAwAAFAlBAgBlEej1V/y1VKMdam87jqXJZIfmGltda+HMvZiHX7HxqSf\n/az8+5aWXRTqnPvTn5Z/LJILlNaLefP8r8+Z4zLPsgoFD0LTZCX3+qJF/hp0ixZlH0vI+LgLhtdD\noMMY6X/+z5lZhuPjrqt40l3ctzxtqngo+Jr1Ppe1liBdc6fUSu3bcndGBgAAqCIChADKo5HqL4Wy\nBDdvDmdJ7t4trV/v9jM3e2T5cunjHw9n7KVlyIWCroWIZSbGvPGG//WDB7OPJebAgfBxqLUgR6iW\n5KFD6V2MY979bv/rv/Eb8fXe+15/Ftz73pd9LDH//M/hTNnW1spkLsaEgt2trdLLL/vrGiZdinfv\n9i9/6aV4Zmbomsx6n8uaedZoWdtZhe7Xs5VFWc7OyAAAAFVEgBBAeTRKR81YVs4VV4SDIx0d7r2+\n7JHdu7OPZ+nS7OvGstJiqh2sGx+vjzqDUnic4+PS+9+ffbs/+Yn/9aeeiq/3wx/6s+BCWaClev75\ncKZsb284YFepmngnnBDOoOzo8K/T0SH9/OfxoP2iRTPH3NLiAv49PeW/z2XJPGu0rO0syKIEAAAo\nGwKEAMqjUeovxbJyDhxwtQR9ko7DvuyRBQuyj+f448NBybRjGgpmjY2Fg4SzcZ7SuhzXi698pfqf\n+eab/iy4UBZoInSe087/WWe577MvU/YrX6l+QGbdOv8955Zb4l21FyyIj3XNGrdPuds95RS37w88\nUJn7XLGZZ42UtZ0VWZQAAABlQxdjAOVTSkdNX2fgcgSrYtv1LUuycnxNM+bMCU8xNcZ1JPZt8/TT\ns4//1FPLn9FnbW1N6Q1letWbX/6y+p8Zy2iMiXW/jvnqV13A2tfl+6674h2OQ/UUOzrcct+6aV2s\nTz7ZPxbJZTQPDk7/zKQmaNp3MrTd5N4RWxZTzvscXXPj9+skizLUARoAAADTECAEUD7Dw2661+7d\n7sfZ974nffObLrOmu7vw9UZH3Q/ftPWKHU/udiX/svXrwx11Dx8O/5i3VvrBD1yzkvxtXnxx9n34\n539u/Glyr78+2yNAIYyRHn10KrvtnHOmB1+efDK+/vnnS/fdN/P1739fevFF6Y//eOayiy6S/vZv\nw9tMvpP5Y5Fcl+Jzz50ZINy4UXriifhYY9uV4stCyn2fS7K287fZ01NfWdulIIsSAACgbIytwR+e\nXV1ddmRkZLaHAaAY1rpsN182S1+fyyz0/WDNul4p4+ntdf8d+szBQX82U2uryyJ8882Zy445Rjr2\nWGn//pkBiUWLpBdeyBbo6++Xtm1r7CDhCSe4xhD1LgnQNLKNG6U/+iOX1ZefKfzJT0rf+U543WOP\nnTklurXVTeWNfecmJvzXvzFuPJdeOnNZ2n3l6qulT3yi+O1mVch9ztrqZ19XKnO7Wir1/w8AAIAG\nYYzZZ63tKuS91CAEUB5Za0ENDLjsF996Q0PZa0jFxjM05MYUWhYLxsWyC33deMfHXdAwa5OGjo7a\nqhdYCWQQ1o8nn3TfrblzpbVrXSBt7Vr3PK3WZqhe4s6d4anJ4+Ph705bmwsu+qTdjw4fDtf2jG03\nq7Tx3H67/5gWcv/L2jW31rr/ZtEotW8BAABqAAFCAOWRtaPmzp3hZgJjY255ucfT2hrvthqq3xbK\nZJLidf1i9eDSfsB2dWVvKFEvQsGhetPIWZ6JV15x03bzv7NHj7rGILHvXJbvh+SCPr6uwb294Tp7\nafejefPC3Yhj280qNp72dheg8x3TD3ygMh2+G6n7b5YO0AAAAJiBACGA8shaC+rQoXjQLVm+dau0\naZN7LOTHa2w84+PxDr8h1saDcpX4UT0y0jiBwJD582d7BOXRCOcpLdP1jTfiAf1162YGwjo6pCuv\nzD6mD384niE2MSFt2OCmDG/Y4J6n3Y+WL0/PPMty3wmJjefw4XCQdHTUZReWW6N1/82aRQkAAID/\nRJMSAOWRtaPmvHlTP8bzGeMCEqeeWnxh/9h4entd4HHv3pnrHX98vB5eKEiQ9oM0lJkYy1iUXDAm\nlu1Yieyianv7212dxXpXT0GJUEbfnDluGr3vumprc7U2Y1591QW88mvp3X13+Hue5uyzpb/+a3+t\nvIGB6RmNGze6YOS//PDp0YkAACAASURBVEv6/ciYcDficjcUid2PjjnGHbeQ7duL/7w0dP8FAABA\nHjIIAfgVmz2TtRbU8uXhWmCtrdKtt7ofq7nT4AYH06fBxcZz//3Sc8/51/vVr+L7GQrIpU2TDGVd\npa135pku4OLTKFNzf/u3Z3sE5dFVUO3f2RcLSh86FM+uPfPM+LZXrHDbX7NG+va33WNLS/r3PFRn\ns71dOuUU/7KJifB055UrpR/9KP1+NDHhuo9/5zvuMSkjUO7pt7H70ec+F193xYriPy+X715eSMZ3\nOTMoAQAAUPPIIAQwU9bsmaQWVDFdMfv7pcWL3bS2fG97m/TLX/obGyQNTGJZLqHxfOtb4eBarWXk\nPf989nXb2vz7GXq9kkLZY21t0u/+rnTTTdUdTyW8/e3uuqwVS5e6aaT5TjwxHCBPs2tX/Lq6/HL/\nev39LnNvcHBmF+Ok/EAo27ery59FfPHF4cD76KgLEMbuR5s3u+nLiUcecdfhn/95+vTbLNl1ofuR\ntdKXv+zfl46O8DEtROhefv/98QzL0DHPmkEJAACAmkcGIYDpaql4/dGjpTcw8dWmeuyxsg6zov7P\n/8m+7tVX++vBff7z1Z8OG7puxsak//iP6o6lUv7936v7eS0t0lVX+Zd9/vPhqemlBIezfneSDLq+\nvukZdMuXSw88MJVd197upjm3t09l+65e7b7rufejnTulG26If+b27eHadOPj04ODub7whfCxizVc\nKoRvPC0t0kMP+b+rDz+cvQN67F5+/vnu2IYyrFevro3/B6A+kX0KAEBdIoMQwHSFFK8PZc9kyTwc\nGJD27fMve/nl9AYmWbzxRrb16s2uXTMDrMkP/Vr6wbZ+/WyPoDyqHXSdmHA1M5cvnx4sX75cete7\npJtv9q8Xq7GZpr09HGAcG3O1B9es8S+PZRgPD7trMrkurXX797Ofues4P7N3YkJ6/fX4WGNTc6++\nOr6urzafFG+4VIr+fn/txqzBQSn9Xj4y4j8fpfw/ACh3/U4AAFA1BAgBTJe1eH1utsrY2FR9qyTr\nZMcOfwAl9nltbVM1wfIZ4xqcWBuf0uxbntZooZa89a3Z17333uJeny0vvDDbIyiPRYsKy2otpxtv\nnBnw3r1buuIK9/3xfa/SGuPEpP3AT8swTDLocu8hyb1j1y5370gCU7t2SWvXhrOI04Lcn/pU9nF2\ndEwfi5TecKlUSe3Gcin0Xp5/Pmhggqyy/j0AAADUBKYYA5iukOL1PoVknRT7eePj4Qya1lbp2GNd\nnayVK6V169zjqae6DAbJPfqWL1vm32aa2fhhEzo2syXWTCKrWqv7mNWhQ+FGHJXy+uv+79z+/eEs\nuLQpxqHMu9tvl958M75uluzc2L3jwIHit5e4887wsrPOiq978cXFN1yqNVnv5VnXA7L+PQAAANQE\nAoQApuvvdwG0/EBHWvZMknXik2Sd+OoSpX1eKEDY0iJdc024TtbEhMtk8HVAvuee8Fhjga7ZmJbb\n0VH9z4wJZZ6Fsryaybx5szPN2Gd8XFq4cOb3p6VFmjs3vs2nn/Z/H7/xDWn+/Pi6WbJzY/eOUo7n\n9u3hWmhf+1p83TvucMfhwQelW25xjzt2SEuWuOX1UGMt670863pAIX8PAAAANYsAIYDpjJE2bpz5\nw7ylxf96Ii3rpLPTn823d+9Ug4L8bJ2vfCX8eRMT8UyF2293Uy19HZB37ZK++EX/di+5xP/6bAnV\nZ2wktRYEzerQodrJhrRWet/7/LX73vOe+LpHjvi/V0ND0lveEl83LTPPJ3bvKEV3dzjDuLVV+od/\n8K/3gx+45aEGJ6HM5CRzuVYkjWGKzYTMuh5A9ikAAHXN2Br8V++uri47MjIy28MAmpO17sfu4OD0\n4Fprq2t+EKohlKyX1B5KtLW5H5qSf1lfn9umNLNW4N13ux/gBw/O/Lw5c9yjbxplZ6d00UXSXXeF\nM3tOPFF68cXpAZSWFjdt+dVX/evMhoULS5tmWQ9OPrkxAqHveY/0k5/M9igqxxjp2992zTN8GaMd\nHS5Iaky8Lmi+2L1j2bJ4Xcf29vBYli6dqmuYu83knmOMu8ddfbWrSXjWWS6zMDSNPm2sudutJWl1\nWsu9HppXPX4/AABocMaYfdbarkLeW1AGoTFmrjHmH40xzxhjnjDG3G+MWZr3nj80xlhjzIdyXnvb\n5Ht3GmOeNMZQ1RqodUkNoVDmXaiGUCzr5Prr0+sS+bJ1+vrCddTGx8O11A4flhYsiE/7yw8OSoV1\nRq22tOmgjaARgoNS40+fs9Z9t77/ff/y739fevbZ4rPrYveOv/iL8JTFtjbXqTl/eUeHe314OL0W\nWmur9PWvSz/+sXuMBQel+qyxFsqErNR6aF5knwIAUNeKmWJ8p6Rft9a+Q9J9k88lScaYLkmflvRo\n3jp/KelRa+1ySZdKuscYQ+dkoJaVUkOou9tft+v117PVJzz77PBnxTqxjo25oERMaCroxES47mEp\njTiy6iroH3tQC371q9keQeV1dEjXXutfds01Ux1MfXVBYwH72L0jyRbON3euq/t4+LB0223SZZe5\nx0OH3LJK1EKjxhoQF/ouJ/U7AQBAzSooWGetPSzphzkvPSrpypznd0r6rKS/ylv1IknLJrfxM2PM\nC5LOkfRwxvECqLRSawglWSfn5CQMF1qfcPdu9yN7dNRNLVy/PpxxkNaJ9Vvfii+POf986X/9r5mv\nX3KJ9Nd/nX27WWzfXt3PA2L+9/92mXI+O3e6DLxYdt05kYkEWe4dfX0uoL9mzfRllaqFRo01IJ3v\nuwwAAGpe1iYlV0j6J0kyxvyxpKestf+a+wZjzAmSWqy1+3Ne3iNpxj8hGmOuMsaMJH8O+uqNofHV\nQ1fIehM7pqFlhXSwjG13fFy66irpve91j+Pj6du89lp/1tG6deEGFqEsv0Qp01Z//OOZUw1bW6W/\n/dvs28yqEs0bas1xx832CJpPrEFFzL594Y7VsQYtWbPraq0TLx1+AQAA0KCKnu5rjLlG0nJJlxtj\nlkn6pKTQ34jzIzzeXx7W2q9L+nryvKuri8hQsxkedlPT8jPItmxx01VQvNgxleLHe8uWmct7etzr\ne/eG133sMenDH54awyOPSDfd5LqFhra5fr108cX+rKMDB8IBi7QA8sknuzqDWbzxxsxgx/j47NQn\nbG0NT6VuFKEppPUmLWhdSy66yHXrzQ32dXS4jJ9/+ZfwemnfqdC1mjW7LqlpFrofpXXiLXa9So0H\nAAAAqHFFdTE2xnxO0v8t6Txr7SvGmI/JBfYOT77lREmvSrrOWvvXxpg3JC1NsgiNMT+V9Hlr7cOx\nz6GLcZOh6135pR3TiQm3LNal2NfBUgp3OO7rk37xi/CYxsbcdm+/3U2bXbHCdUP97nfDnYqPOcZ1\nFT5wwN8ZOfZ53/qW9Md/HD9O9eC446TXXpvtUVTWkiUu8Fzv3vpW6eWXZ3sUhdm4Ufr933eBrh07\npNNOcwGuT33KZQaH9Pa6e0fIccdJb75Z/nt5rXXipcMvAAAA6kAxXYwLDhAaY66SdLFccNBbid0Y\n87CkG6y1900+3yRpj7X2z4wx75K0WVKPtTZaPIwAYZPZulU67zx/t9qODlfgmjo2xYkd0/Z29+PW\nV8Ovvd1lD4WO99atriupb9prElQMuewyt76vzuDFF/u32dEh3XOPdN11M7N1Lr5Y+sIXwp935pnS\n44+Hl9eLZJ8b2aJF0v796e+rdV1dUi39v6ulxT/tt61N+tKX/N+fD31Iuu++8DbPPVd66KHw8i9/\n2X1nfdl1NCkAAAAAqqqYAGFB86EmuxTfKOl4SQ8ZY54wxvxrymqS9KeSzjbG7JS0SdLvpwUH0YTo\nCll+sWNqTLjBx9iYazQQsnNnuP5Y2j823HOPv87gF74gLV06M/vGGBdYuPBC6amnpLVrXdBv7Vrp\nySelPXvin/fcc/Hl9aLRpxdLjVNvdPHi2R7BdH19/lqaPT3h4HosOCi5wHzsfn3ttdk7mFaiDi21\nbQEAAICCFNrFeESB+oF573t/3vMXJH0w08jQPOgKWX6xYxoLOFkrHToUXn7oUPYf2EeOzFx3bMwF\nCa+4Qrrxxplj+cxnpG3bXNZSEph85BHp1lvdtOSYk06SXngh21hrybx5/unXjSStI3W9mDvXZeeV\ne39C2bktLW6Z7zvd1iZdeaX7DuWXAzjzTOmZZ8KfF8o8bG///9u79yipqjtf4N9d1V3dDa2YJQ0a\nWqBfcgG9YxAnUTAuxUGdZWaWsKIram5QYsKIiCaSzPiIkwzkzsQoYwAHY1CcxDhq9DoTY2zWZTSR\nRhMf8RrRFejmZRsfgE+k37XvH786dlG19z5Vp+rU8/tZy1VW7d7nnKreVd3947d/P2DaNMkgTH5P\nAhIcfOqp0TqM2XYwDaMOLWvbEhERERFlLKsahIXCLcZVhjUI88/1mo4fL4Ez03tfKalNdtll5uPe\nfbdsFS4kW8ClttaezQgAd9wBXHlleNdVKJ/7HPDss8W+inBVyhbjRYuAZ56R4Fvy+0spoLExeJMb\nW6OaaFSCkh9/nD7m1e/cty89QFhbC/T3p8/xNDTIe8v1eRyPp9cTDdqkJdefAdnWS02utUpERERE\nVMHyvsWYKFReV8i2NsnyaGyU2/Z2doUMyvWarl0rf3ib1NTIH882rqCC3/UEZcvGGhqyHzcale7J\nlaAa/rGkUroYf+pTEmBPfX/V1krzDxdbcC0adXfqNdUZBeTxAwfSA4sjI/Y5nrPO8v88jkQkAP+T\nn8htLh2cu7qkZICpk/nOnTJus2ePBALnzZOs4nnz5P7DD0vmoOn59/S4j0lEREREVIUy2mJMFLop\nU6RuFbtC5o/tNQWkBpkpW6etbfRrTBoa7NsdXU1KwspUth13ZAR4881wzllold7BGACOPbYyAqEz\nZkiGbeq6jMeBX/3KPde0pReQtdzYaN5mXl8vY6Yu3+PHyxxTlm006t4GfcEFwOWXF+7z2KuZamtU\n1d1t3q6stWwh9j7LvLIKPT3AVVfZM4y9WqtsfkVERERE9AkGCKl0KJV93apKYtoml+sf5LbXtLNT\n/rDeuXO03lhbm3/GZkeHBB9Mf3j7dTG21TULS6XU7jNtH600fg1nysWrr9oz4Xp67FuF/d4btrqg\ng4PSCOSGG+S97B2/rQ1YtQq4+GL7MW3njEalzmAhP48zqUNr+nx0ZR7u3+/+BwtXrVUiIiIioirE\nACFRKShGMX2tR/+A1lqCBX6ZfnPmSPahqa7X2LHubLexY8012MaMAQ4dyv76/XR0VEZdu0IGVYsl\n6Nb1UqIU8MEH9ky4SET+CxIgbGyUQHFqlmBrKzB7tpzbC+x7tyefLJ8htkxhQLLoks8bicj7xpVF\nHIY5c+zX2toKNDfLtuHUz8evftX+etuCsYC8Rg0N4TwXIiIiIqIyxRqERIWkNbBlC7Bxo9x6QTpv\nm9zgoGS9DQ7K/XPP9Q/amY6Zyfl27pQ/xgcGRmt9+Z3Pq23Y3n54fbKODmDFCvd1xmLmx+vr3fOC\nmjUrnOMWWmNjsa8gfC0txb6CzNlq7dXUSFDOlgkXj9sDVn5B4G9+U4J6tbVSr7G2Vt6DTzwh79me\nHsnqHRiQ254e4LzzZNxUS3DTJnkfd3QcPnb88cWp++qqmZr8HFM/H9essddT9OvW3t4eznMhIiIi\nIipTzCAkKhRbluDKlf4F+m3b/FyZh0D+zwfYaxtqDdx8sznYoZQ0TDB59137uXLxxBPhHLfQxo8P\n3v22XLz+erGvIDNKARMnmutbTp4snXxvvVXeR6bxeFzej6mOOQb485/t5502zZzx+9xz7vdyb6+7\ntmsp1X21fa64thG/9Za8dm++mZ55eOyx5bOuiIiIiIhKADMIqfy5MuhK5ZiuLMFlyyQjyMQr0B8k\n83D+/ODny+T5vPyyXMvLL48GLGyZUGE1KXHZu7fw5wxDpTRbcfngg3COe+SR5sdt699jC5I1NLib\ne7hobT/u0JB9y2tDA7B8+ej2Wy/jt6cHuPpqe0dy773s1RJctEhuk6/BNVYMpuvxGpiYxGLyGpgy\nD5cvl/IFJmPGyOtHRERERESfYAYhlbcwaveFcUy/Yvo2AwPyR6+p/tbKlfKY6ZheYCDI+fy23nV1\nAWeeOdqoZMMG4JprSq+5TKXU7it20KYQjjwSeP/9/B/X1qTGtf0UsDfcGRqyX+frrwPr1wNvvGEe\ndwWs333XvnXZe8+mXvPIiLvGptfco9z5NTD53OdkC7Yp89AWzB0erozXhoiIiIgoj5QuRmaPj+bm\nZt3b21vsy6BSp7UEzkyF7dvbpaNotsGVMI4JSObfsmXmgMWYMRKYMwUtYjFg6tTReoHJ1zN+PPD2\n2+ZAhlIy11Sfy+98fX0SrDB1DdVaagaauhiXmtra8rhOP0ccUflbjH/0I8kEKxXt7ekB/ZoaoKlJ\nGvGYOks3NgIXXQQ88ID5fR6LyXq0/cw95hgJBGb7Pp8wQbbv5/PzqpQE/UwO67M8V2F0qyciIiIi\nslBKvaG1bs7ka7nFmMqXKyvPq6VXCscE/LNgbH8gejXLTNezb5892KC1PXvGdT6tga1bJYty+nRg\n3jwJbM6bJ/dXrSqfoFul/NEdRofnUnPPPdJ11sY1FpRtfUSjwLXXpo9HIsBNN9mbYvT3S2Mc2/jw\nsHur/ZVXmrfKLl3qfp8vXWqeV4xmI2FwNTBxPceg88Jk+1zds6fw10JERERElIIBQipffrWpMqml\nV4hjApIl0tKSXi/MyxCydfKNRu1bD11BE6XkuNmer64O2LFDtlh3dx9ev7C7G/jhD+3npHD4bYet\nBG+8Ya/BN3asZO6lBnS87Ll8i8eB730vPcA+NASsXu3etnrFFcHPO2mSNOnYvFm6827eLFlukya5\ng2DNzeZ5kycHv5ZS4zUwyfY5Bp0Xhly71RMRERERhYwBQipf7e32bJ1MaunZjunK9Atat8qVzbJ2\nrf15jIzYA0SupgeRiBw32/MNDMgW4507zTXPPvwws+dL+WMLEFeSSZPsa3JwEPjOd9KD3bW1wJe/\nHPycrqw8U3au1v7/QPDtb7uP69Lfb27S0dFhb0RSUyPjpdZsJAxBn2OpvDZhZacTEREREeUJm5RQ\n+TrtNPuYUu5xGy/Tz1S3qrVVxoPysllMdf1sIhF7DcKWFmD7dvO8kRHggguABQukccKLL8r2xyVL\n3NeolGQRlss24mpQW2sPnlWKK6+U/2xuvz296czICPDzn4dzPUG7cT/3nD3D0G+uLas3k8+5cqpr\nV07Xmk9edrrpvexlp5daoyciIiIiqipVkJpCFWvrVv9aetkKu26VKZvFdZ3xuNT9M12PX/bU978P\nzJgh9dQeeEBuZ8wAHnnEHgAZHgY2bQr89EpKLFbsK8gP25b3ShGN+tfh7O42Z7S+/bZ9q30xMi9z\n+V7195sf9/uce+SR8qlrV801+MLKTiciIiIiyhMGCKl8dXfbg0B1dcHrBRa6btWOHfaso5ER6WBr\nup5du9zH/eEPzXUEly61b1uOx4HXX8/t+ZSKpqZiX0F+VHp21ciIvF9t7+Vo1L1ejz46PUgYjUp9\nwjBeO1vg0es4HoRS9hqMrs+5WEwCbeVQ167aa/C56tDmmp1ORERERJQHDBBS+QozI6OQdav6+tx1\ny/r6zNczbpz7uB99ZM66eucd97xKCRCeckqxryA/Dh4s9hWEb9s2ewad7T3umTkzPWgXjZrrFubD\nNdekZwrGYsBTTwGzZ7vn2rIdvVqCJq7PuYEBYP9+c127np7SqmtX7TX4SrGrMhERERFREgYIqXxl\nkpGhNbBlC7Bxo9wWO0vFdD0NDe4upQ0N5nknnOB/riAqpd7dvfcW+wryo9hrthAOHLBn0fp55pn0\nQPjwMPCv/2qfk0sw5gc/kGDmunXA4sVy29cHnHoq8PWvu+e2tpqzHdva7Blkfh3QbdmVw8OSnVwq\nwuoQX05KqasyEREREVEKNimh8qUUsGEDcOaZhz8eicjje/fKlrZdu+QP0MFB+UO7s1P+UCu0PXvM\n17Nypfyxb2oMUlMDHHGE1OkyzYtE7PUEg6qUBiVf+UqxryA/XFtsK8V//3fwuQMD6UHUeFwy6Fxd\nvrU2v3eUknHTa15TIwHJuXPNTVWeeUaCYLb38jXXyH/Jx45G5fPK9Y8EnZ3pnx2trcAllwA33WSe\n52UflwrW4BNeNjgbkhARERFRiWEGIZUvrSWDx9Td9PLLw613FY8Dd9wBfPWrcusXpHPV37rpJgn4\nmbS2AjfeaJ534435Dw4ClbPV7fnni30F+XHSScW+gvB98EHwubb38siIvV5gfb25RqFSwMSJ9nqA\n9fWS6WZ7/3d3Sz1F29x/+idzMHPxYvdnki3zbNIk/+zjUsEafEREREREJY0BQipfXk0rU529nh6p\naxVGvauuLvljf+lSyfxZulTuu47Z1SXZP7ZaYZ//vHne5z9vnxfWlrww6rYVw7vvFvsK8uPDD4t9\nBZmJROw19vwcc4x7PGjQ2pZ5OTQkgbbjjz+8Hty0acDate5Mt74++/vfr16gaSt1pp9JpjqkHR32\n96urrmExsAYfEREREVFJY4CQyperplU06u426hdcs9UujMdlS3PqFsKhIeCss+wZfTt22LfuDg8D\nP/mJeeyuu+wBh7C2nR5xRDjHLbSgNe1KTaltL542zfx4R4cEe0w19iZOdB9zxQr3e9mVXefKoGtq\nsmesLVxozspbsMCe6dbSAixfbn//n3qqu16gqxtxkID/nDnB6hoWC2vwERERERGVLAYIqXy5snVG\nRuzBOr96V3v2SM2/efOAZcvkdvp0eXz9enugb3BQxk38OhWXEr8uxy6zZpkftwWVwlQpmZB+XXzD\ncNZZ5sfXrwfOP988dv756fX1ALl/6aX2gH0kIu+v++83j192mftabQHCmhoJQrky1kxZea5Mt0sv\ndb//77zTPnfNGvfcIDX4vGttbz/8fB0dpZuVV8gO8URERERElDGlSy04AaC5uVn39vYW+zKo1Gkt\ngYWensOzxWpq5A90wDzW3i5ZK6Y/TL1jdnenNxLo6JAMoXvusV/T5ZfLtsNU99zjX2csiDAaWITR\n+KQYpk6VLejlrqVFtpkX0sSJEihOXq9KSbZaT0+wY9qad8RiwKFDwMyZkmmbvPYiEcm8cwWtbe+B\nWEwC80rJ9t3ubnnvz5mTWVBK6/R5V1xhfn97Fi+WbGDTXMD+eeX6TMqE6XwMvBERERERVT2l1Bta\n6+ZMvpYZhFS+XJk+mzYFq3fl1Qq01TX8+GP3NY0bZ37cVSssF7bsKluWVyaOPDL43FJSKVuM33sv\nnOPaMvqiUWD//vRgttbBg4OAPZCttWTe7d6dHpiOx6Vun4srM3fr1uAZa6Z5tgxZjzeebWZirtl+\nzMojIiIiIqIcVcgePKp4tgwZr6aVLXvGNWbiVytw7Fj3dZ5wgvlxr1aYKTPxqKP8gyA2jz1mfnz7\n9mDHA4AZMySwUu5s3WTLjW095sr1Pihk3cO6OuDFFyXDcGAgfTwScV9PNGrOeK2rk/fb3Ln5u9Yl\nS2QbtS0TcskS93y/zysiIiIiIqIiYQYhlT5XTUDAnT2TbWaNX63Ao46yd2qNRqUrqomrVlgu9fne\nesv8eHc38NWvmsf8Ghf09QW/nlJSLt1//YwZE85xbUG3QjdFGRyUzDtbrUW/7e626x0YCFbXzyUS\nsddKvP9+e1ZmMmb7ERERERFRCWKAkEqb1sA558jWxsFB4OBBue3pAc49N/81/Roa3F1RZ850B1ZO\nPdV+bFsHz/37c7/uVPG4vVZaV5d7bqU09yi17r9BdXQU+wryw7TN3usovGSJvftvU5P7PekaO+20\n3K87mdbADTeYuwbfcEPpNRwiIiIiIiLKEAOEVNq6uqQ2WWo9ueFhYOdO/2BXtly1AmtqgG3b3PPv\nvFOCBFu2ABs3yq1f0OCkkwJdqq+gwYrXXsvvdRRLJTRaAYDmZtl+Ww5sWauPPOKuvxeJ2MfXrrW/\nJ6NRe4DQq0GYT97nkalGaRifR0SUu2x/JhMRERFVqQpJFaKK1d1tr00Wi+W/xphXK9DWGfmDD9zz\nf/Mb4Ec/kkYnsZhkO7a0SPADkGzI1LFf/Qp48MH8PYdc9fcX/pw1NeamIkceGXyrcLkE1fzMnw88\n/ri57p1fF+sjjpAOwal1L2trw/k+v/VW+jVFo8CECf7192zjgP092dQk68O0dsKoQVjozyMiys2e\nPeafu52d8plDRERERJ9gBiGVtvZ2e22ywcH81xjz6zR68snu+b/5jX079Pz5EkBIHuvulo7Dd9xh\nPt43vpHf55eJiRMLf05bx+Fc6gjmUtux0Gxb0x95RJ6H7T3gZ8UKWcs1NRIwq6mRtXzxxcGO51dj\n79e/NmfXnXWWZHT61d/LtvvvmjX2Ji7e50M+s4cK/XlEmWGGGJkUukQJERERUZljgJBK25w59tpk\nra3+DTeCsNUKnDxZaqXZMtNqaoD33jNvh+7uli2IpuBJTw9w4okS6LjwQml0cuGFcr+3N//Pz88F\nFxT+nGGwNXDJhC0QlkkTiiCuvlq2t0cio/91dEjzDtd74Nhj3cedNu3wOn3e7eTJ7nlNTeY6ex0d\n9vXvymYcHATWr3ef08X2nlywwP350NzsbnCUrWJ8HpGbXxMrql6FLlFCREREVOYy+mtXKVWvlHpU\nKbVdKfWSUuoJpdTUxNjdSqk/JR7/rVLqpKR5Y5RS9yuluhNzF4TzNKhsZJvp4ZfR59cBNN+ZJZEI\n8OST6UGSWAz41rfs2UwjI/YsueFhYMcOOfYZZwCnny63kQjw0ku5XW8QL7xQ+HOGIYzgahgZJ7EY\ncO21sgUuHh/9b9cuyXIBRt8DtbWSCVhbK++B5cvdx16+XALQQ0OyLXZoSO6vXu2ed+aZ5o7bmzbZ\n1/9557mP+eKLg7pcjgAAIABJREFU7nE/2WYXPvGEvH75zB7K9fOI8osZYuTilQQw8UoCEBEREdEn\nsqlB+GMAv9Zaa6XUVYn78wE8CuBrWuthpdT5AB4EcHxiznUABrTW7UqpFgDPKKWe1Fq/l8fnQOUi\naC0gv9pl+T6f37w5c6R+2/r1EvSYNUsyC9evt/9B6vpDVWvglVeA+vrRAOOGDcA110iwcPt29/PM\nt0r5o6m+PnidPVuDk1wCDkqZ52sNHDjgznI57jj5Om++1nKNfX3uc+7bl57VNzwMfPSRe96kScB/\n/If5PTd5sn39P/aY/ZizZrnPGZTt86GrS97Dpte1p0fGg9QLDPp5RPmXSYYYa0JWL5YEICIiIsqK\n0gH+4FVKzQbwH1rr9pTHxwN4A0CD1jqulNoGYJHW+rnE+IMAHtdab3Qdv7m5WfcWY2sljdI6v38A\nay3bvkyNBtrbZbtgPv/ADno+b153d3qjhY6O0XkjI1Lf7fnngdmzgVtuAe69F1i8ONj1RiLmoJSt\neUeYxo4FPv64sOcMw1/+JfD73xf7KkYdeaQ0DLE12jC95o2N0vTmX/7FvJbHjwfeftseuLQFJW2P\nezZsAC6/PLPn5YnHDw9yJ4vFJJgZ1hZtk3vukfej7flv2ABcdlnhrofyb+NG2VZ88GD6WGOjbEdf\ntKjQV0WlotC/dxARERGVIKXUG1rr5ky+Nuhfa1cD+KXh8eWQAKAX6ZgMILkQ0O7EY1TKwqjpVOha\nQEHP19VlrxXY3S3jDz8sf2CsXg08/bTc1tQAzzwT/HptGWuFDg4CxeliHIaxY4GVK81jra2FvRYA\n+OIXgzXa6OuzZ8Lt32//AzcScWe02ubV1EgdzGy5tt8/9VRhg4OAvG6u5++XfUmljxli5MKSAERE\nRERZyWaLMQBAKXU9gA4AS1IevxTAhQBOT5mS/Bea8bcxpdQ3AHzSrnXcuHHZXhblS3JNp+Hh0T++\nvJpOQf/F3asFNDCQPubVAvK2BZqyFl0ZjaaxTM5n2nq2fbs9WDM8LFsLv/Y18/hPfuL/OpQDW6OJ\ncnPcccB3v2se27mzsNcCAKedBtx1V/paBWQLuynLpbXVnpUHyPcqaOCtqUm2NqdmyiZfV7Zs2++9\na8x3ZrJLQ4M7g7KhIZzzUuF4TWNs7x02jSGWBCAiIiLKWFYBQqXUdQAWADhba30o6fGLANwMYJ7W\n+p2kKXsBTAWwL3F/CoDHU4+rtb4NwG3e/ebmZlYWL5awajr5ZXo0NkqWoqnuH2CvCWgbW7nSHBwE\n5HFbZskrr7ifx7/9m/9zLSS/raJBuLrR+rFtlS6GP/7RHljLRWOjeUvjihXArbean38kIll5XqON\n1PdQZ2f6Om5tlccfeyxYbUs/V10F3Hef+Zy5/PEciQBXXpn+eNCaoEF1dEigyLQGampknMqblyFm\ne+8wCESA/XOXiIiIiA6TcYAwkeX3JUhw8P2kxy8EsDLx+N6UaQ8BWApgUaJJyRlIyTykEhM0886P\nK9OjpQW48UZ71mI8LsHJbMZuuMF+LUpJNpfJ+++bH/eUWm3Mpibg3XfTX9NctiZ79eKCKKU/yP0a\ncQRVXy+v+TnnSEbtjBkSjIhEpBalSTwOnHqq/ZiuLBdXJhxgD+hGo+5g7aRJ7syafGb7hZWZ7DJn\njgSKTPVE29qYXVYpmCFGRERERJQXGQUIlVLNAG4FsBPAk0p+8R7QWn8WwH0A3gLwn2r0F/J5WusD\nAG4BcLdSqhtAHMBSrfW7+X0KlFdh1XRyZXqsXAlccom926j3/6Yxre1jtj8QtQa2bjUHOo86yv08\n6urc44X2hS8AW7akv6YDA/JYENFo8Osppe3Jxx0XTkfmxkbgxBNHX/OuLrl/ySXueXfeac6s89iy\nXDo65HtiCvq6goB+mZz9/fZz5jvbL6yOwi7MLqsezBAjIiIiIspZRgFCrXUvLPUDtda1pscTYx8D\nuCjYpVFRhFnTyZbpce+99qxFV321SMS+jXhkRIJ5pqBKXZ295uHMmf7PoZSyCONxYNu29I7KixYF\nDxA2NJi30JabL31Jgqf53ma8f78E11Iz4W691T3vhReCZeWddpr9a6JRYOrU0SxaT00NcPTRwDvv\nZF+DL4xsvx073LU9d+wIJ7jD7DIiIiIiIqKMZN2khCpc2Fk3pkwPV9ZiPG7PhPIL/Ni22bpqHvpl\ngU2a5B4vtEOHJNDjvRZPPw2sXQuccELwYx51lGyhLaVswCCGhqSr7plnHr5WYjHggguABx4IdtxD\nh9LX5PCw/5Zmpex1Nl1ZeVu3urNhr7kGWL788McjEeDmm+XxbGvwhVGHtJgdhZldRkRERERE5Ctg\n+0uqaF7WzebNwJo1cvvqq8DkybkfW2vJ6tq4UW61Hs1arEmJV3tZi7YsQr9gZVNT+nbZaPTwmoeD\ng5ItNzgo9++4w33Ms892jxfaQw+lB4CGhoA//CH4MT/7WQnaml67cur8Wlcna6uvD7j2WuD00+X2\n0CFpzhGUbQt26vpN9dhjksWWvOa6uyUrz9VspLtbAoomdXXA976XHswdHgZuv13eP6bvo6sGn1eH\n1MSrQ5otr46iCTsKExERERERFR0DhGTmZd0sWiS3+diSt2ePZFDNmwcsWya306cDe/dKFlVbmwQg\nGhvltr0dWLXKHViwBWtqa4HvfCc9uBiNSsaVrR7avn1weu01e/CkGMLoGDw4CGzYYH7tpk/P//nC\nsm2brLmZM4F16yRoum6d3O/tBX7xC/O8VavswT7Xlnet7eORCHDgQHogb2RktAafjSvDdmBAtjyn\nrgOvec/KlTI/+X3V0eHOBg6jDqnXUdiEHYWJiIiIiIiKjgFCKozkumapWXvnnivZidu2AUuXAp/5\njNy+8ops27RlT9XX27MEW1slgyo1Mysel4wrWwDEb1vte+/ZG5WEVdcsaAZlUGPHAosXm7PStm93\nz3UFcwvtvffca27BAsm2vPBC4Pjj5XZoCPiHf5BgderrHolIIKu11Zzt2tYmwTPTvKYm+9ryavDZ\nuDJsjz7afdyPPpLs39WrgYsukttt29zZwN75bO+rIHVIvY7C2WYzEhERERERUUEwQEiF4VfXbP16\n2Wa4erXU0Vu9Wu739bmzmdasMWdIrVplzxJ8553gz+PQIXtjFNc20VyEdVyb3bvle2LKSjt0yD3X\nVSsvyLxcAot79rjX3MMPS63GRx8F/vxnuT3hBMlo3bAhPZhVUwPcfbc927WzU8ZN8y65JHgNPq8u\nqOmcS5e6j9vbC8yYIVurH3hAbmfMkNfGdT5bBumGDcG+J95zyDabkYiIiIiIiAqCTUqoMLy6Zqbg\nWm2tbDlOzYQaGpLtwLYura2twMKFkgm2fj3w4ovArFnAkiXSGdnWxCSXbbljxtjHlAonmOcKAIVh\nYCD4axf0ta2vl3Omfo9ra4M3sBga8l9z+/ebO/WamuOMjEhm5auvmjvjAsD8+eZ5P/+5fX1kUoPP\n1o1340b3cdetk63N2XQj1lqepyn71nv+QQJ67ChMRERERERUsphBSIXhqmvW32/fJjk4CFx6qT1j\na+9ec4ZUb687sGarXegXrHBl0FVKoMO2hdoTRrbfF76QPj8SAf7mb4If85RT7Nme/f2jgbNkw8MS\nQNu1y1wv0Ovia6rR6WXJmubt3+9ubpJJDT7TOV21/aJR6Ubt6kZskkkX46DCqG1KREREREREOWOA\nkArDVUetsdE9d88ecx21446z15hbu9Z9zKOPNtdDmzDBPW/MmPTAicfVpKJcAiGxmH+3alugy9XA\nw88LL5gz7154wT3P1W33Bz9wz7UFQiMR+3NxdfF1df+tqwPGj7fXLgxag8+r7Wc6blOTvX5n0OcR\ntIsxERERERERlTQGCKkwXHXUrrvOPXfKFHOW4MMP2zOdDhxwH/Oqq8z10Natc3db/dSn3JmJX/yi\neeyii9zXU2hnnZUeBIrFgKee8t/SG3QbsS3oFo1KJqgp8273bnfm3e2325/Hs8+6A7O27MJ43J3R\nauvi68qSHRqSepm2TNigAWTX+2rNGvtW8aDPI2gXYyIiIiIiIipprEFIhWOrQRaPAzfdZJ93332S\nFZhaR+3qqyVIZAv0uBx7rGQhrlgBPP88MHs2cMstEnCxBWsiEWDmTPdxH3oou8eL5eKLgU2b0p9/\nNArcdZd77hFHAB9/nF4vsKXF3Y23oUHmpbIFZIHR4KApYFdfL8fs70+vQRmJSH2+WMwc7Kqvl+fh\n1SBMvpa2NlmTtrqXtmw/L0vWW6up8xYulP/yXYPP9r4C3NcT9Hmw4zAREREREVHFYYCQCsurQTZ3\n7uhjzzwjgSBTECgSSQ/UAHJ//357ppftcc/99wNXXjmaYfX007It+fbb7RmCIyMSVHSxZdf5XU8h\nRaPAuHES7Ny1S4Jov/sd8Pjjko02ezZwzz32+YsXS3ZaskhE6gjedpt9Xn+/+XHXazMyYg+gedls\nkYh8L1O1t9uDx14H7BtvHH0NBgclANbZKWvgnHPMY64ajJ2d/vNS138+mN5XQGbXE/R5EBERERER\nUcVQOqxOqDlobm7Wvb29xb4MKpS775agk01dnTnQM3asOSMtF5GIewvtokXSIbkE3zdpbM+ltlaC\nPaYMsfZ24I9/tNegA+RrUpt4RKPy/fjwQ/s8W7fdWEyy4HbtMmfzAfZrdXXUjcdHuyObztnXN9pc\nxJTRp3WwbL+g88JSKc+DiIiIiIiIsqKUekNr3ZzJ1zKDkArLFHR45RX3HFsdNb9aeUH41dc7dEiC\nU7ZrCsOpp0qWZapVq4CbbzY3TfEabZiej2n7LDDapfbHP5YAoek5RqPSNMZUL9AvWBuJmLMFtQa+\n//38ZvMBwNat9nGtZdzLustnRp8tm69YXNfjCgKW2vMgIiIiIiKi0DBASIWzZ096oKelBfiLv3DP\ns9W8q60NJ0joMnasBKe6u9Mz6MaMAT76KPtj2jLrPH/7t7Kduqdn9LG2Nqkj+O//br6Wpibp6nzw\nYPrxXDX/YjGp5VdXZw4QuuZ6mZ6mIGA0KuOHDpnnHTxorqPnBatcYzbd3fYahHV1Mm4LftnWamen\nZDtWgmp4jkRERERERJQRdjGmwvCywLq7JRBx8KDcdndLx1mXb37T3KX14osLcumHOfnk0a6xNTUS\naPK2u37rW+65tm68tsc969ZJZl88Pvrfzp3AeecBTzwhQR0vYzASkQDm2rX2TrQjI/ZMycFBafRh\nm+vq8Ds8LHX9TF2F1641Zzp652xvH81YW7RIbpMDgK4xm0y68WoNbNkiDU22bJH73lrt6Tl8rfb0\nAOeeWx7by/1Uw3MkIiIiIiKijDFASIXR1ZVetw6Q+wcOuOeecYZkkG3eLAGozZul9tyXvxz8eoIG\n6048UW6Tux17t5dcYs+wi0btWVkTJ7rP+eab5tetpwf42c8kyJocPNyxQwI8LS3p1+PV9WttNY+1\ntkoX4Fzm9vdLUHPxYrnt6wO+/nX7McPqjOt147Wds7kZmD4dmDcPWLZMbqdPBx5+GNi9274Fu6sr\n/9daaF1dlf8ciYiIiIiIKGMMEJYSUzZTsY6Z72vZscNet29kxB5Yq6+XgIVJ8pZbk1jM/PiYMcC3\nv23OdPPLAtyxYzTzamhIttQODcn9v/7rYK/T0BDQ0GAeq621Z94NDwM33WQe++IXpSuxKfNy0ybJ\ngjRlHnZ2yv93do4GAr0sybY2eXzTJvNxM+mMm+08T5D16DrnE09Ippwpg27ZMnuTllhMArL5vtZC\n6+7O7TkSERERERFRRWENwlIRRj2woMcM41r6+tyBEttYPC6BnenT06/Hr3mCK7D2mc8AU6dK8NGr\nAThlCvDOO+5jbtpkz7zascO+/XZkBNi71zz23nvu52/jF3hau9Zeu+/hh+V6k23fDjz3HDB5stw3\nZUl6r5PtuF1dwJlnjgaDN2wArrkGePJJ+ZogtQRzWY+2a3Vl0O3fb78mb2tyGNdaSJlsvyYiIiIi\nIqKqoXQJZrc0Nzfr3t7eYl9G4WgtAbCenvRGHO3tsp02k5pr+ThmGNcCAPfcI1tOTetNKWDCBGDf\nvsMDYpEI0NEh/2+6njFjgA8/tJ9z3Dhzc5P2djmPtzU3+Xxjx7objcydC7z0kr35hy0o6RpvbJT/\n9u9Pv9bx44G33w6WhXb66cBvf5v+uCtjE5Dg3gknZL8G4nHJ+DRlisZiEiSOZJm0HNZ63LhRMgVN\n38exY6Uxjun7UYz3ThjK6VqJiIiIiIgoEKXUG1rr5ky+lluMS0EY9cCCHjOs2mQdHfagVE0NcNVV\n6dly8bjUGbRdj1/H4LlzzdtLV66UDC/T+fyO+elPuxt4uLgag6xZY77WtWvtr5tfsG32bPPjK1a4\n511ySbA1sH69fRv54KCMZyus9ejKoBsasn8/XNuhy6muX65bvomIiIiIiKiiMEBYSLbaZJnUA8u2\nrlnQGmNh1SabM8fe3KKtDfjud83zbr7Zv3GITVOTZEKtXg1cdJHcbtsGfPCBPZDlZ/58e+OLCRPc\ncydMsDfMWLjQfK0LFthft+OPd5/vllvM6+b5593zXnop2Hp84QX3cf3GTcJcj64GJgsXmhvjeNuv\nC3mtYfG2X2fzHImIiIiIiKgisQZhobhqk/nVA7PV4HPVNQtaYyys2mRexlLqa9DaKhlrtmYbIyPS\nFdd2TFegNBoFZswYPd9Pfwr86Ef+tQttamqAadOkrt6ZZx4+FokA3/kOsHy5OfhYWwssXZr+PIeH\nJaNx797DXxvvWjs77efbsAF4+WXg7/4u/Xzr1wO9veY1N3cu8PTT9ud50kmSCWfiWo9+r+u4ce5x\nk2Ksx+QMurlzM18v5VjXT6nsniMRERERERFVJNYgLAS/el/btkkgyzTe1ib/X6hagt687u7DG25E\no7JNONfaZPG4BK9efBGYNQtYsgT42tck2GVjCwRGo/amIABwzDHmOnJ+tQtt54vFgEOHgJkzza+P\nFwCyfR937rTX5/Mapti+/9mez6uzaDpmS0t6g5Jkg4PAiSdmf9zx44G33rIfd8MG4PLL7eMmYdfK\n0zr7pinFulYiIiIiIiKiLLAGYanxq022dau9HtiqVcHqmgWtMaaUBHJS69tFo/J4LgGOPXskEHrt\ntcADD8jtjBn+3V1dtfZs24+jUeDAAfPrZmpMkQmtgTvvlO9HamByZEQy0VauNL/ml17qrs+XGlTy\nrrWnR77PpvN5Y7Z5u3aZx3bvtr+m0Sjwu9/Z187KlfJ9NB33wAH79yOTLdEmYdfK8zLoFi2S21yO\nx7p+REREREREVKa4xbgQvNpkAwPpY15tsrlzpR5YajbTvfdmNtfEqzGWTYaU1uZuw/G4PB40C0pr\n2c7pBcK8rZg9PcDPfuaeW1trzhSsr7d3m21qkixBU1Cupsa+FdQbN82rq5PMR9f34+BB82t+xRXu\n52h7TV31F11jrqBqJCL/mZ5DQ0Pw9VhXJ0Gxd95J7w7tzQ8iyDoulnK6ViIiIiIiIqIEBggLIdPa\nZKZ6YLnWNcu2xlgmnViD1CtzHbenxz3XlnnndZu98cb0OnIrVwIXX2ye59qWDLi7Dc+aJfUBbePt\n7ebXfNYs9zZq21b/kRF7cMk1Fo/bj+kay3U92r4fuWbQlVOtvHK6ViIiIiIiIiJwi3Fh+HVMdWVW\n5TI3iLA6sbqO6xc4Gjs2WPffIN2GlZJaerbzLVkS7PuxZIn7dW1rs3d4dnV/zvdYrusxSPdfIiIi\nIiIiIioqBggLIZfaZIWuaxZWJ1bXcf0a5Vx3nf35791rrmu4d6/9dVuzxh6sq6kB1q61ny8SCfb9\niESAJ59MP28sBjz1FLBpk/mYmzbZz+ca6+y0H9NvLNf1mM+6fkREREREREQUOnYxLqRcOqa65pZD\nJ1bXcf06/Pb1yTlTnyPgf62AfZ6rU7NpXvLzDvqam7o4e/UCg36Pwxjzk881R0RERERERER5l00X\nYwYIy92ePdL8I7nmW0uLZHP5dQfO5pheHblctoq6jvvTn0rtulSrVgHXX28+3pYtwNln2xuGbN5s\nrwMX1nMkIiIiIiIiIioBDBBWi7Cy/bxjh5EhZjpuPJ5e0y7Z8LC5Y+/GjcCyZdI5OFVjo2wl/spX\nCpN5SURERERERERUQrIJELKLcTkLq+MwEF4nVtNxV6xwz1mxArjttvTH/eolNjZKANWWXclus0RE\nREREREREbFJS1sLqOFxozz8fbNzrqJuaXRiNynbhG26Q7MrBQckyHByU++ee698YhYiIiIiIiIio\nSmQUIFRK1SulHlVKbVdKvaSUekIpNTUxNiFxf4dS6hWl1NykedYxyoOwOg4X2uzZwcaVAjZsGG3y\n4YlGgeXLpc6gK7uSiIiIiIiIiIgyq0GolKoHcBaAX2uttVLqKgB/o7Wer5S6G8BerfU/KqVOAfAL\nAG1a62HXmOt8rEGYoTBrEBbSyEiwGoSu59/UBHz4IfDxx+nzvPqEixblfOlERERERERERKUomxqE\nGWUQaq37tdaP69Fo4rMAWhP/fyGAdYmvew7A2wDmZjBGuVJK6um1tcmW4sZGuW1vl8fLITgISPDv\nF78wjz3yiDk4CLhrMO7fD/T3m+cNDJRPdiURERERERERUciCNim5GsAvlVJHA4horfclje0GMNk1\nlnowpdQ3AHzDuz9u3LiAl1WFpkwBXnut/LvxLlwogb0VK6Tm4OzZwC232IODwGgNxoGB9LFYzB4g\nVAo47bT8XDcRERERERERUZnLOkColLoeQAeAJQAaAKTuUU6OTLnGRr9I69sAfNKmtrm5mR0kshFG\nN16t7UFH11guolFzt2IbVw3GgQH7NWkNbN3K7sVERERERERERMgyQKiUug7AAgBna60PATiklIJS\nqikpU3AKpO7gAdtY3q6ewrFnD3DOOcCuXZKJNzgo3YI7O2XcNjZlSmGv0+tibKpBOH68dC4+eDB9\nXl2dBDcZICQiIiIiIiIiyqwGIfDJNuAvAfgrrfX7SUMPAVia+JpTABwDYEsGY5QNrYEtW4CNG+U2\ng+Yygc9zzjkSdBsclADb4KDcP/dcYP58+1hY12TjqsG4dm1ldHgmIiIiIiIiIgpZpl2MmwG8DmAn\ngI8SDw9orT+rlJoI4KcAWgAMArhSa/2bxDzrmAu7GKdwZfTlO2tvyxbg7LPNdf1qa+V2aCh9LBYD\nNm8uTlaeacszUBkdnomIiIiIiIiIAsimi3FGW4y11r2w1w98G8D8bMcoQ8kZfcPDo1lxXtZeLoEu\nU2DN1fgj4kg4jcWKt23XVoOxszM9sNraWl4dnomIiIiIiIiIQha0izEVSlcXsHv34VlwgNzfuVPG\ngwTlbFmJK1fat+bG4/ZtxKW4bbdSOjwTEREREREREYWIAcJS58roC5q158pKvPFGe+OPtjYJEu7c\nmT7W2jq6tbeUhNHhmYiIiIiIiIiogmTcpISKpL09/802XFmJu3ZJFqGp8UdnJ7Bpk32MmXlERERE\nRERERGWHGYSlbs4ce0Zf0Kw9v6zEgwfdW3O5bZeIiIiIiIiIqGIwQFjqlMp/s41MshJdW3O5bZeI\niIiIiIiIqGIobWs6UUTNzc26t7e32JdRWkwdh3PpXjx9ujkrsb09t87IRERERERERERUdEqpN7TW\nzRl9LQOEVcrUxdjLSpw8udhXR0REREREREREOcgmQMgtxtVqyhTWEiQiIiIiIiIiImYQEhERERER\nERERVZpsMggjYV8MERERERERERERlS4GCImIiIiIiIiIiKoYA4RERERERERERERVjAFCIiIiIiIi\nIiKiKsYAIRERERERERERURVjgJCIiIiIiIiIiKiKMUBIRERERERERERUxRggJCIiIiIiIiIiqmIM\nEBIREREREREREVUxBgiJiIiIiIiIiIiqmNJaF/sa0iilBgDsK/Z1VJhGAAeLfRFUlrh2KAiuGwqK\na4eC4tqhILhuKCiuHQqKa4eCCLpumrTWdZl8YUkGCCn/lFK9WuvmYl8HlR+uHQqC64aC4tqhoLh2\nKAiuGwqKa4eC4tqhIAqxbrjFmIiIiIiIiIiIqIoxQEhERERERERERFTFGCCsHrcV+wKobHHtUBBc\nNxQU1w4FxbVDQXDdUFBcOxQU1w4FEfq6YQ1CIiIiIiIiIiKiKsYMQiIiIiIiIiIioirGACERERER\nEREREVEVY4CQiIiIiIiIiIioijFAWOaUUvVKqUeVUtuVUi8ppZ5QSk1NjE1I3N+hlHpFKTU3aZ51\njKqDz9q5Wyn1p8Tjv1VKnZQ0b4xS6n6lVHdi7oJiPQcqDtfaSfqaryiltFLq/KTH+LlTxXw+c5RS\n6h8TY68opZ5Kmsd1U+V81s5spdQzSqk/KKVeU0p9K2kef14RlFKblFIvJ9bO097vNEqpDqXU1sTa\n+L1SakbSHOsYVQfTuvH7/Yc/rwiwf+Ykjd+c+B35hKTH+JlDrp9XdUqptYnPlm1KqZ8lzcnr2mGA\nsDL8GMA0rfVJAB5L3AeAfwbwrNa6A8BlAO5TStVkMEbVw7Z2HgUwM/H4DwA8mDTnOgADWut2AOcA\nuEMp9akCXjOVBtvagVKqGcDXATybMoefO2RbN1cDOBHACVrrEwB8KWkO1w0B9rVzF4D/rbX+DIA5\nAK5L+uWYP68IAC7UWv/PxNq5FcDdicfvBPBjrfXxkN91NiTNcY1RdbCtG+vvP+DPKxK2tQOl1CwA\nnwOwN2UOP3MIsK+dfwYQB3C81nomgBVJc/K6dhggLHNa636t9eN6tB31swBaE/9/IYB1ia97DsDb\nAOZmMEZVwLV2tNb/pbUeTnp8ilLK+7y4CKNrZxeA3wL428JdORWbz+cOIL8sXwtgIGUqP3eqmM+6\nWQHg21rrwcTXvpk0leumymXwmXNU4nYsgEEA7ybu8+cVQWv9ftLdcQDiSqkJAGYB8LIwHgbQopSa\n6horzBURiU78AAAEsklEQVRTKTCtmww+i/jzioxrB5AsMMj6uBKAt4bAzxzyWH5ejYX8g8P13meP\n93tyGGuH/6JRea4G8Eul1NEAIlrrfUljuwFMdo0V7CqpFF0N4JeGx5cDeFxrHU/cnwxgT9L4bnDt\nVLtP1o5S6u8AbNNa/04p9ckX8HOHDLyfV0cCaAJwgVJqYWJstdb6Aa4bskj+eXUZgP9USq2ErKOv\naa3fSozx5xUBAJRS/w7gzMTdcwEcB+DP3j+Gaq21UmovZH187BjbXehrp+IxrJtUyb//8OcVfcKy\ndr4H4Gda613JvyPD/Xm0uzBXTKXCsHbaABwAcKNS6mwAfQD+UWu9GSGsHQYIK4hS6noAHQCWAGhA\n0r9MeF+S9P+uMaoyKWsn+fFLIf8aenrKlOT1w7VTxZLXjlKqBcAVkG1+JvzcIQDGn1cxAA1a688p\npSYDeEYptQ3Am+C6oSSGn1crAKzQWj+olGoF8JRS6vda6z8lxvnziqC1/l+A1McFcAuAm8Dfk8mH\nYd38tTdm+d2Z64YApK8dpdQ/ATgFwN/bpqTc59qpUpafV60AXtVa/71S6i8A/N+kcip5XTvcYlwh\nlFLXAVgA4Dyt9SGt9YHE401JXzYFwF7XWKGul0pH6tpJevwiADcD+Cut9TtJU/YCmJp0n2unShnW\nzqkAPg3gNaXUbkiNlQ1KqSv4uUMey8+rg0hsj9Ba7wXQBWA21w0lS107SqnxAC7QWj8IAFrrnQB+\nB+C0xBT+vKLDaK3vhWRm9AJo9urDKUnnOQ6yPl53jFEV8tZNIkvQ+Lszf16RSdJnzlkA/geAXYnf\nkZsBdCqlzgM/c8gg5edVHMB9icf/H4BdAGYihLXDAGEFUEp9A1LQ/a9S9q0/BGBp4mtOAXAMgC0Z\njFGVsK0dpdSFAFYCODvxx3qy5LXTAuAMAP9VmCumUmFaO1rrn2utj9FaT9VaT4XU5lmstb4rMY2f\nO1XO8fPqfiS24CSaSPwlgJcTY1w3ZFs77wHoV0qdkfia8ZB/mHglMc6fV1VOKXWkUurTSfcvgGzV\negfAHwBcmhhaCGC31np34h9FjWMFu3AqKse6edfxcwzgz6uq51g739dafzrpd+ReAOdorX/NzxwC\nfH9ebYY0W4NSagqAFgB/CmPtqNEaq1SOEt1CXwewE8BHiYcHtNafVUpNBPBTyAIaBHCl1vo3iXnW\nMaoOPmtnCMBbkA8lzzyt9YFEodS7AZwM+deM67XWvyjgpVORudZOytc9BeCHWuvHEvf5uVPFfD5z\nxgO4B7I2AGCN1vrOxDyumyrns3bOBvAvkLI5tQDu1FrfnpjHn1dVTil1HKRoewNkDewDcJ3W+iWl\n1DQAGwEcDeBDAF/RWm9LzLOOUeWzrRsA++H4/Yc/r8j1mZPydbsBnK+1fiVxn585Vc7n51Ur5PeZ\nowGMAPiu1vr/JOblde0wQEhERERERERERFTFuMWYiIiIiIiIiIioijFASEREREREREREVMUYICQi\nIiIiIiIiIqpiDBASERERERERERFVMQYIiYiIiIiIiIiIqhgDhERERERERERERFWMAUIiIiIiIiIi\nIqIqxgAhERERERERERFRFfv/+LhrQGsi1k0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2e2bcfc5828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = '212'\n",
    "mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "\n",
    "plt.figure(figsize=(20, 6), dpi=80)\n",
    "\n",
    "for i, features in enumerate(Testing_Data_DS_2[ds]):\n",
    "    if features[1] > 1000:\n",
    "        continue\n",
    "    if Testing_Data_Label_DS_2[ds][i] in N:\n",
    "        color = mark[0]\n",
    "        plt.plot(features[0], features[1], color)\n",
    "    elif Testing_Data_Label_DS_2[ds][i] in SVEB:\n",
    "        color = mark[1]\n",
    "        plt.plot(features[0], features[1], color)\n",
    "    else:\n",
    "        continue\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 N Median   : {287.0,15.1082197986}\n",
      "100 N Mean     : {287.185234899,15.1082197986}\n",
      "100 S Median   : {215.0,14.6038600128}\n",
      "100 S Mean     : {214.0,14.6038600128}\n",
      "100 ALL Median : {287.0,17.5648608582}\n",
      "100 ALL Mean   : {286.079330101,17.5648608582}\n",
      "\n",
      "103 N Median   : {313.0,16.6532988625}\n",
      "103 N Mean     : {311.875901876,16.6532988625}\n",
      "103 S Median   : {270.0,8.0}\n",
      "103 S Mean     : {270.0,8.0}\n",
      "103 ALL Median : {313.0,16.6976360499}\n",
      "103 ALL Mean   : {311.835655935,16.6976360499}"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "105 N Median   : {253.0,19.3999125999}\n",
      "105 N Mean     : {254.143423138,19.3999125999}\n",
      "105 S Median   : {nan,nan}\n",
      "105 S Mean     : {nan,nan}\n",
      "105 ALL Median : {253.0,23.2997979869}\n",
      "105 ALL Mean   : {252.635797665,23.2997979869}\n",
      "\n",
      "111 N Median   : {307.0,13.7677803978}\n",
      "111 N Mean     : {305.982083923,13.7677803978}\n",
      "111 S Median   : {nan,nan}\n",
      "111 S Mean     : {nan,nan}\n",
      "111 ALL Median : {307.0,13.8072149625}\n",
      "111 ALL Mean   : {305.958529689,13.8072149625}\n",
      "\n",
      "113 N Median   : {365.0,34.1317664088}\n",
      "113 N Mean     : {362.883538634,34.1317664088}\n",
      "113 S Median   : {180.0,7.475887164}\n",
      "113 S Mean     : {180.666666667,7.475887164}\n",
      "113 ALL Median : {365.0,35.6659853182}\n",
      "113 ALL Mean   : {362.2734375,35.6659853182}\n",
      "\n",
      "117 N Median   : {425.0,14.5780910044}\n",
      "117 N Mean     : {423.690398432,14.5780910044}\n",
      "117 S Median   : {211.0,0.0}\n",
      "117 S Mean     : {211.0,0.0}\n",
      "117 ALL Median : {425.0,15.5528435992}\n",
      "117 ALL Mean   : {423.55156658,15.5528435992}\n",
      "\n",
      "121 N Median   : {359.0,29.8971595273}\n",
      "121 N Mean     : {349.120559742,29.8971595273}\n",
      "121 S Median   : {252.0,0.0}\n",
      "121 S Mean     : {252.0,0.0}\n",
      "121 ALL Median : {359.0,30.1487340126}\n",
      "121 ALL Mean   : {348.991397849,30.1487340126}\n",
      "\n",
      "123 N Median   : {431.5,42.2967171621}\n",
      "123 N Mean     : {428.714285714,42.2967171621}\n",
      "123 S Median   : {nan,nan}\n",
      "123 S Mean     : {nan,nan}\n",
      "123 ALL Median : {431.0,43.5457095106}\n",
      "123 ALL Mean   : {428.245544554,43.5457095106}\n",
      "\n",
      "200 N Median   : {267.0,48.0249525484}\n",
      "200 N Mean     : {275.237794371,48.0249525484}\n",
      "200 S Median   : {211.5,13.9018783703}\n",
      "200 S Mean     : {211.266666667,13.9018783703}\n",
      "200 ALL Median : {241.0,54.7631344358}\n",
      "200 ALL Mean   : {249.877983064,54.7631344358}\n",
      "\n",
      "202 N Median   : {328.0,101.220217093}\n",
      "202 N Mean     : {308.20845481,101.220217093}\n",
      "202 S Median   : {176.0,22.8860201292}\n",
      "202 S Mean     : {173.709090909,22.8860201292}\n",
      "202 ALL Median : {319.0,102.128762216}\n",
      "202 ALL Mean   : {304.263478669,102.128762216}\n",
      "\n",
      "210 N Median   : {250.0,34.6276945397}\n",
      "210 N Mean     : {252.446465482,34.6276945397}\n",
      "210 S Median   : {151.5,18.9727947901}\n",
      "210 S Mean     : {151.818181818,18.9727947901}\n",
      "210 ALL Median : {247.0,43.2694118791}\n",
      "210 ALL Mean   : {245.375283447,43.2694118791}\n",
      "\n",
      "212 N Median   : {236.0,14.8619173171}\n",
      "212 N Mean     : {236.50273224,14.8619173171}\n",
      "212 S Median   : {nan,nan}\n",
      "212 S Mean     : {nan,nan}\n",
      "212 ALL Median : {236.0,14.8619173171}\n",
      "212 ALL Mean   : {236.50273224,14.8619173171}\n",
      "\n",
      "213 N Median   : {200.0,9.5598876285}\n",
      "213 N Mean     : {201.415466262,9.5598876285}\n",
      "213 S Median   : {151.5,10.4790850979}\n",
      "213 S Mean     : {152.785714286,10.4790850979}\n",
      "213 ALL Median : {200.0,11.1405003969}\n",
      "213 ALL Mean   : {199.963669951,11.1405003969}\n",
      "\n",
      "214 N Median   : {290.0,50.0702917243}\n",
      "214 N Mean     : {302.464232116,50.0702917243}\n",
      "214 S Median   : {nan,nan}\n",
      "214 S Mean     : {nan,nan}\n",
      "214 ALL Median : {285.0,64.2196172729}\n",
      "214 ALL Mean   : {287.437112489,64.2196172729}\n",
      "\n",
      "219 N Median   : {291.0,79.8620582221}\n",
      "219 N Mean     : {304.262626263,79.8620582221}\n",
      "219 S Median   : {278.0,17.4660019607}\n",
      "219 S Mean     : {270.714285714,17.4660019607}\n",
      "219 ALL Median : {289.0,80.2858263216}\n",
      "219 ALL Mean   : {301.273826127,80.2858263216}\n",
      "\n",
      "221 N Median   : {267.0,63.444870327}\n",
      "221 N Mean     : {286.401182849,63.444870327}\n",
      "221 S Median   : {nan,nan}\n",
      "221 S Mean     : {nan,nan}\n",
      "221 ALL Median : {256.0,72.064456983}\n",
      "221 ALL Mean   : {267.756701031,72.064456983}\n",
      "\n",
      "222 N Median   : {281.0,75.4374064642}\n",
      "222 N Mean     : {269.741409692,75.4374064642}\n",
      "222 S Median   : {170.0,24.4987916505}\n",
      "222 S Mean     : {175.325358852,24.4987916505}\n",
      "222 ALL Median : {274.0,77.1350494442}\n",
      "222 ALL Mean   : {261.781363453,77.1350494442}\n",
      "\n",
      "228 N Median   : {323.0,51.4938037319}\n",
      "228 N Mean     : {338.675563464,51.4938037319}\n",
      "228 S Median   : {254.0,13.7194104182}\n",
      "228 S Mean     : {250.333333333,13.7194104182}\n",
      "228 ALL Median : {314.0,67.5818167004}\n",
      "228 ALL Mean   : {316.514870795,67.5818167004}\n",
      "\n",
      "231 N Median   : {352.0,115.195010211}\n",
      "231 N Mean     : {414.127795527,115.195010211}\n",
      "231 S Median   : {455.0,0.0}\n",
      "231 S Mean     : {455.0,0.0}\n",
      "231 ALL Median : {352.0,115.357925078}\n",
      "231 ALL Mean   : {413.878826531,115.357925078}\n",
      "\n",
      "232 N Median   : {664.0,146.288186174}\n",
      "232 N Mean     : {655.78028169,146.288186174}\n",
      "232 S Median   : {263.0,10.372833733}\n",
      "232 S Mean     : {261.839971035,10.372833733}\n",
      "232 ALL Median : {266.0,172.357945839}\n",
      "232 ALL Mean   : {342.398041475,172.357945839}\n",
      "\n",
      "233 N Median   : {216.0,31.8066377383}\n",
      "233 N Mean     : {232.688370004,31.8066377383}\n",
      "233 S Median   : {152.0,12.4375993484}\n",
      "233 S Mean     : {154.142857143,12.4375993484}\n",
      "233 ALL Median : {212.0,45.5643269207}\n",
      "233 ALL Mean   : {211.121300813,45.5643269207}\n",
      "\n",
      "234 N Median   : {237.0,7.18054203495}\n",
      "234 N Mean     : {237.101186064,7.18054203495}\n",
      "234 S Median   : {179.0,29.1068720408}\n",
      "234 S Mean     : {184.1,29.1068720408}\n",
      "234 ALL Median : {237.0,11.0228457054}\n",
      "234 ALL Mean   : {236.05997819,11.0228457054}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for ds in DS2:\n",
    "    NNN = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    SSS = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    ALL = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    for idx, label in enumerate(Testing_Data_Label_DS_2[ds]):\n",
    "        if Testing_Data_DS_2[ds][idx][1] > 1000:\n",
    "            continue\n",
    "        ALL['preRR'].append(Testing_Data_DS_2[ds][idx][1])\n",
    "        ALL['skewness'].append(Testing_Data_DS_2[ds][idx][2])\n",
    "        ALL['kurtosis'].append(Testing_Data_DS_2[ds][idx][3])\n",
    "        if label == 'N':\n",
    "            NNN['preRR'].append(Testing_Data_DS_2[ds][idx][1])\n",
    "            NNN['skewness'].append(Testing_Data_DS_2[ds][idx][2])\n",
    "            NNN['kurtosis'].append(Testing_Data_DS_2[ds][idx][3])\n",
    "        if label == 'S':\n",
    "            SSS['preRR'].append(Testing_Data_DS_2[ds][idx][1])\n",
    "            SSS['skewness'].append(Testing_Data_DS_2[ds][idx][2])\n",
    "            SSS['kurtosis'].append(Testing_Data_DS_2[ds][idx][3])\n",
    "    print(ds + ' N Median   ' + ': {' + str(np.median(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' N Mean     ' + ': {' + str(np.mean(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' S Median   ' + ': {' + str(np.median(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' S Mean     ' + ': {' + str(np.mean(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' ALL Median ' + ': {' + str(np.median(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print(ds + ' ALL Mean   ' + ': {' + str(np.mean(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing SUP Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1175,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ann', 'annIdx', 'beat', 'cA7', 'cD1', 'cD2', 'cD3', 'cD4', 'cD5', 'cD6', 'cD7', \n",
    "           'kurtosis', 'postRR', 'preRR', 'skewness', 'beatValues', 'beatIndex']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "SUP_Data_Label_DS_2 = {}\n",
    "SUP_Data_DS_2 = {}\n",
    "SUP_Data_Label_2 = []\n",
    "SUP_Data_2 = []\n",
    "\n",
    "for ds in SUP: \n",
    "    SUP_Data_Label_DS_2[ds] = []\n",
    "    SUP_Data_DS_2[ds] = []\n",
    "    dsLength = len(SUP_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if SUP_Hbs_lead0[ds]['ann'][i] in Non_beat_anns:\n",
    "            continue\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            SUP_Data_Label_2.append('N')\n",
    "            SUP_Data_Label_DS_2[ds].append('N')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            SUP_Data_Label_2.append('S')\n",
    "            SUP_Data_Label_DS_2[ds].append('S')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            SUP_Data_Label_2.append('V')\n",
    "            SUP_Data_Label_DS_2[ds].append('V')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            SUP_Data_Label_2.append('F')\n",
    "            SUP_Data_Label_DS_2[ds].append('F')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            SUP_Data_Label_2.append('Q')\n",
    "            SUP_Data_Label_DS_2[ds].append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 逐个计算feature\n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(SUP_Hbs_lead0[ds][column][i]) == list:\n",
    "                features.extend(SUP_Hbs_lead0[ds][column][i])\n",
    "            else:\n",
    "                features.append(SUP_Hbs_lead0[ds][column][i])\n",
    "        SUP_Data_2.append(features)\n",
    "        SUP_Data_DS_2[ds].append(features)\n",
    "SUP_Data_2 = preprocessing.scale(SUP_Data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check distribution over features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ds = '860'\n",
    "mark = ['or', 'ob', 'og', 'ok', '^r', '+r', 'sr', 'dr', '<r', 'pr']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "\n",
    "plt.figure(figsize=(20, 6), dpi=80)\n",
    "\n",
    "for i, features in enumerate(SUP_Data_DS_2[ds]):\n",
    "    if features[1] > 1000:\n",
    "        continue\n",
    "    if SUP_Data_Label_DS_2[ds][i] in VEB:\n",
    "        color = mark[0]\n",
    "        plt.plot(features[2], features[3], color)\n",
    "    elif SUP_Data_Label_DS_2[ds][i] in SVEB:\n",
    "        color = mark[1]\n",
    "        plt.plot(features[2], features[3], color)\n",
    "    else:\n",
    "        continue\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1176,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851 N Median   : {251.0,36.9731605041}\n",
      "851 N Mean     : {258.230733733,36.9731605041}\n",
      "851 S Median   : {197.0,31.2697281478}\n",
      "851 S Mean     : {198.78125,31.2697281478}\n",
      "851 ALL Median : {246.0,45.6349109693}\n",
      "851 ALL Mean   : {244.581333333,45.6349109693}\n",
      "\n",
      "852 N Median   : {246.0,30.5886829218}\n",
      "852 N Mean     : {251.371783877,30.5886829218}\n",
      "852 S Median   : {159.0,28.6199694001}\n",
      "852 S Mean     : {169.320872274,28.6199694001}\n",
      "852 ALL Median : {243.0,40.5396502715}\n",
      "852 ALL Mean   : {241.287377911,40.5396502715}\n",
      "\n",
      "853 N Median   : {290.0,23.7456925908}\n",
      "853 N Mean     : {292.880703422,23.7456925908}\n",
      "853 S Median   : {220.0,19.2067967571}\n",
      "853 S Mean     : {210.875,19.2067967571}\n",
      "853 ALL Median : {290.0,31.7684623803}\n",
      "853 ALL Mean   : {288.128815081,31.7684623803}\n",
      "\n",
      "854 N Median   : {260.0,36.4243768429}\n",
      "854 N Mean     : {261.092841163,36.4243768429}\n",
      "854 S Median   : {182.0,21.8283109901}\n",
      "854 S Mean     : {183.530434783,21.8283109901}\n",
      "854 ALL Median : {235.0,48.4215074199}\n",
      "854 ALL Mean   : {235.223443223,48.4215074199}\n",
      "\n",
      "855 N Median   : {263.0,50.5939251739}\n",
      "855 N Mean     : {272.839074803,50.5939251739}\n",
      "855 S Median   : {203.0,27.2782601299}\n",
      "855 S Mean     : {197.140969163,27.2782601299}\n",
      "855 ALL Median : {257.0,61.9786197763}\n",
      "855 ALL Mean   : {253.217665615,61.9786197763}\n",
      "\n",
      "856 N Median   : {226.0,10.0569597218}\n",
      "856 N Mean     : {226.294054824,10.0569597218}\n",
      "856 S Median   : {164.5,12.8482056681}\n",
      "856 S Mean     : {166.916666667,12.8482056681}\n",
      "856 ALL Median : {226.0,13.1311671513}\n",
      "856 ALL Mean   : {225.320350877,13.1311671513}\n",
      "\n",
      "857 N Median   : {257.0,25.6371708579}\n",
      "857 N Mean     : {254.373905794,25.6371708579}\n",
      "857 S Median   : {159.0,29.7116898584}\n",
      "857 S Mean     : {171.162162162,29.7116898584}\n",
      "857 ALL Median : {256.0,33.0220680242}\n",
      "857 ALL Mean   : {248.832945736,33.0220680242}\n",
      "\n",
      "858 N Median   : {296.0,11.6118459924}\n",
      "858 N Mean     : {295.581449008,11.6118459924}\n",
      "858 S Median   : {134.0,20.4740689654}\n",
      "858 S Mean     : {142.25,20.4740689654}\n",
      "858 ALL Median : {296.0,15.9311083114}\n",
      "858 ALL Mean   : {294.854453627,15.9311083114}\n",
      "\n",
      "859 N Median   : {184.0,26.9429993576}\n",
      "859 N Mean     : {186.656905158,26.9429993576}\n",
      "859 S Median   : {153.0,16.6317466566}\n",
      "859 S Mean     : {152.608695652,16.6317466566}\n",
      "859 ALL Median : {178.0,28.6712705831}\n",
      "859 ALL Mean   : {181.514697569,28.6712705831}\n",
      "\n",
      "860 N Median   : {282.0,56.9214559009}\n",
      "860 N Mean     : {313.88576555,56.9214559009}\n",
      "860 S Median   : {204.0,28.7104625083}\n",
      "860 S Mean     : {207.058823529,28.7104625083}\n",
      "860 ALL Median : {271.0,86.4485843713}\n",
      "860 ALL Mean   : {265.840993789,86.4485843713}\n",
      "\n",
      "861 N Median   : {277.0,50.0643757954}\n",
      "861 N Mean     : {284.830752803,50.0643757954}\n",
      "861 S Median   : {185.0,26.9678685443}\n",
      "861 S Mean     : {182.312829525,26.9678685443}\n",
      "861 ALL Median : {259.0,63.4781938072}\n",
      "861 ALL Mean   : {259.944129555,63.4781938072}\n",
      "\n",
      "862 N Median   : {285.0,48.9005034745}\n",
      "862 N Mean     : {295.790806754,48.9005034745}\n",
      "862 S Median   : {229.0,24.2173344929}\n",
      "862 S Mean     : {231.538461538,24.2173344929}\n",
      "862 ALL Median : {285.0,50.1855877599}\n",
      "862 ALL Mean   : {293.794602013,50.1855877599}\n",
      "\n",
      "863 N Median   : {210.0,25.6192664008}\n",
      "863 N Mean     : {218.71484375,25.6192664008}\n",
      "863 S Median   : {157.0,11.2826435913}\n",
      "863 S Mean     : {157.570093458,11.2826435913}\n",
      "863 ALL Median : {207.0,37.1992794173}\n",
      "863 ALL Mean   : {205.747597694,37.1992794173}\n",
      "\n",
      "864 N Median   : {346.0,14.0980952333}\n",
      "864 N Mean     : {348.377726751,14.0980952333}\n",
      "864 S Median   : {187.0,42.3437980101}\n",
      "864 S Mean     : {196.052631579,42.3437980101}\n",
      "864 ALL Median : {346.0,37.2402738296}\n",
      "864 ALL Mean   : {339.227152668,37.2402738296}\n",
      "\n",
      "865 N Median   : {284.5,46.2201486957}\n",
      "865 N Mean     : {292.82,46.2201486957}\n",
      "865 S Median   : {151.0,9.56537993619}\n",
      "865 S Mean     : {151.97249725,9.56537993619}\n",
      "865 ALL Median : {159.0,72.6405122114}\n",
      "865 ALL Mean   : {203.228236784,72.6405122114}\n",
      "\n",
      "866 N Median   : {282.0,61.9033756123}\n",
      "866 N Mean     : {261.54,61.9033756123}\n",
      "866 S Median   : {179.0,25.2918027068}\n",
      "866 S Mean     : {166.718562874,25.2918027068}\n",
      "866 ALL Median : {262.0,67.0744323825}\n",
      "866 ALL Mean   : {241.123544874,67.0744323825}\n",
      "\n",
      "867 N Median   : {181.0,71.7796321567}\n",
      "867 N Mean     : {217.22074659,71.7796321567}\n",
      "867 S Median   : {173.0,31.6259770149}\n",
      "867 S Mean     : {177.941176471,31.6259770149}\n",
      "867 ALL Median : {176.0,70.4486249456}\n",
      "867 ALL Mean   : {214.208875542,70.4486249456}\n",
      "\n",
      "868 N Median   : {198.0,28.7858908044}\n",
      "868 N Mean     : {201.825626959,28.7858908044}\n",
      "868 S Median   : {154.0,10.2495668343}\n",
      "868 S Mean     : {154.625550661,10.2495668343}\n",
      "868 ALL Median : {195.0,32.5942642775}\n",
      "868 ALL Mean   : {191.999102871,32.5942642775}\n",
      "\n",
      "869 N Median   : {337.0,34.5628961128}\n",
      "869 N Mean     : {334.95282392,34.5628961128}\n",
      "869 S Median   : {212.0,41.3458210723}\n",
      "869 S Mean     : {213.75118859,41.3458210723}\n",
      "869 ALL Median : {325.0,68.1880908469}\n",
      "869 ALL Mean   : {297.464318814,68.1880908469}\n",
      "\n",
      "870 N Median   : {276.0,47.6848834397}\n",
      "870 N Mean     : {268.991596639,47.6848834397}\n",
      "870 S Median   : {164.0,29.2807072456}\n",
      "870 S Mean     : {170.202643172,29.2807072456}\n",
      "870 ALL Median : {234.0,59.2591625358}\n",
      "870 ALL Mean   : {240.003363229,59.2591625358}\n",
      "\n",
      "871 N Median   : {348.0,46.9228640844}\n",
      "871 N Mean     : {359.472645234,46.9228640844}\n",
      "871 S Median   : {236.0,18.6964048832}\n",
      "871 S Mean     : {240.333333333,18.6964048832}\n",
      "871 ALL Median : {348.0,48.8312281332}\n",
      "871 ALL Mean   : {357.970998327,48.8312281332}\n",
      "\n",
      "872 N Median   : {326.0,24.8185863428}\n",
      "872 N Mean     : {329.266490765,24.8185863428}\n",
      "872 S Median   : {198.0,7.80313327381}\n",
      "872 S Mean     : {201.666666667,7.80313327381}\n",
      "872 ALL Median : {326.0,33.1551174822}\n",
      "872 ALL Mean   : {324.57330637,33.1551174822}\n",
      "\n",
      "873 N Median   : {382.0,16.068743619}\n",
      "873 N Mean     : {382.660505237,16.068743619}\n",
      "873 S Median   : {301.0,30.34571176}\n",
      "873 S Mean     : {301.066666667,30.34571176}\n",
      "873 ALL Median : {382.0,17.8668850095}\n",
      "873 ALL Mean   : {381.816180845,17.8668850095}\n",
      "\n",
      "874 N Median   : {288.0,27.3528017075}\n",
      "874 N Mean     : {288.488563586,27.3528017075}\n",
      "874 S Median   : {212.0,17.5780446672}\n",
      "874 S Mean     : {221.888888889,17.5780446672}\n",
      "874 ALL Median : {287.0,28.9046729992}\n",
      "874 ALL Mean   : {287.033094812,28.9046729992}\n",
      "\n",
      "875 N Median   : {316.0,22.5993956173}\n",
      "875 N Mean     : {318.123005661,22.5993956173}\n",
      "875 S Median   : {267.5,24.8819085884}\n",
      "875 S Mean     : {262.125,24.8819085884}\n",
      "875 ALL Median : {315.0,30.8222056447}\n",
      "875 ALL Mean   : {313.293801855,30.8222056447}\n",
      "\n",
      "876 N Median   : {307.0,28.8129003592}\n",
      "876 N Mean     : {304.348802395,28.8129003592}\n",
      "876 S Median   : {248.0,31.6952480936}\n",
      "876 S Mean     : {237.62962963,31.6952480936}\n",
      "876 ALL Median : {307.0,33.2326036358}\n",
      "876 ALL Mean   : {300.137914914,33.2326036358}\n",
      "\n",
      "877 N Median   : {329.0,21.0362058046}\n",
      "877 N Mean     : {328.188350572,21.0362058046}\n",
      "877 S Median   : {172.0,43.6852558361}\n",
      "877 S Mean     : {197.647959184,43.6852558361}\n",
      "877 ALL Median : {326.0,45.5870733211}\n",
      "877 ALL Mean   : {315.529990167,45.5870733211}\n",
      "\n",
      "878 N Median   : {343.0,53.7857140563}\n",
      "878 N Mean     : {359.271410579,53.7857140563}\n",
      "878 S Median   : {266.5,62.0025023909}\n",
      "878 S Mean     : {280.546875,62.0025023909}\n",
      "878 ALL Median : {334.0,72.9215507866}\n",
      "878 ALL Mean   : {336.377358491,72.9215507866}\n",
      "\n",
      "879 N Median   : {340.0,53.2237443263}\n",
      "879 N Mean     : {350.260040844,53.2237443263}\n",
      "879 S Median   : {251.0,23.7170733012}\n",
      "879 S Mean     : {250.145833333,23.7170733012}\n",
      "879 ALL Median : {315.0,76.3814181919}\n",
      "879 ALL Mean   : {311.776590578,76.3814181919}\n",
      "\n",
      "880 N Median   : {187.0,11.9574148641}\n",
      "880 N Mean     : {189.509026435,11.9574148641}\n",
      "880 S Median   : {142.0,13.2952818141}\n",
      "880 S Mean     : {143.497925311,13.2952818141}\n",
      "880 ALL Median : {186.0,19.2158364728}\n",
      "880 ALL Mean   : {184.364810563,19.2158364728}\n",
      "\n",
      "881 N Median   : {321.0,69.0068895735}\n",
      "881 N Mean     : {329.055219365,69.0068895735}\n",
      "881 S Median   : {229.0,35.7389696803}\n",
      "881 S Mean     : {231.380573248,35.7389696803}\n",
      "881 ALL Median : {277.0,80.1324196472}\n",
      "881 ALL Mean   : {284.038938053,80.1324196472}\n",
      "\n",
      "882 N Median   : {332.0,24.9748296736}\n",
      "882 N Mean     : {335.307529162,24.9748296736}\n",
      "882 S Median   : {201.0,20.3757679972}\n",
      "882 S Mean     : {206.731707317,20.3757679972}\n",
      "882 ALL Median : {332.0,31.7881335255}\n",
      "882 ALL Mean   : {332.214803313,31.7881335255}\n",
      "\n",
      "883 N Median   : {352.0,24.8981934564}\n",
      "883 N Mean     : {356.824392998,24.8981934564}\n",
      "883 S Median   : {207.0,25.1164786545}\n",
      "883 S Mean     : {219.25,25.1164786545}\n",
      "883 ALL Median : {352.0,33.3921766425}\n",
      "883 ALL Mean   : {353.202970297,33.3921766425}\n",
      "\n",
      "884 N Median   : {224.0,22.0941250818}\n",
      "884 N Mean     : {228.431964573,22.0941250818}\n",
      "884 S Median   : {171.0,22.7797821835}\n",
      "884 S Mean     : {167.603773585,22.7797821835}\n",
      "884 ALL Median : {223.0,26.231464615}\n",
      "884 ALL Mean   : {222.96528983,26.231464615}\n",
      "\n",
      "885 N Median   : {354.0,46.3116110611}\n",
      "885 N Mean     : {357.474734043,46.3116110611}\n",
      "885 S Median   : {240.0,38.1252165714}\n",
      "885 S Mean     : {237.766917293,38.1252165714}\n",
      "885 ALL Median : {334.0,70.5518845899}\n",
      "885 ALL Mean   : {327.840143003,70.5518845899}\n",
      "\n",
      "886 N Median   : {290.0,19.2425764504}\n",
      "886 N Mean     : {291.425473004,19.2425764504}\n",
      "886 S Median   : {170.0,15.0311806101}\n",
      "886 S Mean     : {175.423076923,15.0311806101}\n",
      "886 ALL Median : {290.0,24.1681310019}\n",
      "886 ALL Mean   : {289.213513514,24.1681310019}\n",
      "\n",
      "887 N Median   : {235.0,37.1745890141}\n",
      "887 N Mean     : {248.355017007,37.1745890141}\n",
      "887 S Median   : {154.0,9.55182579406}\n",
      "887 S Mean     : {155.432,9.55182579406}\n",
      "887 ALL Median : {232.0,43.3572503169}\n",
      "887 ALL Mean   : {238.952380952,43.3572503169}\n",
      "\n",
      "888 N Median   : {282.0,17.7378972721}\n",
      "888 N Mean     : {281.420018282,17.7378972721}\n",
      "888 S Median   : {206.0,15.6600178534}\n",
      "888 S Mean     : {203.617647059,15.6600178534}\n",
      "888 ALL Median : {279.0,23.5742873854}\n",
      "888 ALL Mean   : {277.967965368,23.5742873854}\n",
      "\n",
      "889 N Median   : {377.0,53.8288168454}\n",
      "889 N Mean     : {394.827067669,53.8288168454}\n",
      "889 S Median   : {304.0,38.2906035057}\n",
      "889 S Mean     : {301.085526316,38.2906035057}\n",
      "889 ALL Median : {374.0,71.5423274208}\n",
      "889 ALL Mean   : {376.181711606,71.5423274208}\n",
      "\n",
      "890 N Median   : {301.0,25.1482367886}\n",
      "890 N Mean     : {305.250874563,25.1482367886}\n",
      "890 S Median   : {173.0,21.1484586815}\n",
      "890 S Mean     : {179.283783784,21.1484586815}\n",
      "890 ALL Median : {298.5,41.6168887055}\n",
      "890 ALL Mean   : {295.628913444,41.6168887055}\n",
      "\n",
      "891 N Median   : {251.0,25.4441742455}\n",
      "891 N Mean     : {257.242567249,25.4441742455}\n",
      "891 S Median   : {192.0,5.99160094534}\n",
      "891 S Mean     : {192.339350181,5.99160094534}\n",
      "891 ALL Median : {248.0,32.9269260017}\n",
      "891 ALL Mean   : {246.707260853,32.9269260017}\n",
      "\n",
      "892 N Median   : {254.0,34.1310439423}\n",
      "892 N Mean     : {258.033908046,34.1310439423}\n",
      "892 S Median   : {161.0,21.0660801017}\n",
      "892 S Mean     : {166.277246654,21.0660801017}\n",
      "892 ALL Median : {229.0,50.8835421939}\n",
      "892 ALL Mean   : {226.017247448,50.8835421939}\n",
      "\n",
      "893 N Median   : {260.0,52.5687375148}\n",
      "893 N Mean     : {270.654021938,52.5687375148}\n",
      "893 S Median   : {nan,nan}\n",
      "893 S Mean     : {nan,nan}\n",
      "893 ALL Median : {256.0,64.6130296478}\n",
      "893 ALL Mean   : {254.298495645,64.6130296478}\n",
      "\n",
      "894 N Median   : {279.0,27.0131408708}\n",
      "894 N Mean     : {278.438263229,27.0131408708}\n",
      "894 S Median   : {217.5,25.5853351551}\n",
      "894 S Mean     : {210.875,25.5853351551}\n",
      "894 ALL Median : {276.0,32.9770058894}\n",
      "894 ALL Mean   : {273.812366738,32.9770058894}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for ds in SUP:\n",
    "    NNN = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    SSS = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    ALL = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    for idx, label in enumerate(SUP_Data_Label_DS_2[ds]):\n",
    "        if SUP_Data_DS_2[ds][idx][1] > 1000:\n",
    "            continue\n",
    "        ALL['preRR'].append(SUP_Data_DS_2[ds][idx][1])\n",
    "        ALL['skewness'].append(SUP_Data_DS_2[ds][idx][2])\n",
    "        ALL['kurtosis'].append(SUP_Data_DS_2[ds][idx][3])\n",
    "        if label == 'N':\n",
    "            NNN['preRR'].append(SUP_Data_DS_2[ds][idx][1])\n",
    "            NNN['skewness'].append(SUP_Data_DS_2[ds][idx][2])\n",
    "            NNN['kurtosis'].append(SUP_Data_DS_2[ds][idx][3])\n",
    "        if label == 'S':\n",
    "            SSS['preRR'].append(SUP_Data_DS_2[ds][idx][1])\n",
    "            SSS['skewness'].append(SUP_Data_DS_2[ds][idx][2])\n",
    "            SSS['kurtosis'].append(SUP_Data_DS_2[ds][idx][3])\n",
    "    print(ds + ' N Median   ' + ': {' + str(np.median(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' N Mean     ' + ': {' + str(np.mean(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' S Median   ' + ': {' + str(np.median(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' S Mean     ' + ': {' + str(np.mean(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' ALL Median ' + ': {' + str(np.median(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print(ds + ' ALL Mean   ' + ': {' + str(np.mean(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Preparing INCART Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1687,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns = ['ann', 'annIdx', 'beat', 'cA7', 'cD1', 'cD2', 'cD3', 'cD4', 'cD5', 'cD6', 'cD7', \n",
    "           'kurtosis', 'postRR', 'preRR', 'skewness', 'beatValues', 'beatIndex']\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "INCART_Data_Label_DS_2 = {}\n",
    "INCART_Data_DS_2 = {}\n",
    "INCART_Data_Label_2 = []\n",
    "INCART_Data_2 = []\n",
    "\n",
    "for ds in INCART: \n",
    "    INCART_Data_Label_DS_2[ds] = []\n",
    "    INCART_Data_DS_2[ds] = []\n",
    "    dsLength = len(INCART_Hbs_lead1[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if INCART_Hbs_lead1[ds]['ann'][i] in Non_beat_anns:\n",
    "            continue\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in N:\n",
    "            INCART_Data_Label_2.append('N')\n",
    "            INCART_Data_Label_DS_2[ds].append('N')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in SVEB:\n",
    "            INCART_Data_Label_2.append('S')\n",
    "            INCART_Data_Label_DS_2[ds].append('S')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in VEB:\n",
    "            INCART_Data_Label_2.append('V')\n",
    "            INCART_Data_Label_DS_2[ds].append('V')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in F:\n",
    "            INCART_Data_Label_2.append('F')\n",
    "            INCART_Data_Label_DS_2[ds].append('F')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in Q:\n",
    "            INCART_Data_Label_2.append('Q')\n",
    "            INCART_Data_Label_DS_2[ds].append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # 逐个计算feature\n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(INCART_Hbs_lead1[ds][column][i]) == list:\n",
    "                features.extend(INCART_Hbs_lead1[ds][column][i])\n",
    "            else:\n",
    "                features.append(INCART_Hbs_lead1[ds][column][i])\n",
    "        INCART_Data_2.append(features)\n",
    "        INCART_Data_DS_2[ds].append(features)\n",
    "INCART_Data_2 = preprocessing.scale(INCART_Data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1688,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I60 N Median   : {248.0,46.9355906863}\n",
      "I60 N Mean     : {259.726132686,46.9355906863}\n",
      "I60 S Median   : {nan,nan}\n",
      "I60 S Mean     : {nan,nan}\n",
      "I60 ALL Median : {248.0,46.9355906863}\n",
      "I60 ALL Mean   : {259.726132686,46.9355906863}\n",
      "\n",
      "I61 N Median   : {443.0,28.4732536814}\n",
      "I61 N Mean     : {442.252239835,28.4732536814}\n",
      "I61 S Median   : {292.0,0.0}\n",
      "I61 S Mean     : {292.0,0.0}\n",
      "I61 ALL Median : {443.0,28.7350855765}\n",
      "I61 ALL Mean   : {442.148760331,28.7350855765}\n",
      "\n",
      "I62 N Median   : {315.0,52.7196135334}\n",
      "I62 N Mean     : {312.973121985,52.7196135334}\n",
      "I62 S Median   : {201.0,41.7319488588}\n",
      "I62 S Mean     : {208.0,41.7319488588}\n",
      "I62 ALL Median : {277.0,61.1913919215}\n",
      "I62 ALL Mean   : {283.198059109,61.1913919215}\n",
      "\n",
      "I63 N Median   : {328.0,29.2018927925}\n",
      "I63 N Mean     : {328.692682927,29.2018927925}\n",
      "I63 S Median   : {220.0,0.0}\n",
      "I63 S Mean     : {220.0,0.0}\n",
      "I63 ALL Median : {327.0,39.255869394}\n",
      "I63 ALL Mean   : {322.345381526,39.255869394}\n",
      "\n",
      "I64 N Median   : {338.0,24.6511157462}\n",
      "I64 N Mean     : {337.498672331,24.6511157462}\n",
      "I64 S Median   : {nan,nan}\n",
      "I64 S Mean     : {nan,nan}\n",
      "I64 ALL Median : {338.0,28.7605344023}\n",
      "I64 ALL Mean   : {336.16762703,28.7605344023}\n",
      "\n",
      "I65 N Median   : {270.0,59.2766808438}\n",
      "I65 N Mean     : {256.945398503,59.2766808438}\n",
      "I65 S Median   : {191.0,29.0860791445}\n",
      "I65 S Mean     : {192.0,29.0860791445}\n",
      "I65 ALL Median : {245.5,66.7445296564}\n",
      "I65 ALL Mean   : {241.204733283,66.7445296564}\n",
      "\n",
      "I66 N Median   : {285.0,37.0298267176}\n",
      "I66 N Mean     : {285.679156909,37.0298267176}\n",
      "I66 S Median   : {232.0,0.0}\n",
      "I66 S Mean     : {232.0,0.0}\n",
      "I66 ALL Median : {284.0,50.3836756167}\n",
      "I66 ALL Mean   : {274.749571918,50.3836756167}\n",
      "\n",
      "I67 N Median   : {217.0,43.4330913001}\n",
      "I67 N Mean     : {231.308418891,43.4330913001}\n",
      "I67 S Median   : {203.0,9.01997782702}\n",
      "I67 S Mean     : {199.8,9.01997782702}\n",
      "I67 ALL Median : {210.0,51.18761144}\n",
      "I67 ALL Mean   : {216.006056528,51.18761144}\n",
      "\n",
      "I68 N Median   : {243.0,18.8956643425}\n",
      "I68 N Mean     : {247.375554659,18.8956643425}\n",
      "I68 S Median   : {210.0,20.0}\n",
      "I68 S Mean     : {210.0,20.0}\n",
      "I68 ALL Median : {243.0,24.9408394606}\n",
      "I68 ALL Mean   : {243.057910674,24.9408394606}\n",
      "\n",
      "I69 N Median   : {297.0,39.7383750586}\n",
      "I69 N Mean     : {306.093640461,39.7383750586}\n",
      "I69 S Median   : {211.0,0.0}\n",
      "I69 S Mean     : {211.0,0.0}\n",
      "I69 ALL Median : {296.0,50.9574255388}\n",
      "I69 ALL Mean   : {296.364727608,50.9574255388}\n",
      "\n",
      "I70 N Median   : {396.0,25.624077815}\n",
      "I70 N Mean     : {401.016254876,25.624077815}\n",
      "I70 S Median   : {196.0,11.54280432}\n",
      "I70 S Mean     : {200.777777778,11.54280432}\n",
      "I70 ALL Median : {395.0,58.5076297304}\n",
      "I70 ALL Mean   : {385.853966346,58.5076297304}\n",
      "\n",
      "I71 N Median   : {412.0,64.9190281857}\n",
      "I71 N Mean     : {389.129289216,64.9190281857}\n",
      "I71 S Median   : {186.0,26.8097454106}\n",
      "I71 S Mean     : {193.542857143,26.8097454106}\n",
      "I71 ALL Median : {411.0,70.1954129631}\n",
      "I71 ALL Mean   : {385.022795441,70.1954129631}\n",
      "\n",
      "I72 N Median   : {287.0,51.2659261257}\n",
      "I72 N Mean     : {304.783653846,51.2659261257}\n",
      "I72 S Median   : {177.0,18.0134498362}\n",
      "I72 S Mean     : {183.625,18.0134498362}\n",
      "I72 ALL Median : {282.0,67.1129461766}\n",
      "I72 ALL Mean   : {283.214916152,67.1129461766}\n",
      "\n",
      "I73 N Median   : {329.0,25.3343954656}\n",
      "I73 N Mean     : {330.443855932,25.3343954656}\n",
      "I73 S Median   : {185.0,18.3324070552}\n",
      "I73 S Mean     : {187.71875,18.3324070552}\n",
      "I73 ALL Median : {328.0,41.9197608906}\n",
      "I73 ALL Mean   : {322.66080402,41.9197608906}\n",
      "\n",
      "I74 N Median   : {270.0,25.9316610572}\n",
      "I74 N Mean     : {272.059163059,25.9316610572}\n",
      "I74 S Median   : {nan,nan}\n",
      "I74 S Mean     : {nan,nan}\n",
      "I74 ALL Median : {264.0,28.1024267734}\n",
      "I74 ALL Mean   : {267.354019159,28.1024267734}\n",
      "\n",
      "I75 N Median   : {318.0,47.0488424647}\n",
      "I75 N Mean     : {338.823211876,47.0488424647}\n",
      "I75 S Median   : {nan,nan}\n",
      "I75 S Mean     : {nan,nan}\n",
      "I75 ALL Median : {301.0,66.3098206097}\n",
      "I75 ALL Mean   : {305.736190476,66.3098206097}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:135: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  keepdims=keepdims)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:105: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean, rcount, out=arrmean, casting='unsafe', subok=False)\n",
      "D:\\Anaconda3\\lib\\site-packages\\numpy\\core\\_methods.py:127: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "for ds in INCART:\n",
    "    NNN = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    SSS = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    ALL = {'preRR': [], 'skewness': [], 'kurtosis': []}\n",
    "    for idx, label in enumerate(INCART_Data_Label_DS_2[ds]):\n",
    "        if INCART_Data_DS_2[ds][idx][1] > 1000:\n",
    "            continue\n",
    "        ALL['preRR'].append(INCART_Data_DS_2[ds][idx][1])\n",
    "        ALL['skewness'].append(INCART_Data_DS_2[ds][idx][2])\n",
    "        ALL['kurtosis'].append(INCART_Data_DS_2[ds][idx][3])\n",
    "        if label == 'N':\n",
    "            NNN['preRR'].append(INCART_Data_DS_2[ds][idx][1])\n",
    "            NNN['skewness'].append(INCART_Data_DS_2[ds][idx][2])\n",
    "            NNN['kurtosis'].append(INCART_Data_DS_2[ds][idx][3])\n",
    "        if label == 'S':\n",
    "            SSS['preRR'].append(INCART_Data_DS_2[ds][idx][1])\n",
    "            SSS['skewness'].append(INCART_Data_DS_2[ds][idx][2])\n",
    "            SSS['kurtosis'].append(INCART_Data_DS_2[ds][idx][3])\n",
    "    print(ds + ' N Median   ' + ': {' + str(np.median(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' N Mean     ' + ': {' + str(np.mean(NNN['preRR'])) + ',' + str(np.std(NNN['preRR'])) + '}') \n",
    "    print(ds + ' S Median   ' + ': {' + str(np.median(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' S Mean     ' + ': {' + str(np.mean(SSS['preRR'])) + ',' + str(np.std(SSS['preRR'])) + '}')\n",
    "    print(ds + ' ALL Median ' + ': {' + str(np.median(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print(ds + ' ALL Mean   ' + ': {' + str(np.mean(ALL['preRR'])) + ',' + str(np.std(ALL['preRR'])) + '}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 1 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_1 = SVC(kernel='rbf', decision_function_shape='ovr')\n",
    "clf_1.fit(Training_Data_1, Training_Data_Label_1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 2 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treshold Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1014,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101\n",
      "106\n",
      "108\n",
      "109\n",
      "112\n",
      "114\n",
      "115\n",
      "116\n",
      "118\n",
      "119\n",
      "122\n",
      "124\n",
      "201\n",
      "203\n",
      "205\n",
      "207\n",
      "208\n",
      "209\n",
      "215\n",
      "220\n",
      "223\n",
      "230\n"
     ]
    }
   ],
   "source": [
    "tresholds = {}\n",
    "step = 0.02\n",
    "\n",
    "for ds in DS1:\n",
    "    print(ds)\n",
    "    max_value = 0\n",
    "    max_t = 0\n",
    "    t_value = -0.2\n",
    "    dsLength = len(Training_Hbs_lead0[ds]['beat'])\n",
    "    \n",
    "    while t_value > -0.6:\n",
    "        label_true = []\n",
    "        label_pred = []\n",
    "        N_Pre_RR = []\n",
    "        S_Pre_RR = []\n",
    "        for i in range(1, dsLength-1):\n",
    "            #if Training_Hbs_lead0[ds]['preRR'][i] > 1000:\n",
    "             #   continue\n",
    "            if Training_Hbs_lead0[ds]['ann'][i] in N:\n",
    "                label_true.append('N')\n",
    "                N_Pre_RR.append(Training_Hbs_lead0[ds]['preRR'][i])\n",
    "            elif Training_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "                label_true.append('S')\n",
    "                S_Pre_RR.append(Training_Hbs_lead0[ds]['preRR'][i])\n",
    "            else:\n",
    "                continue\n",
    "        \n",
    "            #mean_pre_rr = np.mean(Training_Hbs_lead0[ds]['preRR'][1:])  #对DS2效果最好\n",
    "            mean_pre_rr = max(np.mean(Training_Hbs_lead0[ds]['preRR'][1:]), np.median(Training_Hbs_lead0[ds]['preRR'][1:]))\n",
    "            #mean_pre_rr = (np.mean(N_Pre_RR) + np.median(N_Pre_RR))/2\n",
    "        \n",
    "            if (Training_Hbs_lead0[ds]['preRR'][i] - Training_Hbs_lead0[ds]['postRR'][i]) / mean_pre_rr < t_value:\n",
    "                label_pred.append('S')\n",
    "            elif (Training_Hbs_lead0[ds]['preRR'][i] - mean_pre_rr) / mean_pre_rr < t_value:\n",
    "                label_pred.append('S')\n",
    "            else:\n",
    "                label_pred.append('N')\n",
    "        \n",
    "        if len(S_Pre_RR) == 0:\n",
    "            max_t = t_value\n",
    "            break\n",
    "            \n",
    "        N_Result = list(confusion_matrix(label_true, label_pred, labels=['N', 'S'])[0])\n",
    "        S_Result = list(confusion_matrix(label_true, label_pred, labels=['N', 'S'])[1])\n",
    "        N_Spec = N_Result[0] / (N_Result[0] + N_Result[1])\n",
    "        S_Spec = S_Result[1] / (S_Result[0] + S_Result[1])\n",
    "        if N_Spec + S_Spec > max_value:\n",
    "            max_value = N_Spec + S_Spec\n",
    "            max_t = t_value\n",
    "        t_value -= step\n",
    "    tresholds[ds] = [np.mean(N_Pre_RR), np.std(N_Pre_RR), max_t]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'101': [348.66720516962846, 25.17908215432, -0.2],\n",
       " '106': [367.38338870431892, 57.087551719040803, -0.2],\n",
       " '108': [370.72769142199195, 40.452935033402667, -0.5000000000000002],\n",
       " '109': [257.34150261149057, 12.645993125788825, -0.2],\n",
       " '112': [256.04577742699291, 7.7005081326221347, -0.2],\n",
       " '114': [348.7981298129813, 44.594067605336349, -0.22],\n",
       " '115': [332.92102564102566, 31.367138103343351, -0.2],\n",
       " '116': [273.67246628969116, 20.63673636570984, -0.24],\n",
       " '118': [288.92140545538604, 29.274891127796593, -0.2],\n",
       " '119': [365.25827384815057, 67.625314286789418, -0.2],\n",
       " '122': [262.55155681358673, 14.444165497012348, -0.2],\n",
       " '124': [404.43770384866275, 28.670147629765626, -0.2],\n",
       " '201': [340.9804041641151, 133.17138162846246, -0.3400000000000001],\n",
       " '203': [232.2837356549268, 68.501530349935322, -0.32000000000000006],\n",
       " '205': [247.15070093457945, 16.628273677384527, -0.2],\n",
       " '207': [345.06485084306098, 212.48987389456329, -0.42000000000000015],\n",
       " '208': [244.78282828282829, 46.36585470914892, -0.44000000000000017],\n",
       " '209': [225.83116883116884, 15.001163395466545, -0.2],\n",
       " '215': [195.54104010025063, 16.232457503792425, -0.2],\n",
       " '220': [323.49589743589746, 17.67509427210905, -0.2],\n",
       " '223': [262.94419970631424, 25.420166112974531, -0.2],\n",
       " '230': [288.19493783303727, 30.910828477749668, -0.2]}"
      ]
     },
     "execution_count": 990,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check above Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1098,  439],\n",
       "       [   0,  106]], dtype=int64)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds = '207'\n",
    "ttt = -0.14\n",
    "rrrr = []\n",
    "real = []\n",
    "dsLength = len(Training_Hbs_lead0[ds]['beat'])\n",
    "for i in range(1, dsLength-1):\n",
    "    if Training_Hbs_lead0[ds]['preRR'][i] > 1000:\n",
    "        continue\n",
    "    if Training_Hbs_lead0[ds]['ann'][i] in N:\n",
    "        real.append('N')\n",
    "    elif Training_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "        real.append('S')\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "    me = np.mean(Training_Hbs_lead0[ds]['preRR'][1:])\n",
    "    if (Training_Hbs_lead0[ds]['preRR'][i] - Training_Hbs_lead0[ds]['postRR'][i]) / me < ttt:\n",
    "        rrrr.append('S')\n",
    "    elif (Training_Hbs_lead0[ds]['preRR'][i] - me) / me < ttt:\n",
    "        rrrr.append('S')\n",
    "    else:\n",
    "        rrrr.append('N')\n",
    "\n",
    "confusion_matrix(real, rrrr, labels=['N', 'S'])   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "S_V Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 553,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.31239211,  0.22834703,  0.8458107 ,  1.14379641,  0.29825978,\n",
       "       -0.25794329, -0.4496015 , -0.53170662, -0.20842206,  0.59653996,\n",
       "       -0.01276096,  0.51226308,  0.31359264,  0.0826024 ,  0.20081946,\n",
       "       -0.57965195,  0.51413261,  0.        ,  0.10267241, -0.237055  ,\n",
       "       -0.47643094,  0.74893263,  0.35798413, -0.53856392, -0.35992489,\n",
       "        0.1410865 ,  0.11135279,  0.20638357, -0.30503849, -0.65887837,\n",
       "       -0.21836847,  0.75554872,  0.07607732])"
      ]
     },
     "execution_count": 553,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_Data_2[1][]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1454,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "S_V_Train = []\n",
    "S_V_Label = []\n",
    "\n",
    "for idx, label in enumerate(Training_Data_Label_2):\n",
    "    if label == 'N':\n",
    "        continue\n",
    "    S_V_Label.append(label)\n",
    "    #S_V_Train.append(Training_Data_2[idx][2:]) #这个配置对DS2效果好\n",
    "    S_V_Train.append(Training_Data_2[idx][2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight={'S': 3, 'V': 1}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 1455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_SV = SVC(kernel='rbf', class_weight={'S':3, 'V':1})\n",
    "clf_SV.fit(S_V_Train, S_V_Label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 735,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 933,   66,   26,    4],\n",
       "       [  10, 3711,   49,    4],\n",
       "       [   0,    9,  339,    0],\n",
       "       [   0,    0,    0,    0]], dtype=int64)"
      ]
     },
     "execution_count": 735,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(clf_SV.predict(S_V_Train), S_V_Label, labels=['S', 'V', 'F','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N_V Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_V_Train = []\n",
    "N_V_Label = []\n",
    "\n",
    "for idx, label in enumerate(Training_Data_Label_2):\n",
    "    if label == 'S':\n",
    "        continue\n",
    "    N_V_Label.append(label)\n",
    "    N_V_Train.append(Training_Data_2[idx][:-2]) #这个配置对DS2效果好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 921,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight={'N': 1, 'V': 1, 'F': 0.1}, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 921,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_NV = SVC(kernel='rbf', class_weight={'N':1, 'V':1, 'F':0.1})\n",
    "clf_NV.fit(N_V_Train, N_V_Label) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 917,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[45803,    62,    81,     4],\n",
       "       [    4,  3717,    17,     0],\n",
       "       [    1,     7,   316,     0],\n",
       "       [    0,     0,     0,     4]], dtype=int64)"
      ]
     },
     "execution_count": 917,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(clf_NV.predict(N_V_Train), N_V_Label, labels=['N', 'V', 'F','Q'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------- DESLib ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from deslib.des.knop import KNOP\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.calibration import CalibratedClassifierCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_label_1 = []\n",
    "for label in Training_Data_Label_1:\n",
    "    if label in N:\n",
    "        temp_label_1.append(0)\n",
    "    elif label in SVEB:\n",
    "        temp_label_1.append(1)\n",
    "    elif label in VEB:\n",
    "        temp_label_1.append(2)\n",
    "    elif label in Q:\n",
    "        temp_label_1.append(3)\n",
    "    elif label in F:\n",
    "        temp_label_1.append(4)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_dsel, y_train, y_dsel = train_test_split(Training_Data_1, temp_label_1, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:445: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:447: RuntimeWarning: invalid value encountered in multiply\n",
      "  TEP_minus_T1P = P * (T * E - T1)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:435: RuntimeWarning: overflow encountered in exp\n",
      "  E = np.exp(AB[0] * F + AB[1])\n"
     ]
    }
   ],
   "source": [
    "model_perceptron = CalibratedClassifierCV(Perceptron(max_iter=100)).fit(X_train, y_train)\n",
    "model_linear_svm = CalibratedClassifierCV(LinearSVC()).fit(X_train, y_train)\n",
    "model_svc = SVC(probability=True).fit(X_train, y_train)\n",
    "model_bayes = GaussianNB().fit(X_train, y_train)\n",
    "model_tree = DecisionTreeClassifier().fit(X_train, y_train)\n",
    "model_knn = KNeighborsClassifier(n_neighbors=5).fit(X_train, y_train)\n",
    "pool_classifiers = [model_perceptron, model_linear_svm, model_svc, model_bayes,  model_tree, model_knn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\calibration.py:510: RuntimeWarning: overflow encountered in exp\n",
      "  return 1. / (1. + np.exp(self.a_ * T + self.b_))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<deslib.des.knop.KNOP at 0x2e32bc03c88>"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knop = KNOP(pool_classifiers)\n",
    "knop.fit(X_dsel, np.array(y_dsel))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 1 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result_1 = clf_1.predict(SUP_Data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 2 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine The Treshold Value for Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Pre_RR = {}\n",
    "Test_Nearest = {}\n",
    "for ds in DS2:\n",
    "    temp = []\n",
    "    dsLength = len(Testing_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength):\n",
    "        if Testing_Hbs_lead0[ds]['preRR'][i] > 1100:\n",
    "            continue\n",
    "        else:\n",
    "            temp.append(Testing_Hbs_lead0[ds]['preRR'][i])\n",
    "    Test_Pre_RR[ds] = [max(np.mean(temp), np.median(temp)), np.std(temp)]\n",
    "    minDis = 999\n",
    "    neighbor = -1\n",
    "    for ds_1 in DS1:\n",
    "        if tresholds[ds_1][2] == -0.2:\n",
    "            continue\n",
    "        elif tresholds[ds_1][0] < Test_Pre_RR[ds][0]:\n",
    "            continue\n",
    "        else:\n",
    "            temp1 = abs(Test_Pre_RR[ds][0] - tresholds[ds_1][0]) \n",
    "            if temp1 < minDis:\n",
    "                minDis = temp1\n",
    "                neighbor = ds_1\n",
    "    if neighbor == -1:\n",
    "        neighbor = '124'\n",
    "    Test_Nearest[ds] = [neighbor, round(tresholds[neighbor][2], 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction of Each Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 823,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.1"
      ]
     },
     "execution_count": 823,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Nearest['232'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100:\n",
      "[[2234    1]\n",
      " [   0   33]]\n",
      "\n",
      "103:\n",
      "[[2079    0]\n",
      " [   1    1]]\n",
      "\n",
      "105:\n",
      "[[2520    4]\n",
      " [   0    0]]\n",
      "\n",
      "111:\n",
      "[[2120    1]\n",
      " [   0    0]]\n",
      "\n",
      "113:\n",
      "[[1783    3]\n",
      " [   0    6]]\n",
      "\n",
      "117:\n",
      "[[1530    1]\n",
      " [   0    1]]\n",
      "\n",
      "121:\n",
      "[[1858    0]\n",
      " [   0    1]]\n",
      "\n",
      "123:\n",
      "[[1485   27]\n",
      " [   0    0]]\n",
      "\n",
      "200:\n",
      "[[1734    7]\n",
      " [   9   21]]\n",
      "\n",
      "202:\n",
      "[[1626  432]\n",
      " [   4   51]]\n",
      "\n",
      "210:\n",
      "[[2258  161]\n",
      " [   0   22]]\n",
      "\n",
      "212:\n",
      "[[2745    0]\n",
      " [   0    0]]\n",
      "\n",
      "213:\n",
      "[[2636    2]\n",
      " [   5   23]]\n",
      "\n",
      "214:\n",
      "[[1999    0]\n",
      " [   0    0]]\n",
      "\n",
      "219:\n",
      "[[1906  173]\n",
      " [   5    2]]\n",
      "\n",
      "221:\n",
      "[[1815  214]\n",
      " [   0    0]]\n",
      "\n",
      "222:\n",
      "[[1586  684]\n",
      " [   4  205]]\n",
      "\n",
      "228:\n",
      "[[1686    0]\n",
      " [   1    2]]\n",
      "\n",
      "231:\n",
      "[[1292  273]\n",
      " [   1    0]]\n",
      "\n",
      "232:\n",
      "[[ 335   20]\n",
      " [   3 1378]]\n",
      "\n",
      "233:\n",
      "[[2227    0]\n",
      " [   0    7]]\n",
      "\n",
      "234:\n",
      "[[2698    0]\n",
      " [  49    1]]\n",
      "\n",
      "42152 2003\n",
      "82 1754\n"
     ]
    }
   ],
   "source": [
    "n2n = 0\n",
    "n2s = 0\n",
    "s2s = 0\n",
    "s2n = 0\n",
    "\n",
    "for ds in DS2:\n",
    "    rrrr = []\n",
    "    real = []\n",
    "    \n",
    "    if np.std(Testing_Hbs_lead0[ds]['preRR'][1:]) > 45:\n",
    "        if abs(np.mean(Testing_Hbs_lead0[ds]['preRR'][1:]) - np.median(Testing_Hbs_lead0[ds]['preRR'][1:])) > 30:\n",
    "            Test_Nearest[ds][1] = -(math.floor(Test_Nearest[ds][1] * (-10) - 0.1))/10\n",
    "        \n",
    "    dsLength = len(Testing_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if Testing_Hbs_lead0[ds]['preRR'][i] > 1000:\n",
    "            continue\n",
    "        if Testing_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            real.append('N')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            real.append('S')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        #me = np.mean(Testing_Hbs_lead0[ds]['preRR'][1:])\n",
    "        me = max(np.mean(Testing_Hbs_lead0[ds]['preRR'][1:]),np.median(Testing_Hbs_lead0[ds]['preRR'][1:]))\n",
    "        if (Testing_Hbs_lead0[ds]['preRR'][i] - Testing_Hbs_lead0[ds]['postRR'][i]) / me < Test_Nearest[ds][1]:\n",
    "            rrrr.append('S')\n",
    "        elif (Testing_Hbs_lead0[ds]['preRR'][i] - me) / me < Test_Nearest[ds][1]:\n",
    "            rrrr.append('S')\n",
    "        else:\n",
    "            rrrr.append('N')\n",
    "    \n",
    "    n2n += confusion_matrix(real, rrrr, labels=['N', 'S'])[0][0]\n",
    "    n2s += confusion_matrix(real, rrrr, labels=['N', 'S'])[0][1]\n",
    "    s2n += confusion_matrix(real, rrrr, labels=['N', 'S'])[1][0]\n",
    "    s2s += confusion_matrix(real, rrrr, labels=['N', 'S'])[1][1]\n",
    "                            \n",
    "    print(ds + ':')\n",
    "    print(confusion_matrix(real, rrrr, labels=['N', 'S']))\n",
    "    print()\n",
    "print(n2n, n2s)\n",
    "print(s2n, s2s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform the whole idea testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1701,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_Set = []\n",
    "N_Id = []\n",
    "S_Set = []\n",
    "S_Id = []\n",
    "result_2 = []\n",
    "real_label = []\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "\n",
    "for ds in DS2:\n",
    "    dsLength = len(Testing_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if Testing_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            real_label.append('N')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            real_label.append('S')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            real_label.append('V')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            real_label.append('F')\n",
    "        elif Testing_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            real_label.append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(Testing_Hbs_lead0[ds][column][i]) == list:\n",
    "                features.extend(Testing_Hbs_lead0[ds][column][i])\n",
    "            else:\n",
    "                features.append(Testing_Hbs_lead0[ds][column][i])\n",
    "                \n",
    "        #me = np.mean(Testing_Hbs_lead0[ds]['preRR'][1:])\n",
    "        me = max(np.mean(Testing_Hbs_lead0[ds]['preRR'][1:]),np.median(Testing_Hbs_lead0[ds]['preRR'][1:]))\n",
    "        if (Testing_Hbs_lead0[ds]['preRR'][i] - Testing_Hbs_lead0[ds]['postRR'][i]) / me < Test_Nearest[ds][1]:\n",
    "            result_2.append('S')\n",
    "            S_Set.append(features)\n",
    "            S_Id.append(len(result_2)-1)\n",
    "        elif (Testing_Hbs_lead0[ds]['preRR'][i] - me) / me < Test_Nearest[ds][1]:\n",
    "            result_2.append('S')\n",
    "            S_Set.append(features)\n",
    "            S_Id.append(len(result_2)-1)\n",
    "        else:\n",
    "            result_2.append('N')\n",
    "            N_Set.append(features)\n",
    "            N_Id.append(len(result_2)-1)\n",
    "            \n",
    "total = []\n",
    "total.extend(list(N_Set))\n",
    "total.extend(list(S_Set))\n",
    "normalized_total = preprocessing.scale(total)\n",
    "Norlize_N_Set = normalized_total[:len(N_Set)]\n",
    "Norlize_S_Set = normalized_total[len(N_Set):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1702,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempN = []\n",
    "for i in Norlize_N_Set:\n",
    "    tempN.append(i[0:-2])\n",
    "N_result = clf_NV.predict(tempN)\n",
    "for idx, resultId in enumerate(N_Id):\n",
    "    result_2[resultId] = N_result[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transform = {0.0: 'N', 1.0: 'S', 2.0: 'V', 3.0: 'Q', 4.0: 'F'}\n",
    "N_result = knop.predict(Norlize_N_Set)\n",
    "for idx, resultId in enumerate(N_Id):\n",
    "    result_2[resultId] = transform[N_result[idx]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1703,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempS = []\n",
    "for i in Norlize_S_Set:\n",
    "    tempS.append(i[2:])\n",
    "S_result = clf_SV.predict(tempS)\n",
    "for idx, resultId in enumerate(S_Id):\n",
    "    result_2[resultId] = S_result[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 539,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'N'"
      ]
     },
     "execution_count": 539,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform [0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 439,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knop.predict(Norlize_N_Set[:10])[0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1704,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40420,  1863,  1898,    17,     0],\n",
       "       [   77,  1576,   180,     3,     0],\n",
       "       [   46,   105,  3065,     3,     0],\n",
       "       [  230,     1,   157,     0,     0],\n",
       "       [    1,     0,     6,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 1704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(real_label, result_2, labels=['N', 'S', 'V','F','Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1705,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90760957138253306"
      ]
     },
     "execution_count": 1705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(real_label, result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1709,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DS2 & 44198 & 1836 & 3219 && 90.76 & 91.45 & 99.13 && 85.84 & 44.46 && 95.22 & 57.76 & \\\\\n",
      "\n",
      "ACC: 0.907609571383\n",
      "\n",
      "N Total: 44198\n",
      "S Total: 1836\n",
      "V Total: 3219\n",
      "\n",
      "N Sen: 0.91\n",
      "N +P: 0.99\n",
      "\n",
      "S Sen: 0.86\n",
      "S +P: 0.44\n",
      "\n",
      "V Sen: 0.95\n",
      "V +P: 0.58\n"
     ]
    }
   ],
   "source": [
    "a = confusion_matrix(real_label, result_2, labels=['N', 'S', 'V','F','Q'])\n",
    "\n",
    "    \n",
    "print('DS2' + ' & ' \n",
    "      + str(sum(a[0])) + ' & ' \n",
    "      + str(sum(a[1])) + ' & ' \n",
    "      + str(sum(a[2])) + ' && ' \n",
    "      + str(round(accuracy_score(real_label, result_2) * 100, 2)) + ' & ' \n",
    "      + str(round(a[0][0]/sum(a[0]) * 100, 2)) + ' & ' \n",
    "      + str(round(a[0][0]/sum(a[:, 0]) * 100, 2)) + ' && ' \n",
    "      + str(round(a[1][1]/sum(a[1]) * 100, 2) ) + ' & '\n",
    "      + str(round(a[1][1]/sum(a[:, 1]) * 100, 2)) + ' && '\n",
    "      + str(round(a[2][2]/sum(a[2]) * 100, 2)) + ' & '\n",
    "      + str(round(a[2][2]/sum(a[:, 2]) * 100, 2)) + ' & \\\\\\\\'\n",
    "     )\n",
    "\n",
    "print()\n",
    "\n",
    "print('ACC: ' + str(accuracy_score(real_label, result_2)))\n",
    "print()\n",
    "print('N Total: ' + str(sum(a[0])))\n",
    "print('S Total: ' + str(sum(a[1])))\n",
    "print('V Total: ' + str(sum(a[2])))\n",
    "print()\n",
    "print('N Sen: ' + str(round(a[0][0]/sum(a[0]), 2)))\n",
    "print('N +P: ' + str(round(a[0][0]/sum(a[:, 0]), 2)))\n",
    "print()\n",
    "print('S Sen: ' + str(round(a[1][1]/sum(a[1]), 2)))\n",
    "print('S +P: ' + str(round(a[1][1]/sum(a[:, 1]), 2)))\n",
    "print()\n",
    "print('V Sen: ' + str(round(a[2][2]/sum(a[2]), 2)))\n",
    "print('V +P: ' + str(round(a[2][2]/sum(a[:, 2]), 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------- SUP ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Pre_RR_SUP = {}\n",
    "Test_Nearest_SUP = {}\n",
    "for ds in SUP:\n",
    "    temp = []\n",
    "    dsLength = len(SUP_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength):\n",
    "        if SUP_Hbs_lead0[ds]['preRR'][i] > 1100:\n",
    "            continue\n",
    "        else:\n",
    "            temp.append(SUP_Hbs_lead0[ds]['preRR'][i])\n",
    "    Test_Pre_RR_SUP[ds] = [max(np.mean(temp), np.median(temp)), np.std(temp)]\n",
    "    minDis = 999\n",
    "    neighbor = -1\n",
    "    for ds_1 in DS1:\n",
    "        if tresholds[ds_1][2] == -0.2:\n",
    "            continue\n",
    "        elif tresholds[ds_1][0] < Test_Pre_RR_SUP[ds][0]:\n",
    "            continue\n",
    "        else:\n",
    "            temp1 = abs(Test_Pre_RR_SUP[ds][0] - tresholds[ds_1][0]) \n",
    "            if temp1 < minDis:\n",
    "                minDis = temp1\n",
    "                neighbor = ds_1\n",
    "    if neighbor == -1:\n",
    "        neighbor = '124'\n",
    "    Test_Nearest_SUP[ds] = [neighbor, round(tresholds[neighbor][2], 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'851': ['116', -0.24],\n",
       " '852': ['208', -0.48],\n",
       " '853': ['201', -0.4],\n",
       " '854': ['208', -0.48],\n",
       " '855': ['116', -0.24],\n",
       " '856': ['203', -0.3],\n",
       " '857': ['116', -0.24],\n",
       " '858': ['201', -0.4],\n",
       " '859': ['203', -0.3],\n",
       " '860': ['116', -0.24],\n",
       " '861': ['116', -0.24],\n",
       " '862': ['201', -0.4],\n",
       " '863': ['203', -0.3],\n",
       " '864': ['101', -0.22],\n",
       " '865': ['203', -0.3],\n",
       " '866': ['116', -0.24],\n",
       " '867': ['203', -0.3],\n",
       " '868': ['203', -0.3],\n",
       " '869': ['201', -0.4],\n",
       " '870': ['208', -0.48],\n",
       " '871': ['108', -0.5],\n",
       " '872': ['201', -0.4],\n",
       " '873': ['124', -0.24],\n",
       " '874': ['118', -0.22],\n",
       " '875': ['201', -0.4],\n",
       " '876': ['201', -0.4],\n",
       " '877': ['201', -0.4],\n",
       " '878': ['201', -0.4],\n",
       " '879': ['201', -0.4],\n",
       " '880': ['203', -0.3],\n",
       " '881': ['118', -0.22],\n",
       " '882': ['201', -0.4],\n",
       " '883': ['108', -0.5],\n",
       " '884': ['203', -0.3],\n",
       " '885': ['201', -0.4],\n",
       " '886': ['201', -0.4],\n",
       " '887': ['208', -0.48],\n",
       " '888': ['118', -0.22],\n",
       " '889': ['124', -0.24],\n",
       " '890': ['201', -0.4],\n",
       " '891': ['116', -0.24],\n",
       " '892': ['203', -0.3],\n",
       " '893': ['116', -0.24],\n",
       " '894': ['118', -0.22]}"
      ]
     },
     "execution_count": 1178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Nearest_SUP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Nearest_SUP['865'][1]= -0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1179,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "851:\n",
      "[[2085   82]\n",
      " [  12   20]]\n",
      "\n",
      "852:\n",
      "[[2298   34]\n",
      " [ 123  198]]\n",
      "\n",
      "853:\n",
      "[[2100    4]\n",
      " [  10   38]]\n",
      "\n",
      "854:\n",
      "[[1785    3]\n",
      " [ 410   50]]\n",
      "\n",
      "855:\n",
      "[[1870  162]\n",
      " [  48  179]]\n",
      "\n",
      "856:\n",
      "[[2809    0]\n",
      " [   9    3]]\n",
      "\n",
      "857:\n",
      "[[2325   74]\n",
      " [   3   34]]\n",
      "\n",
      "858:\n",
      "[[2167    0]\n",
      " [   1    7]]\n",
      "\n",
      "859:\n",
      "[[2999    6]\n",
      " [  64    5]]\n",
      "\n",
      "860:\n",
      "[[1672    0]\n",
      " [   8    9]]\n",
      "\n",
      "861:\n",
      "[[1800   73]\n",
      " [  15  554]]\n",
      "\n",
      "862:\n",
      "[[2129    3]\n",
      " [  23    3]]\n",
      "\n",
      "863:\n",
      "[[2557    3]\n",
      " [  59  262]]\n",
      "\n",
      "864:\n",
      "[[1736    6]\n",
      " [   2   17]]\n",
      "\n",
      "865:\n",
      "[[1082   18]\n",
      " [  92 1726]]\n",
      "\n",
      "866:\n",
      "[[1464  586]\n",
      " [   3  164]]\n",
      "\n",
      "867:\n",
      "[[1238 1548]\n",
      " [  27  109]]\n",
      "\n",
      "868:\n",
      "[[2398  154]\n",
      " [  91  136]]\n",
      "\n",
      "869:\n",
      "[[1489   16]\n",
      " [ 274  357]]\n",
      "\n",
      "870:\n",
      "[[1784    1]\n",
      " [ 340  114]]\n",
      "\n",
      "871:\n",
      "[[1773    0]\n",
      " [   5    7]]\n",
      "\n",
      "872:\n",
      "[[1895    0]\n",
      " [   0    9]]\n",
      "\n",
      "873:\n",
      "[[1623    0]\n",
      " [   0   15]]\n",
      "\n",
      "874:\n",
      "[[2183    3]\n",
      " [   0    9]]\n",
      "\n",
      "875:\n",
      "[[1943    0]\n",
      " [   7    1]]\n",
      "\n",
      "876:\n",
      "[[2000    4]\n",
      " [ 112   23]]\n",
      "\n",
      "877:\n",
      "[[1833    4]\n",
      " [  62  134]]\n",
      "\n",
      "878:\n",
      "[[1588    0]\n",
      " [  18   46]]\n",
      "\n",
      "879:\n",
      "[[1469    0]\n",
      " [   5   43]]\n",
      "\n",
      "880:\n",
      "[[3093    9]\n",
      " [  56  185]]\n",
      "\n",
      "881:\n",
      "[[1248   74]\n",
      " [ 110  518]]\n",
      "\n",
      "882:\n",
      "[[1886    0]\n",
      " [   0   41]]\n",
      "\n",
      "883:\n",
      "[[1771    0]\n",
      " [   3   37]]\n",
      "\n",
      "884:\n",
      "[[2466   18]\n",
      " [  22   31]]\n",
      "\n",
      "885:\n",
      "[[1497    7]\n",
      " [ 120  279]]\n",
      "\n",
      "886:\n",
      "[[2166    1]\n",
      " [   2   24]]\n",
      "\n",
      "887:\n",
      "[[2350    2]\n",
      " [  43   82]]\n",
      "\n",
      "888:\n",
      "[[2184    4]\n",
      " [   0   68]]\n",
      "\n",
      "889:\n",
      "[[1447   16]\n",
      " [  27  125]]\n",
      "\n",
      "890:\n",
      "[[1998    3]\n",
      " [   8   66]]\n",
      "\n",
      "891:\n",
      "[[2098   21]\n",
      " [   8  269]]\n",
      "\n",
      "892:\n",
      "[[1720   20]\n",
      " [ 104  419]]\n",
      "\n",
      "893:\n",
      "[[1951  237]\n",
      " [   0    0]]\n",
      "\n",
      "894:\n",
      "[[2207    4]\n",
      " [   5   75]]\n",
      "\n",
      "86176 3200\n",
      "2331 6491\n"
     ]
    }
   ],
   "source": [
    "n2n = 0\n",
    "n2s = 0\n",
    "s2s = 0\n",
    "s2n = 0\n",
    "\n",
    "for ds in SUP:\n",
    "    rrrr = []\n",
    "    real = []\n",
    "    \n",
    "    if np.std(SUP_Hbs_lead0[ds]['preRR'][1:]) > 45:\n",
    "        if abs(np.mean(SUP_Hbs_lead0[ds]['preRR'][1:]) - np.median(SUP_Hbs_lead0[ds]['preRR'][1:])) > 30:\n",
    "            Test_Nearest_SUP[ds][1] = -(math.floor(Test_Nearest_SUP[ds][1] * (-10) - 0.1))/10\n",
    "            \n",
    "    dsLength = len(SUP_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if SUP_Hbs_lead0[ds]['preRR'][i] > 1000:\n",
    "            continue\n",
    "        if SUP_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            real.append('N')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            real.append('S')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        #me = np.mean(SUP_Hbs_lead0[ds]['preRR'][1:])\n",
    "        me = max(np.mean(SUP_Hbs_lead0[ds]['preRR'][1:]), np.median(SUP_Hbs_lead0[ds]['preRR'][1:]))\n",
    "        \n",
    "        if (SUP_Hbs_lead0[ds]['preRR'][i] - SUP_Hbs_lead0[ds]['postRR'][i]) / me < Test_Nearest_SUP[ds][1]:\n",
    "            rrrr.append('S')\n",
    "        elif (SUP_Hbs_lead0[ds]['preRR'][i] - me) / me < Test_Nearest_SUP[ds][1]:\n",
    "            rrrr.append('S')\n",
    "        else:\n",
    "            rrrr.append('N')\n",
    "    \n",
    "    n2n += confusion_matrix(real, rrrr, labels=['N', 'S'])[0][0]\n",
    "    n2s += confusion_matrix(real, rrrr, labels=['N', 'S'])[0][1]\n",
    "    s2n += confusion_matrix(real, rrrr, labels=['N', 'S'])[1][0]\n",
    "    s2s += confusion_matrix(real, rrrr, labels=['N', 'S'])[1][1]\n",
    "                            \n",
    "    print(ds + ':')\n",
    "    print(confusion_matrix(real, rrrr, labels=['N', 'S']))\n",
    "    print()\n",
    "print(n2n, n2s)\n",
    "print(s2n, s2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SUP = ['800', '801', '802', '803', '804', '805', '806', '807', '808', '809', '810', '811', '812', '820', '821', \n",
    "#       '822', '823', '824', '825', '826', '827', '828', '829', '840', '841', '842', '843', '844', '845', '846', \n",
    "#       '847', '848', '849', '850']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_Set_SUP = []\n",
    "N_Id_SUP = []\n",
    "S_Set_SUP = []\n",
    "S_Id_SUP = []\n",
    "result_SUP = []\n",
    "real_label_SUP = []\n",
    "DS_SUP = []\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "\n",
    "for ds in SUP:\n",
    "#for ds in ['822']:\n",
    "    dsLength = len(SUP_Hbs_lead0[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if SUP_Hbs_lead0[ds]['ann'][i] in N:\n",
    "            real_label_SUP.append('N')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in SVEB:\n",
    "            real_label_SUP.append('S')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in VEB:\n",
    "            real_label_SUP.append('V')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in F:\n",
    "            real_label_SUP.append('F')\n",
    "        elif SUP_Hbs_lead0[ds]['ann'][i] in Q:\n",
    "            real_label_SUP.append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(SUP_Hbs_lead0[ds][column][i]) == list:\n",
    "                features.extend(SUP_Hbs_lead0[ds][column][i])\n",
    "            else:\n",
    "                features.append(SUP_Hbs_lead0[ds][column][i])\n",
    "        DS_SUP.append(features)       \n",
    "        me = max(np.mean(SUP_Hbs_lead0[ds]['preRR'][1:]), np.median(SUP_Hbs_lead0[ds]['preRR'][1:]))\n",
    "        if (SUP_Hbs_lead0[ds]['preRR'][i] - SUP_Hbs_lead0[ds]['postRR'][i]) / me < Test_Nearest_SUP[ds][1]:\n",
    "            result_SUP.append('S')\n",
    "            S_Set_SUP.append(features)\n",
    "            S_Id_SUP.append(len(result_SUP)-1)\n",
    "        elif (SUP_Hbs_lead0[ds]['preRR'][i] - me) / me < Test_Nearest_SUP[ds][1]:\n",
    "            result_SUP.append('S')\n",
    "            S_Set_SUP.append(features)\n",
    "            S_Id_SUP.append(len(result_SUP)-1)\n",
    "        else:\n",
    "            result_SUP.append('N')\n",
    "            N_Set_SUP.append(features)\n",
    "            N_Id_SUP.append(len(result_SUP)-1)\n",
    "            \n",
    "total_SUP = []\n",
    "total_SUP.extend(list(N_Set_SUP))\n",
    "total_SUP.extend(list(S_Set_SUP))\n",
    "normalized_total_SUP = preprocessing.scale(total_SUP)\n",
    "Norlize_N_Set_SUP = normalized_total_SUP[:len(N_Set_SUP)]\n",
    "Norlize_S_Set_SUP = normalized_total_SUP[len(N_Set_SUP):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempN_SUP = []\n",
    "for i in Norlize_N_Set_SUP:\n",
    "    tempN_SUP.append(i[0:-2])\n",
    "N_result_SUP = clf_NV.predict(tempN_SUP)\n",
    "for idx, resultId in enumerate(N_Id_SUP):\n",
    "    result_SUP[resultId] = N_result_SUP[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1171,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempS_SUP = []\n",
    "for i in Norlize_S_Set_SUP:\n",
    "    #tempS_SUP.append(i[2:])\n",
    "    tempS_SUP.append(i[2:])\n",
    "S_result_SUP = clf_SV.predict(tempS_SUP)\n",
    "for idx, resultId in enumerate(S_Id_SUP):\n",
    "    result_SUP[resultId] = S_result_SUP[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[65364,  1232,  6165,     4,     0],\n",
       "       [ 1223,  1695,   411,    42,     0],\n",
       "       [   59,   281,  1219,     9,     0],\n",
       "       [    3,     1,     1,     0,     0],\n",
       "       [    6,    15,     7,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 1172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(real_label_SUP, result_SUP, labels=['N', 'S', 'V','F','Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "801\n",
      "ACC: 0.936577582768\n",
      "\n",
      "N Total: 2173\n",
      "S Total: 66\n",
      "V Total: 268\n",
      "\n",
      "N Sen: 0.952600092039\n",
      "N +P: 0.998552821997\n",
      "\n",
      "S Sen: 0.151515151515\n",
      "S +P: 0.357142857143\n",
      "\n",
      "V Sen: 1.0\n",
      "V +P: 0.676767676768\n"
     ]
    }
   ],
   "source": [
    "a = confusion_matrix(real_label_SUP, result_SUP, labels=['N', 'S', 'V','F','Q'])\n",
    "print(ds)\n",
    "print('ACC: ' + str(accuracy_score(real_label_SUP, result_SUP)))\n",
    "print()\n",
    "print('N Total: ' + str(sum(a[0])))\n",
    "print('S Total: ' + str(sum(a[1])))\n",
    "print('V Total: ' + str(sum(a[2])))\n",
    "print()\n",
    "print('N Sen: ' + str(a[0][0]/sum(a[0])))\n",
    "print('N +P: ' + str(a[0][0]/sum(a[:, 0])))\n",
    "print()\n",
    "print('S Sen: ' + str(a[1][1]/sum(a[1])))\n",
    "print('S +P: ' + str(a[1][1]/sum(a[:, 1])))\n",
    "print()\n",
    "print('V Sen: ' + str(a[2][2]/sum(a[2])))\n",
    "print('V +P: ' + str(a[2][2]/sum(a[:, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.945353011568\n",
      "\n",
      "N Total: 2173\n",
      "S Total: 66\n",
      "V Total: 268\n",
      "\n",
      "N Sen: 0.96502531063\n",
      "N +P: 0.994310099573\n",
      "\n",
      "S Sen: 0.106060606061\n",
      "S +P: 0.466666666667\n",
      "\n",
      "V Sen: 0.992537313433\n",
      "V +P: 0.701846965699\n"
     ]
    }
   ],
   "source": [
    "compare = clf_1.predict(preprocessing.scale(DS_SUP))\n",
    "b = confusion_matrix(real_label_SUP, compare, labels=['N', 'S', 'V','F','Q'])\n",
    "print('ACC: ' + str(accuracy_score(real_label_SUP, compare)))\n",
    "print()\n",
    "print('N Total: ' + str(sum(b[0])))\n",
    "print('S Total: ' + str(sum(b[1])))\n",
    "print('V Total: ' + str(sum(b[2])))\n",
    "print()\n",
    "print('N Sen: ' + str(b[0][0]/sum(b[0])))\n",
    "print('N +P: ' + str(b[0][0]/sum(b[:, 0])))\n",
    "print()\n",
    "print('S Sen: ' + str(b[1][1]/sum(b[1])))\n",
    "print('S +P: ' + str(b[1][1]/sum(b[:, 1])))\n",
    "print()\n",
    "print('V Sen: ' + str(b[2][2]/sum(b[2])))\n",
    "print('V +P: ' + str(b[2][2]/sum(b[:, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1844"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(b[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACC: 0.861775651249\n",
      "\n",
      "N Total: 1844\n",
      "S Total: 30\n",
      "V Total: 6\n",
      "\n",
      "N Sen: 0.866594360087\n",
      "N +P: 0.994399502178\n",
      "\n",
      "S Sen: 0.566666666667\n",
      "S +P: 0.197674418605\n",
      "\n",
      "V Sen: 1.0\n",
      "V +P: 0.031914893617\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------- INCART ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1689,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Test_Pre_RR_INCART = {}\n",
    "Test_Nearest_INCART = {}\n",
    "for ds in INCART:\n",
    "    temp = []\n",
    "    dsLength = len(INCART_Hbs_lead1[ds]['beat'])\n",
    "    for i in range(1, dsLength):\n",
    "        if INCART_Hbs_lead1[ds]['preRR'][i] > 1100:\n",
    "            continue\n",
    "        else:\n",
    "            temp.append(INCART_Hbs_lead1[ds]['preRR'][i])\n",
    "    Test_Pre_RR_INCART[ds] = [max(np.mean(temp), np.median(temp)), np.std(temp)]\n",
    "    minDis = 999\n",
    "    neighbor = -1\n",
    "    for ds_1 in DS1:\n",
    "        if tresholds[ds_1][2] == -0.2:\n",
    "            continue\n",
    "        elif tresholds[ds_1][0] < Test_Pre_RR_INCART[ds][0]:\n",
    "            continue\n",
    "        else:\n",
    "            temp1 = abs(Test_Pre_RR_INCART[ds][0] - tresholds[ds_1][0]) \n",
    "            if temp1 < minDis:\n",
    "                minDis = temp1\n",
    "                neighbor = ds_1\n",
    "    if neighbor == -1:\n",
    "        neighbor = '124'\n",
    "    Test_Nearest_INCART[ds] = [neighbor, round(tresholds[neighbor][2], 2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1690,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'I60': ['116', -0.24],\n",
       " 'I61': ['124', -0.24],\n",
       " 'I62': ['118', -0.22],\n",
       " 'I63': ['201', -0.4],\n",
       " 'I64': ['201', -0.4],\n",
       " 'I65': ['116', -0.24],\n",
       " 'I66': ['118', -0.22],\n",
       " 'I67': ['203', -0.3],\n",
       " 'I68': ['208', -0.48],\n",
       " 'I69': ['201', -0.4],\n",
       " 'I70': ['124', -0.24],\n",
       " 'I71': ['124', -0.24],\n",
       " 'I72': ['118', -0.22],\n",
       " 'I73': ['201', -0.4],\n",
       " 'I74': ['116', -0.24],\n",
       " 'I75': ['201', -0.4]}"
      ]
     },
     "execution_count": 1690,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Test_Nearest_INCART"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1691,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I60:\n",
      "[[2427   45]\n",
      " [   0    0]]\n",
      "\n",
      "I61:\n",
      "[[1451    0]\n",
      " [   0    1]]\n",
      "\n",
      "I62:\n",
      "[[1393   58]\n",
      " [   1    8]]\n",
      "\n",
      "I63:\n",
      "[[1845    0]\n",
      " [   1    0]]\n",
      "\n",
      "I64:\n",
      "[[1883    0]\n",
      " [   0    0]]\n",
      "\n",
      "I65:\n",
      "[[1988  283]\n",
      " [   2    3]]\n",
      "\n",
      "I66:\n",
      "[[2038   97]\n",
      " [   1    0]]\n",
      "\n",
      "I67:\n",
      "[[2414   21]\n",
      " [   5    0]]\n",
      "\n",
      "I68:\n",
      "[[2479    0]\n",
      " [   2    0]]\n",
      "\n",
      "I69:\n",
      "[[1997    0]\n",
      " [   0    1]]\n",
      "\n",
      "I70:\n",
      "[[1538    0]\n",
      " [   0  126]]\n",
      "\n",
      "I71:\n",
      "[[1448  184]\n",
      " [   0   35]]\n",
      "\n",
      "I72:\n",
      "[[1864    8]\n",
      " [   0    8]]\n",
      "\n",
      "I73:\n",
      "[[1888    0]\n",
      " [   0   32]]\n",
      "\n",
      "I74:\n",
      "[[2079    0]\n",
      " [   0    0]]\n",
      "\n",
      "I75:\n",
      "[[1482    0]\n",
      " [   0    0]]\n",
      "\n",
      "30214 696\n",
      "12 214\n"
     ]
    }
   ],
   "source": [
    "n2n = 0\n",
    "n2s = 0\n",
    "s2s = 0\n",
    "s2n = 0\n",
    "\n",
    "for ds in INCART:\n",
    "    rrrr = []\n",
    "    real = []\n",
    "    \n",
    "    if np.std(INCART_Hbs_lead1[ds]['preRR'][1:]) > 45:\n",
    "        if abs(np.mean(INCART_Hbs_lead1[ds]['preRR'][1:]) - np.median(INCART_Hbs_lead1[ds]['preRR'][1:])) > 30:\n",
    "            Test_Nearest_INCART[ds][1] = -(math.floor(Test_Nearest_INCART[ds][1] * (-10) - 0.1))/10\n",
    "            \n",
    "    dsLength = len(INCART_Hbs_lead1[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if INCART_Hbs_lead1[ds]['preRR'][i] > 1000:\n",
    "            continue\n",
    "        if INCART_Hbs_lead1[ds]['ann'][i] in N:\n",
    "            real.append('N')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in SVEB:\n",
    "            real.append('S')\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        #me = np.mean(INCART_Hbs_lead1[ds]['preRR'][1:])\n",
    "        me = max(np.mean(INCART_Hbs_lead1[ds]['preRR'][1:]), np.median(INCART_Hbs_lead1[ds]['preRR'][1:]))\n",
    "        \n",
    "        if (INCART_Hbs_lead1[ds]['preRR'][i] - INCART_Hbs_lead1[ds]['postRR'][i]) / me < Test_Nearest_INCART[ds][1]:\n",
    "            rrrr.append('S')\n",
    "        elif (INCART_Hbs_lead1[ds]['preRR'][i] - me) / me < Test_Nearest_INCART[ds][1]:\n",
    "            rrrr.append('S')\n",
    "        else:\n",
    "            rrrr.append('N')\n",
    "    \n",
    "    n2n += confusion_matrix(real, rrrr, labels=['N', 'S'])[0][0]\n",
    "    n2s += confusion_matrix(real, rrrr, labels=['N', 'S'])[0][1]\n",
    "    s2n += confusion_matrix(real, rrrr, labels=['N', 'S'])[1][0]\n",
    "    s2s += confusion_matrix(real, rrrr, labels=['N', 'S'])[1][1]\n",
    "                            \n",
    "    print(ds + ':')\n",
    "    print(confusion_matrix(real, rrrr, labels=['N', 'S']))\n",
    "    print()\n",
    "print(n2n, n2s)\n",
    "print(s2n, s2s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1692,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "N_Set_INCART = []\n",
    "N_Id_INCART = []\n",
    "S_Set_INCART = []\n",
    "S_Id_INCART = []\n",
    "result_INCART = []\n",
    "real_label_INCART = []\n",
    "DS_INCART = []\n",
    "selected_colums = ['postRR', 'preRR', 'skewness', 'kurtosis', 'cD7', 'cD6', 'cD5', 'cD4']\n",
    "\n",
    "for ds in INCART:\n",
    "#for ds in ['I75']:\n",
    "    dsLength = len(INCART_Hbs_lead1[ds]['beat'])\n",
    "    for i in range(1, dsLength-1):\n",
    "        if INCART_Hbs_lead1[ds]['ann'][i] in N:\n",
    "            real_label_INCART.append('N')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in SVEB:\n",
    "            real_label_INCART.append('S')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in VEB:\n",
    "            real_label_INCART.append('V')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in F:\n",
    "            real_label_INCART.append('F')\n",
    "        elif INCART_Hbs_lead1[ds]['ann'][i] in Q:\n",
    "            real_label_INCART.append('Q')\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        features = []\n",
    "        for column in selected_colums:\n",
    "            if type(INCART_Hbs_lead1[ds][column][i]) == list:\n",
    "                features.extend(INCART_Hbs_lead1[ds][column][i])\n",
    "            else:\n",
    "                features.append(INCART_Hbs_lead1[ds][column][i])\n",
    "        DS_INCART.append(features)       \n",
    "        me = max(np.mean(INCART_Hbs_lead1[ds]['preRR'][1:]), np.median(INCART_Hbs_lead1[ds]['preRR'][1:]))\n",
    "        if (INCART_Hbs_lead1[ds]['preRR'][i] - INCART_Hbs_lead1[ds]['postRR'][i]) / me < Test_Nearest_INCART[ds][1]:\n",
    "            result_INCART.append('S')\n",
    "            S_Set_INCART.append(features)\n",
    "            S_Id_INCART.append(len(result_INCART)-1)\n",
    "        elif (INCART_Hbs_lead1[ds]['preRR'][i] - me) / me < Test_Nearest_INCART[ds][1]:\n",
    "            result_INCART.append('S')\n",
    "            S_Set_INCART.append(features)\n",
    "            S_Id_INCART.append(len(result_INCART)-1)\n",
    "        else:\n",
    "            result_INCART.append('N')\n",
    "            N_Set_INCART.append(features)\n",
    "            N_Id_INCART.append(len(result_INCART)-1)\n",
    "            \n",
    "total_INCART = []\n",
    "total_INCART.extend(list(N_Set_INCART))\n",
    "total_INCART.extend(list(S_Set_INCART))\n",
    "normalized_total_INCART = preprocessing.scale(total_INCART)\n",
    "Norlize_N_Set_INCART = normalized_total_INCART[:len(N_Set_INCART)]\n",
    "Norlize_S_Set_INCART = normalized_total_INCART[len(N_Set_INCART):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1693,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempN_INCART = []\n",
    "for i in Norlize_N_Set_INCART:\n",
    "    tempN_INCART.append(i[0:-2])\n",
    "N_result_INCART = clf_NV.predict(tempN_INCART)\n",
    "for idx, resultId in enumerate(N_Id_INCART):\n",
    "    result_INCART[resultId] = N_result_INCART[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1694,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempS_INCART = []\n",
    "for i in Norlize_S_Set_INCART:\n",
    "    #tempS_INCART.append(i[2:])\n",
    "    tempS_INCART.append(i[2:])\n",
    "S_result_INCART = clf_SV.predict(tempS_INCART)\n",
    "for idx, resultId in enumerate(S_Id_INCART):\n",
    "    result_INCART[resultId] = S_result_INCART[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1695,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[27800,   500,  2574,    36,     0],\n",
       "       [   12,    24,   190,     0,     0],\n",
       "       [  398,   254,  3071,    15,     0],\n",
       "       [   74,     2,     7,     1,     0],\n",
       "       [    0,     0,     0,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 1695,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(real_label_INCART, result_INCART, labels=['N', 'S', 'V','F','Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1696,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\specialrule{0em}{1pt}{2pt}\n",
      "I75 & 30910 & 226 & 3738 && 88.38 & 89.94 & 98.29 && 10.62 & 3.08 && 82.16 & 52.57 & \\\\\n",
      "\n",
      "I75\n",
      "ACC: 0.883803421248\n",
      "\n",
      "N Total: 30910\n",
      "S Total: 226\n",
      "V Total: 3738\n",
      "\n",
      "N Sen: 0.9\n",
      "N +P: 0.98\n",
      "\n",
      "S Sen: 0.106194690265\n",
      "S +P: 0.0307692307692\n",
      "\n",
      "V Sen: 0.821562332798\n",
      "V +P: 0.525676138309\n"
     ]
    }
   ],
   "source": [
    "a = confusion_matrix(real_label_INCART, result_INCART, labels=['N', 'S', 'V','F','Q'])\n",
    "\n",
    "print(\"\\\\specialrule{0em}{1pt}{2pt}\")\n",
    "if np.isnan(a[1][1]/sum(a[1])):\n",
    "    SSen = '\\\\textendash'\n",
    "    SP = '\\\\textendash'\n",
    "else:\n",
    "    SSen = str(round(a[1][1]/sum(a[1]) * 100, 2))\n",
    "    SP = str(round(a[1][1]/sum(a[:, 1]) * 100, 2))\n",
    "    \n",
    "if np.isnan(a[2][2]/sum(a[2])):\n",
    "    VSen = '\\\\textendash'\n",
    "    VP = '\\\\textendash'\n",
    "else:\n",
    "    VSen = str(round(a[2][2]/sum(a[2]) * 100, 2))\n",
    "    VP = str(round(a[2][2]/sum(a[:, 2]) * 100, 2))\n",
    "    \n",
    "print(ds + ' & ' \n",
    "      + str(sum(a[0])) + ' & ' \n",
    "      + str(sum(a[1])) + ' & ' \n",
    "      + str(sum(a[2])) + ' && ' \n",
    "      + str(round(accuracy_score(real_label_INCART, result_INCART) * 100, 2)) + ' & ' \n",
    "      + str(round(a[0][0]/sum(a[0]) * 100, 2)) + ' & ' \n",
    "      + str(round(a[0][0]/sum(a[:, 0]) * 100, 2)) + ' && ' \n",
    "      + SSen + ' & '\n",
    "      + SP + ' && '\n",
    "      + VSen + ' & '\n",
    "      + VP + ' & \\\\\\\\'\n",
    "     )\n",
    "\n",
    "print()\n",
    "print(ds)\n",
    "print('ACC: ' + str(accuracy_score(real_label_INCART, result_INCART)))\n",
    "print()\n",
    "print('N Total: ' + str(sum(a[0])))\n",
    "print('S Total: ' + str(sum(a[1])))\n",
    "print('V Total: ' + str(sum(a[2])))\n",
    "print()\n",
    "print('N Sen: ' + str(round(a[0][0]/sum(a[0]), 2)))\n",
    "print('N +P: ' + str(round(a[0][0]/sum(a[:, 0]), 2)))\n",
    "print()\n",
    "print('S Sen: ' + str(a[1][1]/sum(a[1])))\n",
    "print('S +P: ' + str(a[1][1]/sum(a[:, 1])))\n",
    "print()\n",
    "print('V Sen: ' + str(a[2][2]/sum(a[2])))\n",
    "print('V +P: ' + str(a[2][2]/sum(a[:, 2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1697,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttt = ttt + a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1698,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[144377,   3387,   5510,    217,      0],\n",
       "       [   222,   1476,    218,     42,      0],\n",
       "       [   726,   2056,  17151,     60,      0],\n",
       "       [   140,      6,     71,      2,      0],\n",
       "       [     2,      0,      4,      0,      0]], dtype=int64)"
      ]
     },
     "execution_count": 1698,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1710,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ttt1 = np.array([\n",
    "    [144377, 3387, 5727],\n",
    "    [222, 1476, 260],\n",
    "    [868, 2062, 17288]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1712,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\specialrule{0em}{1pt}{2pt}\n",
      "234 & 153491 & 1958 & 20218 && 92.87 & 94.06 & 99.25 && 75.38 & 21.31 && 85.51 & 74.28 & \\\\\n",
      "\n",
      "\n",
      "N Total: 153491\n",
      "S Total: 1958\n",
      "V Total: 20218\n",
      "\n",
      "N Sen: 0.94\n",
      "N +P: 0.99\n",
      "\n",
      "S Sen: 0.753830439224\n",
      "S +P: 0.213140794224\n",
      "\n",
      "V Sen: 0.855079632011\n",
      "V +P: 0.742771213749\n"
     ]
    }
   ],
   "source": [
    "print(\"\\\\specialrule{0em}{1pt}{2pt}\")\n",
    "if np.isnan(ttt1[1][1]/sum(ttt1[1])):\n",
    "    SSen = '\\\\textendash'\n",
    "    SP = '\\\\textendash'\n",
    "else:\n",
    "    SSen = str(round(ttt1[1][1]/sum(ttt1[1]) * 100, 2))\n",
    "    SP = str(round(ttt1[1][1]/sum(ttt1[:, 1]) * 100, 2))\n",
    "    \n",
    "if np.isnan(ttt1[2][2]/sum(ttt1[2])):\n",
    "    VSen = '\\\\textendash'\n",
    "    VP = '\\\\textendash'\n",
    "else:\n",
    "    VSen = str(round(ttt1[2][2]/sum(ttt1[2]) * 100, 2))\n",
    "    VP = str(round(ttt1[2][2]/sum(ttt1[:, 2]) * 100, 2))\n",
    "\n",
    "total = sum(ttt1[0]) + sum(ttt1[1]) + sum(ttt1[2])# + sum(ttt1[3]) + sum(ttt1[4])\n",
    "correct = ttt1[0][0] + ttt1[1][1] + ttt1[2][2] # + ttt1[3][3] + ttt1[4][4]\n",
    "\n",
    "print(ds + ' & ' \n",
    "      + str(sum(ttt1[0])) + ' & ' \n",
    "      + str(sum(ttt1[1])) + ' & ' \n",
    "      + str(sum(ttt1[2])) + ' && ' \n",
    "      + str(round(correct / total * 100, 2)) + ' & ' \n",
    "      + str(round(ttt1[0][0]/sum(ttt1[0]) * 100, 2)) + ' & ' \n",
    "      + str(round(ttt1[0][0]/sum(ttt1[:, 0]) * 100, 2)) + ' && ' \n",
    "      + SSen + ' & '\n",
    "      + SP + ' && '\n",
    "      + VSen + ' & '\n",
    "      + VP + ' & \\\\\\\\'\n",
    "     )\n",
    "\n",
    "print()\n",
    "\n",
    "print()\n",
    "print('N Total: ' + str(sum(ttt1[0])))\n",
    "print('S Total: ' + str(sum(ttt1[1])))\n",
    "print('V Total: ' + str(sum(ttt1[2])))\n",
    "print()\n",
    "print('N Sen: ' + str(round(ttt1[0][0]/sum(ttt1[0]), 2)))\n",
    "print('N +P: ' + str(round(ttt1[0][0]/sum(ttt1[:, 0]), 2)))\n",
    "print()\n",
    "print('S Sen: ' + str(ttt1[1][1]/sum(ttt1[1])))\n",
    "print('S +P: ' + str(ttt1[1][1]/sum(ttt1[:, 1])))\n",
    "print()\n",
    "print('V Sen: ' + str(ttt1[2][2]/sum(ttt1[2])))\n",
    "print('V +P: ' + str(ttt1[2][2]/sum(ttt1[:, 2])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------- DESLib ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dealing with Data: 0 - 1000\n",
      "Dealing with Data: 1000 - 2000\n",
      "Dealing with Data: 2000 - 3000\n",
      "Dealing with Data: 3000 - 4000\n",
      "Dealing with Data: 4000 - 5000\n",
      "Dealing with Data: 5000 - 6000\n",
      "Dealing with Data: 6000 - 7000\n",
      "Dealing with Data: 7000 - 8000\n",
      "Dealing with Data: 8000 - 9000\n",
      "Dealing with Data: 9000 - 10000\n",
      "Dealing with Data: 10000 - 11000\n",
      "Dealing with Data: 11000 - 12000\n",
      "Dealing with Data: 12000 - 13000\n",
      "Dealing with Data: 13000 - 14000\n",
      "Dealing with Data: 14000 - 15000\n",
      "Dealing with Data: 15000 - 16000\n",
      "Dealing with Data: 16000 - 17000\n",
      "Dealing with Data: 17000 - 18000\n",
      "Dealing with Data: 18000 - 19000\n",
      "Dealing with Data: 19000 - 20000\n",
      "Dealing with Data: 20000 - 21000\n",
      "Dealing with Data: 21000 - 22000\n",
      "Dealing with Data: 22000 - 23000\n",
      "Dealing with Data: 23000 - 24000\n",
      "Dealing with Data: 24000 - 25000\n",
      "Dealing with Data: 25000 - 26000\n",
      "Dealing with Data: 26000 - 27000\n",
      "Dealing with Data: 27000 - 28000\n",
      "Dealing with Data: 28000 - 29000\n",
      "Dealing with Data: 29000 - 30000\n",
      "Dealing with Data: 30000 - 31000\n",
      "Dealing with Data: 31000 - 32000\n",
      "Dealing with Data: 32000 - 33000\n",
      "Dealing with Data: 33000 - 34000\n",
      "Dealing with Data: 34000 - 35000\n",
      "Dealing with Data: 35000 - 36000\n",
      "Dealing with Data: 36000 - 37000\n",
      "Dealing with Data: 37000 - 38000\n",
      "Dealing with Data: 38000 - 39000\n",
      "Dealing with Data: 39000 - 40000\n",
      "Dealing with Data: 40000 - 41000\n",
      "Dealing with Data: 41000 - 42000\n",
      "Dealing with Data: 42000 - 43000\n",
      "Dealing with Data: 43000 - 44000\n",
      "Dealing with Data: 44000 - 45000\n",
      "Dealing with Data: 45000 - 46000\n",
      "Dealing with Data: 46000 - 47000\n",
      "Dealing with Data: 47000 - 48000\n",
      "Dealing with Data: 48000 - 49000\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "knopResult = []\n",
    "while start + 1000 < len(Testing_Data_1):\n",
    "    knopResult.extend(list(knop.predict(Testing_Data_1[start: start + 1000])))\n",
    "    print('Dealing with Data: ' + str(start) + ' - ' + str(start+1000))\n",
    "    start += 1000\n",
    "    \n",
    "knopResult.extend(list(knop.predict(Testing_Data_1[start: ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "temp_test_label_1 = []\n",
    "for label in Testing_Data_Label_1:\n",
    "    if label in N:\n",
    "        temp_test_label_1.append(0.0)\n",
    "    elif label in SVEB:\n",
    "        temp_test_label_1.append(1.0)\n",
    "    elif label in VEB:\n",
    "        temp_test_label_1.append(2.0)\n",
    "    elif label in Q:\n",
    "        temp_test_label_1.append(3.0)\n",
    "    elif label in F:\n",
    "        temp_test_label_1.append(4.0)\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------------ 1 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78891691909482231"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(SUP_Data_Label_2, result_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[75983,  3107,  8235,  2051,     0],\n",
       "       [ 4702,  2525,  1433,   162,     0],\n",
       "       [ 1357,  1297,  5615,    95,     0],\n",
       "       [   17,     0,     1,     0,     0],\n",
       "       [   16,     5,    30,     0,     0]], dtype=int64)"
      ]
     },
     "execution_count": 677,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(SUP_Data_Label_2, result_1, labels=['N', 'S', 'V', 'F', 'Q'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### ------------------------------------------------------------------ 2 -------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy_score(Testing_Data_Label_2, result_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "confusion_matrix(Testing_Data_Label_2, result_2, labels=['Non-S', 'S'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ------------------------------------------------------------- DESLib ----------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.90785127296165002"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(temp_test_label_1, knopResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[41893,   715,  1532,     0,    58],\n",
       "       [ 1379,   204,   253,     0,     0],\n",
       "       [  210,    36,  2972,     0,     1],\n",
       "       [    1,     0,     6,     0,     0],\n",
       "       [  202,     3,   179,     0,     4]], dtype=int64)"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(temp_test_label_1, knopResult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt = 0\n",
    "for label in Testing_Data_Label_1:\n",
    "    if label == 'Q':\n",
    "        cnt += 1\n",
    "cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
